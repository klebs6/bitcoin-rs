{
  "crate_name": "bitcoinleveldb-arena",
  "full_readme_markdown": "# bitcoinleveldb-arena\n\nA low-level memory arena allocator and test harness used in the Bitcoin-inspired LevelDB port (`bitcoinleveldb`) for Rust. This crate provides a small, allocation-centric building block that closely mirrors the original C++ `Arena` used in LevelDB, while embracing Rust's safety guarantees where feasible and preserving raw-pointer semantics where required for performance parity.\n\n> **Note**: This README was generated by an AI model. It may not be perfectly accurate in every minor detail, but it should be directionally correct and reasonably comprehensive.\n\n---\n\n## Overview\n\n`bitcoinleveldb-arena` implements a monotonic bump allocator backed by a set of heap-allocated blocks. It is designed for workloads where many small allocations are performed and freed en masse by dropping the arena, rather than via fine-grained deallocation of individual objects.\n\nThe crate intentionally exposes a low-level interface using raw pointers, matching the behavior and layout of the original C++ LevelDB `Arena` to ease validation, benchmarking, and cross-language comparison.\n\nCore components:\n\n- **`Arena`** – a bump-allocating arena:\n  - Carves fixed-size backing blocks into small allocations.\n  - Provides both unaligned (`allocate`) and aligned (`allocate_aligned`) allocation entry points.\n  - Tracks total memory used for debugging and profiling via `memory_usage()`.\n  - Frees all blocks in `Drop`.\n- **`ArenaTest`** – a trivial placeholder struct used to mirror the C++ `ArenaTest` harness for tests/benchmarks.\n- **`LcgRandom`** – a minimal linear congruential generator used for randomized stress tests.\n\nThe allocator is *monotonic*: allocation is O(1), and memory is reclaimed only when the arena is dropped. There is no deallocation API for individual allocations.\n\nThis crate is expected to be used as an internal dependency of higher-level database/LSM components rather than as a general-purpose allocator. Nevertheless, the interface is straightforward to integrate into other high-throughput, allocation-heavy systems.\n\n---\n\n## Design\n\n### Memory model\n\nThe `Arena` maintains:\n\n- `alloc_ptr: *mut u8` – pointer to the current bump position inside the active block.\n- `alloc_bytes_remaining: usize` – remaining capacity in bytes in the current block.\n- `blocks: Vec<*mut u8>` – owned raw pointers to all blocks allocated so far.\n- `memory_usage: AtomicUsize` – a relaxed-ordered counter tracking the total heap footprint of all blocks.\n\nAllocation proceeds as follows:\n\n1. **Fast path** – If `bytes <= alloc_bytes_remaining`, the arena returns `alloc_ptr` and advances the bump pointer and remaining count.\n2. **Fallback path** – Otherwise, it calls an internal `allocate_fallback(bytes)` (not shown in the snippet but expected to:\n   - Allocate a new backing block (typically at least `bytes` and at least some configured block size).\n   - Push the block's base pointer into `blocks`.\n   - Update `memory_usage`.\n   - Serve the requested `bytes` from the newly allocated block.\n\n`Drop` reconstructs `Box<[u8]>` (or equivalent) from each pointer in `blocks` and drops them, reclaiming all underlying memory.\n\n### Alignment\n\n`allocate_aligned(bytes)` ensures the returned pointer has at least `max(align_of::<*const c_void>(), 8)` alignment. The method computes the current pointer modulus with respect to the alignment and either:\n\n- Serves the allocation from the current block by introducing a small \"slop\" offset, or\n- Falls back to `allocate_fallback(bytes)` and asserts that the resulting pointer meets the alignment constraint.\n\nThis suffices for typical pointer- and 64-bit aligned data structures used in database internals.\n\n### Randomized testing with `LcgRandom`\n\nThe included `LcgRandom` is a classic linear congruential generator (LCG):\n\n- State transition: `seed := seed * 6364136223846793005 + 1 (mod 2^64)`.\n- `uniform(range)` returns `(seed >> 32) % range` in `[0, range)`, which is adequate for fuzz-style tests.\n- `one_in(n)` returns `true` with probability ≈ `1/n` by sampling a uniform integer in `[0, n)` and checking equality to 0.\n\nIt is not cryptographically secure and is only intended for performance and correctness tests of the arena.\n\n---\n\n## Logging and observability\n\nThe crate uses the `log` facade (`info!`, `debug!`, `trace!`) to:\n\n- Announce creation of `Arena` and `ArenaTest` instances.\n- Record allocation sizes and decisions about falling back to new blocks.\n- Expose memory usage via `Arena::memory_usage()`.\n- Trace pseudo-random sequences in `LcgRandom`.\n\nTo observe these logs, depend on a `log`-compatible logger (e.g. `env_logger`, `tracing-log`, `fern`) and initialize it in your executable before using this crate.\n\n---\n\n## Usage\n\n### Adding the dependency\n\n```toml\n[dependencies]\nbitcoinleveldb-arena = \"0.1.19\"\nlog = \"0.4\"     # to see internal logging\n``\n\n### Basic arena allocation\n\n```rust\nuse bitcoinleveldb_arena::Arena; // assuming the crate exports Arena at the root\n\nfn main() {\n    // Initialize a logger of your choice here to see logs.\n\n    let mut arena = Arena::default();\n\n    // Allocate 128 bytes (unaligned beyond the arena's natural bump position)\n    let ptr = arena.allocate(128);\n    unsafe {\n        // For example, initialize the memory\n        std::ptr::write_bytes(ptr, 0, 128);\n    }\n\n    // Request an aligned allocation (pointer alignment or 8 bytes, whichever is larger)\n    let aligned = arena.allocate_aligned(64);\n    unsafe {\n        // You may cast the aligned pointer to any type whose alignment is <= arena alignment\n        let slice = std::slice::from_raw_parts_mut(aligned, 64);\n        slice[0] = 42;\n    }\n\n    // Retrieve an approximate total memory footprint\n    let usage = arena.memory_usage();\n    println!(\"arena is using ~{} bytes\", usage);\n\n    // When `arena` is dropped here, all internal blocks are freed en masse.\n}\n```\n\n### Randomized workload generation\n\n```rust\nuse bitcoinleveldb_arena::{Arena, LcgRandom};\n\nfn randomized_allocations() {\n    let mut arena = Arena::default();\n    let mut rng = LcgRandom::new(0x1234_5678_9abc_def0);\n\n    for _ in 0..10_000 {\n        let size = 1 + rng.uniform(256) as usize;\n        let ptr = if rng.one_in(4) {\n            arena.allocate_aligned(size)\n        } else {\n            arena.allocate(size)\n        };\n\n        unsafe { std::ptr::write_bytes(ptr, 0xAA, size); }\n    }\n\n    println!(\"total usage = {} bytes\", arena.memory_usage());\n}\n```\n\n---\n\n## Safety considerations\n\nThis crate purposefully exposes raw pointers and performs manual memory management, so correct usage requires care:\n\n- **Lifetime discipline**: Pointers returned by `Arena::allocate` and `Arena::allocate_aligned` remain valid until the arena is dropped. Do not access them after the arena is out of scope.\n- **No individual free**: You must not attempt to deallocate or `Box::from_raw` these pointers yourself. The arena owns them and will free them when dropped.\n- **Type aliasing and alignment**:\n  - Only cast returned `*mut u8` pointers to types whose alignment is less than or equal to the arena's alignment guarantees (`allocate_aligned` for stricter alignment).\n  - Ensure that your casts do not violate Rust's aliasing rules. Consider using `std::ptr::write`, `ptr::read`, and carefully designed lifetimes.\n- **Threading**: `Arena` uses `AtomicUsize` for `memory_usage` but, given the shared mutable state in `alloc_ptr` and `alloc_bytes_remaining`, treat an individual `Arena` as **not** `Sync`. Access it from a single thread or protect access with synchronization primitives.\n\nBecause this crate is designed for integration inside performance-critical systems, it chooses explicit `unsafe` usage rather than high-level abstractions in some places. Review any unsafe blocks before adapting the allocator to new use cases.\n\n---\n\n## When to use this crate\n\nThis crate is appropriate when you:\n\n- Need a LevelDB-compatible memory arena for porting or interop tests.\n- Want a high-throughput, monotonic allocator for ephemeral data structures (e.g., table building, compaction buffers, query scratchpads).\n- Prefer deterministic, simple allocation behavior over general-purpose, fragmentation-resistant allocators.\n\nIt is **not** a general-purpose allocator replacement and should not be used for arbitrary application-wide memory management without careful profiling and analysis.\n\n---\n\n## Repository and contribution\n\nThe code lives in the `bitcoin-rs` repository:\n\n- Repository: <https://github.com/klebs6/bitcoin-rs>\n\nIssues and pull requests should be filed against that repository. When modifying this crate, preserve behavioral parity with the original C++ LevelDB arena where relevant, especially in terms of pointer alignment, block sizing policies, and performance characteristics.\n\n---\n\n## License\n\nLicensed under the MIT License. See the repository for full license text.\n",
  "package_categories": [
    "algorithms",
    "data-structures",
    "memory-management",
    "development-tools",
    "science"
  ],
  "package_description": "Low-level bump-allocating memory arena and LCG-based test harness extracted from a Bitcoin LevelDB port, providing raw-pointer allocation, aligned blocks, and memory-usage instrumentation.",
  "package_keywords": [
    "arena",
    "allocator",
    "leveldb",
    "bitcoin",
    "memory"
  ]
}