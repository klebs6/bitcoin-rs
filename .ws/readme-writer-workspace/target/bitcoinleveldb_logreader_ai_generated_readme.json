{
  "crate_name": "bitcoinleveldb-logreader",
  "full_readme_markdown": "# bitcoinleveldb-logreader\n\nA low-level, LevelDB-compatible log reader for Rust, tailored for Bitcoin Core–style environments and other append-only WAL/redo-log use cases.\n\nThis crate provides a faithful, allocation-conscious reimplementation of the LevelDB log format reader, including fragmentation handling, checksumming, corruption reporting, and initial-offset based resynchronization.\n\n> NOTE: This README.md was generated by an AI model and may not be 100% accurate, but it should be a close match to the actual crate.\n\n---\n\n## Design Overview\n\n`LogReader` is designed to read *logical* records out of an *append-only, block-structured* log file that uses the LevelDB log format. In this format, each logical record is represented as one or more *physical fragments* stored in fixed-size blocks (typically 32 KiB):\n\n- Each fragment has a header and a payload\n- Fragment headers include CRC32C checksums, length, and type\n- Fragment types: `Full`, `First`, `Middle`, `Last`\n- A logical record is either a single `Full` fragment or a `First` + zero or more `Middle` + `Last` fragments\n\n`LogReader` wraps a `SequentialFile` abstraction to read from the underlying file descriptor/handle, reconstructs fragmented records, and validates them (optionally with checksums). It also tracks *physical offsets* and an *initial logical offset* for resuming from arbitrary positions.\n\n### Key Properties\n\n- **Streaming, forward-only**: reads sequentially; no seeking back\n- **Fragment reassembly**: handles `First`/`Middle`/`Last` fragments into full logical records\n- **Corruption-aware**:\n  - CRC32C-based checksum validation (optional)\n  - Dropped bytes and malformed records are logged via a `LogReaderReporter`\n  - Partial ending records at EOF are tolerated without being reported as corruption\n- **Offset-aware**:\n  - `initial_offset` to start from an arbitrary physical position\n  - Resynchronization logic skips partial fragments until a clean record boundary is found\n- **Low-level, pointer-based**: uses a pre-allocated backing buffer, raw pointers, and a `Slice` abstraction for minimizing allocations and copies\n\nThe behavior is closely aligned with LevelDB’s original C++ `log::Reader`, which is particularly relevant when interoperating with Bitcoin Core data directories or other systems using the same log encoding.\n\n---\n\n## Crate Layout and Core Types\n\n### `LogReaderReporter`\n\n```rust\n/// Interface for reporting errors.\npub trait LogReaderReporter {\n    fn corruption(&mut self, bytes: usize, status: &Status);\n}\n```\n\nImplement this trait to hook into corruption reporting. `bytes` is the number of bytes dropped from the log, and `status` encodes a `corruption(...)` `Status` created by the reader. Typical implementations log, meter, or abort on corruption.\n\n### `LogReader`\n\n```rust\n#[derive(Builder, Setters, Getters, MutGetters)]\npub struct LogReader  {\n    file:                 Box<dyn SequentialFile>,\n    reporter:             Box<dyn LogReaderReporter>,\n    checksum:             bool,\n    backing_store:        *const u8,\n    buffer:               Slice,\n    eof:                  bool,\n    last_record_offset:   u64,\n    end_of_buffer_offset: u64,\n    initial_offset:       u64,\n    resyncing:            bool,\n}\n```\n\nThe primary entry point is the constructor and `read_record`:\n\n```rust\nimpl LogReader {\n    pub fn new(\n        file:           Box<dyn SequentialFile>,\n        reporter:       Box<dyn LogReaderReporter>,\n        checksum:       bool,\n        initial_offset: u64,\n    ) -> Self { /* ... */ }\n\n    /// Read the next logical record into `record`.\n    /// Returns `true` on success, `false` on EOF.\n    pub fn read_record(&mut self, record: &mut Slice, scratch: &mut Vec<u8>) -> bool { /* ... */ }\n}\n```\n\n#### Internal Concepts\n\n- **`SequentialFile`**: Abstraction of a forward-only file. You must provide a concrete implementation that supports `read(block_size, result_ptr, scratch_ptr)` and `skip(n)` semantics. This is often backed by POSIX or OS-specific APIs.\n- **`Slice`**: Thin, pointer-based view over a region of memory (data pointer + length). Both incoming file data and exposed record payloads are represented as `Slice`s.\n- **Backing store**: `LogReader` owns a fixed-sized backing buffer (`LOG_BLOCK_SIZE`) allocated once in `new()`. `read_into_buffer_from_file` refills `buffer` by reading into this backing store.\n- **Offsets**:\n  - `end_of_buffer_offset` tracks the physical offset *just past* the last byte read from the file\n  - `last_record_offset` tracks the physical offset of the last successfully delivered logical record\n  - `initial_offset` is the target physical offset to start delivering records from\n\n---\n\n## Usage\n\nBelow is a conceptual usage sketch. Types like `SequentialFile`, `Slice`, `Status`, and enum types such as `LogRecordType` and `ExtendedRecordTypes` are provided by this crate’s ecosystem (e.g. a Bitcoin LevelDB compatibility layer) and are not reproduced here.\n\n```rust\nuse bitcoinleveldb_logreader::{LogReader, LogReaderReporter};\nuse bitcoinleveldb_env::PosixSequentialFile; // example\nuse bitcoinleveldb_types::{Slice, Status};\n\nstruct MyReporter;\n\nimpl LogReaderReporter for MyReporter {\n    fn corruption(&mut self, bytes: usize, status: &Status) {\n        eprintln!(\"dropped {} bytes due to corruption: {:?}\", bytes, status);\n        // choose your own policy: log, metrics, panic, etc.\n    }\n}\n\nfn read_all_records(path: &str) -> Result<(), Status> {\n    // Build a SequentialFile (implementation-specific)\n    let file: Box<dyn SequentialFile> = Box::new(PosixSequentialFile::open(path)?);\n\n    let reporter: Box<dyn LogReaderReporter> = Box::new(MyReporter);\n    let checksum = true;        // enable CRC32C verification\n    let initial_offset = 0u64;  // start from beginning of file\n\n    let mut reader = LogReader::new(file, reporter, checksum, initial_offset);\n\n    let mut record = Slice::default();\n    let mut scratch = Vec::new();\n\n    while reader.read_record(&mut record, &mut scratch) {\n        // `record` is valid only until the next reader mutation or scratch change\n        let bytes = unsafe { std::slice::from_raw_parts(*record.data(), *record.size()) };\n        // Process record bytes\n        handle_record(bytes);\n    }\n\n    Ok(())\n}\n\nfn handle_record(bytes: &[u8]) {\n    // Application-specific record decoding\n}\n```\n\n### Starting from a Non-Zero Offset\n\nFor fast resume or partial replay, specify `initial_offset`:\n\n```rust\nlet last_known_offset: u64 = load_checkpoint();\nlet mut reader = LogReader::new(file, reporter, true, last_known_offset);\n```\n\n`LogReader` will:\n\n1. Call `skip_to_initial_block()` to jump to the first candidate block\n2. Enter *resync mode* and discard partial fragments until a clean `Full` or `First` fragment is observed at or after `initial_offset`\n3. Begin delivering logical records from a correct boundary\n\nThis mirrors LevelDB’s robust recovery semantics in the presence of torn writes or partial truncations.\n\n---\n\n## Error and Corruption Semantics\n\nFrom a correctness and data-integrity perspective, the key behaviors are:\n\n- **Checksum errors** (`checksum == true`):\n  - Header-payload region CRC32C mismatch → record is discarded\n  - Bytes corresponding to the entire buffer block are dropped and reported as corruption (`\"checksum mismatch\"`)\n- **Bad lengths**:\n  - If the header length field exceeds remaining buffer bytes, the entire buffer is dropped\n  - If EOF has not been seen, this is reported as corruption (`\"bad record length\"`)\n  - If EOF was already set, it is treated as partial tail and not reported as corruption\n- **Partial fragmented records at EOF**:\n  - If EOF is reached in the middle of an assembled logical record, the partial is silently dropped (no corruption report) because this typically indicates an unflushed or partially written tail\n- **Unknown record types**:\n  - The fragment and any accumulated scratch are dropped\n  - Reported as corruption (`\"unknown record type\"`)\n- **Reporter gating by `initial_offset`**:\n  - `report_drop` only emits corruption when the physical `current_offset` is ≥ `initial_offset`\n  - However, failures in the initial `skip` to the target block are treated specially and reported regardless to avoid silent data loss\n\n### Reporter Contract\n\nYour `LogReaderReporter` implementation must:\n\n- Be valid for the entire lifetime of the `LogReader`\n- Tolerate multiple invocations and potentially large `bytes` values\n- Not panic in normal operation if you want robust replay (panic-based fail-fast is also a legitimate policy in some systems)\n\n---\n\n## Memory and Lifetime Model\n\nImportant invariants for a safe integration:\n\n- `LogReader` owns a heap-allocated `[u8; LOG_BLOCK_SIZE]` backing buffer\n  - It keeps only a raw pointer `*const u8` to it (`backing_store`), to pass to `SequentialFile::read`\n  - On `Drop`, it reconstructs the `Box<[u8; LOG_BLOCK_SIZE]>` and frees it\n- `read_record` exposes a `Slice` pointing directly into this backing buffer **or** into the provided `scratch` buffer when assembling fragmented records\n- As a consequence:\n  - The `Slice` returned through `record` is valid only until:\n    - The next `read_record` call, or\n    - The next mutation of `scratch`\n  - If you need to keep a record long-term, copy its bytes out\n\nFrom a performance standpoint, this model keeps heap allocations predictable and reduces copying, which is vital when scanning large Bitcoin block or mempool logs.\n\n---\n\n## Concurrency and Threading\n\n`LogReader` is not designed to be used from multiple threads concurrently without external synchronization:\n\n- It holds internal mutable state (buffer, offsets, EOF flag, resync flag)\n- It operates on raw pointers and assumes exclusive access\n\nTypical patterns:\n\n- Single-threaded log replay loop\n- Sharded readers, each owning its own `SequentialFile` and `LogReader` instance for disjoint files or segments\n\nIf you must share access, wrap `LogReader` in a `Mutex` or design a higher-level ingestion pipeline that uses channels to publish decoded records to multiple worker threads.\n\n---\n\n## Implementation Notes and Mathematics\n\n### CRC32C Validation\n\nLevelDB uses CRC32C (Castagnoli polynomial) with a masking scheme to protect against certain adversarial patterns and coincidences.\n\nIn this crate, the relevant operations are:\n\n- `decode_fixed32(header_ptr)` – read the stored masked CRC32C from the header\n- `crc32c_unmask(encoded)` – recover the actual CRC32C from the masked one\n- `crc32c_value(header_ptr.add(6), 1 + length)` – compute CRC32C over the concatenation of the record type byte and the payload\n\nThe record is valid if `actual_crc == expected_crc`. This is a practical compromise: strong enough against random bit flips and most disk-level corruption, extremely fast, and matches the on-disk format used by LevelDB and Bitcoin.\n\n### Offsets and Block Geometry\n\nGiven:\n\n- `LOG_BLOCK_SIZE = B`\n- `LOG_HEADER_SIZE = H`\n- `initial_offset = O`\n\n`skip_to_initial_block` computes:\n\n- `offset_in_block = O mod B`\n- `block_start_location = O - offset_in_block`\n- If `offset_in_block > B - 6`, the block is treated as a trailing fragment trailer; we skip to `block_start_location + B`\n\nThis guarantees that the scan begins at a block that *can* contain the first complete logical record at or after `O`, respecting the requirement that headers must fit inside a single block (no cross-block headers).\n\n---\n\n## When to Use This Crate\n\nThis crate is appropriate when you:\n\n- Need to read LevelDB-style logs produced by Bitcoin Core or a LevelDB-compatible implementation\n- Want precise control over corruption semantics (which bytes are dropped, what gets reported)\n- Require predictable memory behavior and minimal allocations for large-scale scanning\n- Prefer a low-level API that you can integrate into a custom storage or indexing layer\n\nIt is *not* a high-level database API; instead, it is a specialized building block for storage engines, replication log readers, forensic tools, and Bitcoin-related infrastructure.\n\n---\n\n## License and Metadata\n\n- **License**: MIT\n- **Edition**: Rust 2024\n- **Authors**: `YourName <you@example.com>`\n\nYou are encouraged to audit the implementation, especially around unsafe pointers and `Slice` lifetimes, to ensure that it matches your safety and reliability requirements.\n",
  "package_categories": [
    "database",
    "database-implementations",
    "algorithms",
    "filesystem",
    "network-programming"
  ],
  "package_description": "Low-level LevelDB-compatible log reader for Rust, reconstructing fragmented WAL records with optional CRC32C checksums, precise corruption reporting, and offset-based resynchronization for Bitcoin-style append-only logs.",
  "package_keywords": [
    "leveldb",
    "bitcoin",
    "log-reader",
    "wal",
    "storage"
  ]
}