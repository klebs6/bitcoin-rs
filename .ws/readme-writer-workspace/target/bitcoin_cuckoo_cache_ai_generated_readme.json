{
  "crate_name": "bitcoin-cuckoo-cache",
  "full_readme_markdown": "# bitcoin-cuckoo-cache\n\nA faithful, safe Rust port of Bitcoin Core's *cuckoo-style* eviction cache, extracted and packaged as a reusable crate.\n\nThis structure underpins high‑performance, bounded‑memory caches in latency‑sensitive consensus code. It is engineered for:\n\n- *Predictable memory usage* – fixed upper bound on entries\n- *Fast membership queries* – O(1) expected time, 8‑way cuckoo probing\n- *Lock‑free reads* – interior mutability for GC flags using `AtomicU8`\n- *Lazy reclamation* – entries are logically discarded before being physically overwritten\n\nThe crate provides two primitives:\n\n- [`EightWayHasher`] – abstraction over the 8 independent 32‑bit hash functions\n- [`Cache`] – the cuckoo‑style cache itself, parameterised by element type and hasher\n\nIt also exposes the internal [`BitPackedAtomicFlags`] type used to compactly store collection flags.\n\n> NOTE: This README was generated by an AI model. It may not be perfectly accurate, but it is designed to be a close, technically coherent description of the crate.\n\n---\n\n## High‑level design\n\nThe cache implements an *8‑way cuckoo hash table with bounded kick‑out depth* and a lazily‑applied garbage‑collection scheme.\n\n### Cuckoo hashing recap\n\nClassical cuckoo hashing stores each element in one of several candidate buckets determined by independent hash functions. Upon insertion, if all candidate buckets are occupied, the algorithm *kicks out* an existing element and re‑inserts it in one of its alternative buckets. This process repeats up to some depth bound; if insertion still fails, an element is evicted from the table.\n\nThis crate implements that logic with:\n\n- **Eight** independent 32‑bit hashes per element (`[u32; 8]`)\n- A **bounded insertion depth** (`depth_limit ≈ log2(table_size)`) to cap worst‑case work\n- A **logical garbage‑collection flag** per bucket which marks entries as discardable\n\nThe combination provides a *bounded‑size, probabilistic cache* ideal for ephemeral data such as transaction IDs, UTXO hints, or short‑lived deduplication filters.\n\n### Hash mapping without division\n\nThe user‑supplied hasher yields eight 32‑bit hashes. These are mapped to bucket indices in `[0, size)` using a multiply‑and‑shift reduction:\n\n```text\nindex = floor( (h * size) / 2^32 )\n``\n\nThis treats `h` as a 32‑bit fixed‑point number in `[0, 1)` and scales by `size`. It is:\n\n- Close to uniform (similar bias to `h % size` for large 32‑bit `h`)\n- Much faster than integer division on many architectures\n- Implementable using the upper 32 bits of a 64‑bit product\n\nSee: *Daniel Lemire, \"A fast alternative to the modulo reduction\"* for background.\n\n---\n\n## Core traits and types\n\n### `EightWayHasher<E>`\n\n```rust\npub trait EightWayHasher<E> {\n    /// Compute eight independent 32‑bit hashes for `e`.\n    fn hashes(&self, e: &E) -> [u32; 8];\n}\n```\n\nYou implement this trait to define how `E` is hashed into eight independent 32‑bit values. The cache assumes these hashes have high entropy and are sufficiently independent for cuckoo hashing to work well.\n\nFor example, you might use a domain‑separated cryptographic hash or a good non‑cryptographic PRF over `(e, k)` for `k ∈ {0..8}`.\n\n#### Example: trivial wrapper over `bitcoin_hashes`\n\n```rust\nuse bitcoin_cuckoo_cache::EightWayHasher;\nuse bitcoin_hashes::{sha256, Hash};\n\n#[derive(Default, Clone)]\nstruct Sha256EightWay;\n\nimpl EightWayHasher<[u8; 32]> for Sha256EightWay {\n    fn hashes(&self, e: &[u8; 32]) -> [u32; 8] {\n        // For demonstration only; choose a real construction for production.\n        let mut out = [0u32; 8];\n        for i in 0..8u8 {\n            let mut engine = sha256::Hash::engine();\n            engine.input(e);\n            engine.input(&[i]);\n            let h = sha256::Hash::from_engine(engine);\n            let bytes = h.as_inner();\n            out[i as usize] = u32::from_le_bytes([bytes[0], bytes[1], bytes[2], bytes[3]]);\n        }\n        out\n    }\n}\n```\n\n### `Cache<Element, Hash>`\n\n```rust\n#[derive(Getters, Debug)]\npub struct Cache<Element, Hash>\nwhere\n    Element: PartialEq + Clone,\n    Hash: EightWayHasher<Element>,\n{\n    table:                   Vec<Option<Element>>,\n    size:                    u32,\n    collection_flags:        BitPackedAtomicFlags,\n    epoch_flags:             Vec<bool>,\n    epoch_heuristic_counter: u32,\n    epoch_size:              u32,\n    depth_limit:             u8,\n    hash_function:           Hash,\n}\n```\n\nKey properties:\n\n- **Bounded size:**\n  - Up to `(~(uint32_t)0) - 1` elements (limited by `u32` indices).\n  - `size` is chosen once via [`Cache::setup`] or [`Cache::setup_bytes`].\n- **Threading model:**\n  - Writes (`insert`, `setup`, `setup_bytes`) must be externally synchronized.\n  - Reads (`contains(erase = false)`) must not race with writes.\n  - Erase‑style reads (`contains(erase = true)` or `allow_erase`) must not race with writes.\n  - Lazy reclamation via `BitPackedAtomicFlags` uses only relaxed atomics; the caller is responsible for higher‑level happens‑before ordering between writers and readers.\n\nThe internal `epoch_*` fields implement a *generational aging heuristic*: frequently accessed elements are preferentially preserved while older, rarely touched entries are more likely to be overwritten under pressure.\n\n---\n\n## Construction and sizing\n\n### `Cache::default`\n\n```rust\nimpl<E, H> Default for Cache<E, H>\nwhere\n    E: PartialEq + Clone,\n    H: EightWayHasher<E> + Default,\n{\n    fn default() -> Self { /* ... */ }\n}\n```\n\n`Default` constructs an *empty and unusable* cache. You **must** call either [`setup`] or [`setup_bytes`] before any other operations; otherwise, you will hit panics or UB in practice.\n\n#### Recommended pattern\n\n```rust\nuse bitcoin_cuckoo_cache::{Cache, EightWayHasher};\n\n#[derive(Default)]\nstruct MyHasher; // implements EightWayHasher<MyElement>\n\n#[derive(Clone, PartialEq)]\nstruct MyElement { /* ... */ }\n\nfn build_cache(bytes_budget: usize) -> Cache<MyElement, MyHasher> {\n    let mut cache = Cache::<MyElement, MyHasher>::default();\n    cache.setup_bytes(bytes_budget);\n    cache\n}\n```\n\n### `setup`\n\n```rust\nimpl<E, H> Cache<E, H>\nwhere\n    E: PartialEq + Clone,\n    H: EightWayHasher<E>,\n{\n    pub fn setup(&mut self, new_size: u32) -> u32 { /* ... */ }\n}\n```\n\n- Configures the cache to store at most `new_size` elements.\n- Chooses internal `size = max(2, new_size)`.\n- Sets the depth limit approximately to `log2(size)`.\n- Allocates:\n  - `table: Vec<Option<E>>` of length `size`\n  - `collection_flags: BitPackedAtomicFlags` with one bit per bucket\n  - `epoch_flags: Vec<bool>` with one boolean per bucket\n\nReturns the actual configured `size` (≥ 2).\n\nThis should be called *exactly once* for a given cache instance.\n\n### `setup_bytes`\n\n```rust\n#[inline]\npub fn setup_bytes(&mut self, bytes: usize) -> u32 {\n    let elem_sz = cmp::max(mem::size_of::<E>(), 1);\n    self.setup((bytes / elem_sz) as u32)\n}\n```\n\nConverts a byte budget to an element count using `sizeof(E)` and then calls [`setup`]. This does *not* include struct overhead or flag storage; for realistic use, assume a small constant‑factor overhead and size accordingly.\n\n---\n\n## Core operations\n\n### `compute_hashes`\n\n```rust\n#[inline]\npub fn compute_hashes(&self, e: &E) -> [u32; 8] { /* ... */ }\n```\n\n- Calls `hash_function.hashes(e)` to obtain eight 32‑bit hashes.\n- Maps each hash into `[0, size)` via the multiply‑and‑shift technique described above.\n- Guarantees that every index returned is `0 <= index < size`.\n\nThis is a convenience helper used internally by insertion and lookup; you can also use it directly to inspect bucket placements.\n\n### `invalid`\n\n```rust\n#[inline]\npub fn invalid() -> u32 {\n    u32::MAX\n}\n```\n\nReturns a sentinel bucket index that can never be produced by [`compute_hashes`]. Internal logic uses this as a marker for \"no previous bucket\" when choosing eviction candidates.\n\n### `insert`\n\n```rust\n#[inline]\npub fn insert(&mut self, mut e: E) { /* ... */ }\n```\n\nSemantics:\n\n- Runs the 8‑way cuckoo insertion algorithm with a bounded depth (`depth_limit`).\n- Before insertion, `epoch_check()` (not shown here) may advance the aging epoch and update reclamation state.\n- If any of the eight candidate buckets is currently *collectable* (its bit in `collection_flags` is **set**), the element is written there and marked as *keep* (`bit_unset`).\n- If all candidate buckets are non‑collectable, an eviction sequence begins:\n  - Choose one candidate location derived from the last eviction, cycling through the 8 bucket indices.\n  - Swap the incoming element `e` with the victim stored at the chosen location.\n  - Re‑hash the evicted element and repeat.\n- If the depth limit is exhausted, the final evicted element is **dropped from the cache**; this is a deliberate eviction policy.\n\n**Important invariant:**\n\n```rust\ncache.insert(x);\nlet may_be_present = cache.contains(&x, false);\n```\n\n`may_be_present` is not guaranteed to be `true`. An insertion can cause some other element (or even `x` itself) to be evicted under high load. This is intended: the cache behaves like a finite‑capacity, approximate remember‑set.\n\n### `contains`\n\n```rust\n#[inline]\npub fn contains(&self, e: &E, erase: bool) -> bool { /* ... */ }\n```\n\n- Iterates over all eight candidate buckets for `e`.\n- Returns `true` if a matching `Element` is found (based on `PartialEq`).\n- Ignores the collection flags when checking membership: an element flagged as collectable still counts as *present* until physically overwritten.\n- If `erase == true` and `e` is found, the corresponding bucket is marked collectable via [`allow_erase`].\n\nA key property in a single‑threaded context:\n\n```rust\ninsert(x);\nif contains(&x, true) {\n    assert!(contains(&x, false));\n} else {\n    // If the first contains fails, we do not make any assertion.\n}\n```\n\nIn the reference C++ comments, a slightly different pseudo‑code is given; for re‑org heavy workloads, this semantics is tuned so that certain sequences of `insert` and `contains` behave in a predictably idempotent way when executed without concurrency.\n\n### `allow_erase` and `please_keep`\n\n```rust\n#[inline]\npub fn allow_erase(&self, n: u32) { /* ... */ }\n\n#[inline]\npub fn please_keep(&self, n: u32) { /* ... */ }\n```\n\n- `allow_erase(n)` sets the collection bit for bucket `n` to **true** (collectable).\n- `please_keep(n)` clears the collection bit for bucket `n` (not collectable).\n\nBoth operations are thread‑safe *in the absence of concurrent `insert`*, as they only manipulate `BitPackedAtomicFlags` with relaxed atomics. They do not modify `table` or `epoch_flags`.\n\nThe idea is that higher‑level logic can mark entries as *logically deleted* (`allow_erase`) while deferring physical reclamation to future `insert` calls that need space.\n\n---\n\n## Bit‑packed GC flags\n\n### `BitPackedAtomicFlags`\n\n```rust\n#[derive(Getters, Debug)]\npub struct BitPackedAtomicFlags {\n    mem: Box<[AtomicU8]>,\n}\n```\n\nThis structure stores one **garbage‑collection flag bit per bucket**, packed 8 per `AtomicU8` cell.\n\n- **Construction:**\n\n  ```rust\n  impl BitPackedAtomicFlags {\n      #[inline]\n      pub fn new(size: u32) -> Self { /* ... */ }\n\n      #[inline]\n      pub fn setup(&mut self, b: u32) { /* ... */ }\n  }\n  ```\n\n  - `new(size)` reserves `ceil(size / 8)` bytes and initialises all bits to 1 (`0xFF`), meaning **collectable by default**.\n  - `setup(b)` replaces the internal storage with a new `BitPackedAtomicFlags` sized for at least `b` bits, again initialised with all bits set.\n  - Both are thread‑unsafe while called, but safe once the structure is published.\n\n- **Bit operations:**\n\n  ```rust\n  #[inline]\n  pub fn bit_set(&self, s: u32) { /* ... */ }\n\n  #[inline]\n  pub fn bit_unset(&self, s: u32) { /* ... */ }\n\n  #[inline]\n  pub fn bit_is_set(&self, s: u32) -> bool { /* ... */ }\n  ```\n\n  - `bit_set(s)` marks index `s` as **collectable**.\n  - `bit_unset(s)` marks index `s` as **keep / not collectable**.\n  - `bit_is_set(s)` returns `true` if bucket `s` is currently collectable.\n\nAll operations use `Ordering::Relaxed`. The correctness of the cache relies on higher‑level synchronisation to order updates to `table` vs. these bits.\n\nThis design preserves the C++ implementation's memory layout and semantics while expressing them in Rust via interior mutability instead of `mutable` data members.\n\n---\n\n## Concurrency and memory ordering\n\nThis crate mirrors the reference Bitcoin implementation:\n\n- **Writers** must be serialized.\n- **Readers** must not race with writers that modify the same cache instance.\n- All atomic accesses to collection flags use `Relaxed` ordering.\n\nThe intent is that this cache is used *behind* a higher‑level synchronisation primitive (e.g. `Mutex`, `RwLock`, or a custom epoch‑based reclamation scheme) that enforces the desired consistency model for your application.\n\n### Safety rules recap\n\nThe documentation and comments imply the following discipline:\n\n1. Write requires synchronized access (e.g. a lock).\n2. Read requires no concurrent write, synchronized with the last insert.\n3. Erase requires no concurrent write, synchronized with the last insert.\n4. An Erase caller must release all memory before allowing a new writer.\n\nViolating these assumptions may lead to observable races even though the crate uses only safe Rust (e.g., inconsistent visibility of `table` vs. flags).\n\n---\n\n## Usage example\n\nBelow is a minimal, self‑contained example demonstrating basic API usage in a single‑threaded context.\n\n```rust\nuse bitcoin_cuckoo_cache::{Cache, EightWayHasher};\n\n#[derive(Clone, PartialEq, Debug)]\nstruct Key(u64);\n\n#[derive(Default)]\nstruct SimpleHasher;\n\nimpl EightWayHasher<Key> for SimpleHasher {\n    fn hashes(&self, e: &Key) -> [u32; 8] {\n        // Extremely simplistic; do not use in production.\n        let mut x = e.0.wrapping_mul(0x9E3779B97F4A7C15);\n        let mut out = [0u32; 8];\n        for i in 0..8 {\n            x ^= (x >> 12) ^ ((i as u64) << 32);\n            x = x.rotate_left(27).wrapping_mul(0x94D049BB133111EB);\n            out[i] = (x as u32) ^ ((x >> 32) as u32);\n        }\n        out\n    }\n}\n\nfn main() {\n    // Construct cache with a target memory budget.\n    let mut cache: Cache<Key, SimpleHasher> = Cache::default();\n    let capacity = cache.setup_bytes(1024); // approx capacity in elements\n\n    println!(\"configured cache capacity: {}\", capacity);\n\n    let k1 = Key(1);\n    let k2 = Key(2);\n\n    cache.insert(k1.clone());\n    cache.insert(k2.clone());\n\n    assert!(cache.contains(&k1, false));\n    assert!(cache.contains(&k2, false));\n\n    // Mark k1 as discardable if present.\n    if cache.contains(&k1, true) {\n        // At this point, a future insert might evict `k1`.\n    }\n}\n```\n\n---\n\n## When should you use this crate?\n\nThis cache is appropriate when you need:\n\n- A *fixed‑memory*, high‑throughput cache with probabilistic eviction\n- Very cheap membership checks (`contains`) with stable latency\n- Control over logical deletion vs. physical reclamation\n- Behaviour consistent with Bitcoin Core's existing C++ implementation\n\nTypical applications include:\n\n- Transaction or block ID replay caches\n- Short‑lived deduplication filters\n- Bounded caches for intermediate validation state where false negatives are tolerable but unbounded memory growth is not\n\nIt is *not* a drop‑in replacement for keyed maps or fully general LRU structures; the eviction semantics are designed around cuckoo hashing, not recency or frequency tracking.\n\n---\n\n## Crate metadata\n\n- **Crate name:** `bitcoin-cuckoo-cache`\n- **Version:** `0.1.19`\n- **Edition:** `2021`\n- **License:** MIT\n- **Repository:** <https://github.com/klebs6/bitcoin-rs>\n- **Authors:** `klebs <none>`\n\nBecause this README was generated by an AI model, always treat the crate's Rustdoc, source code, and tests as the ultimate specification of behaviour.\n",
  "package_categories": [
    "algorithms",
    "data-structures",
    "concurrency",
    "cryptography",
    "finance"
  ],
  "package_description": "Safe Rust port of Bitcoin Core's 8-way cuckoo-style eviction cache, providing a bounded-size, hash-based probabilistic cache with lazy reclamation for high-performance blockchain and systems workloads.",
  "package_keywords": [
    "bitcoin",
    "cuckoo-hashing",
    "cache",
    "eviction",
    "blockchain"
  ]
}