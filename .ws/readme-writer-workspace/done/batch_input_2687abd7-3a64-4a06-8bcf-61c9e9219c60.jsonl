{"custom_id":"bitcoin-serialize-ai-readme-request","method":"POST","url":"/v1/chat/completions","body":{"max_completion_tokens":8192,"messages":[{"content":"We would like you to write a README.md for a rust crate with maximally helpful content.\nAdditionally, we would like you to generate several fields from the Cargo.toml package section for this crate.\nWe will show you the strict json output format we would like you to provide.\nPlease tailor your response for an apex consumer of maximal intelligence.\nA reader of this README.md should have a good sense of what the crate does and how to use it after reading what you write.\nPlease include a messaage indicating that this README.md file was generated by an AI model and may not be 100% accurate however it should be pretty good.\n\n\nCarefully read and parse the information we sent you.\n\nWe want to generate all information items requested by our schema:\n\n- Read the description of each field. Use it, along with the content we sent you to generate an appropriate value for each.\n- Ensure that each generated field optimally serves its desired purpose.\n- Each item should be deep, detailed, and specific. Use optimally descriptive and useful language. Do not be too verbose.\n- Do not add any extra keys to the generated object. Generate precisely what we ask of you: no more, no less.\n- For fields which are of an enum type: pick *exactly one variant*. Do not generate any information for the unselected variants.\n- For array fields: supply a JSON list [ ... ] of items, each conforming to the correct item type.\n- For map fields: Provide a JSON object { \"key_as_string\": <value>, ... }. Keys must be valid JSON strings. Keys and Values must conform to the key and value schemas we provide to you. Fill all subfields of each and every map value.\n- If we ask you to justify a map field, provide your justification/confidence score for the entire map. Do not attempt to separately justify each map element.\n- Likewise, if we ask you to justify an array field, provide your justification/confidence score for the entire array. Do not attempt to separately justify each element.\n- Provide numeric fields as real JSON numbers (not strings).\n- For string fields: provide the value precisely as a string literal. If optional, you may set it to null.\n- If we ask you to justify or provide confidence scores for the fields of a structure, please do so carefully. For each field we ask you to justify, please explain or justify your choice clearly. Confidence scores must be specified as real JSON numbers in the range `[0..1]`.\n- If we ask to you generate an optional field, either fill it or set it to null.\n- If we ask you to justify your choice of an enum variant, please explain your choice clearly. Do not justify your decision to leave a variant unselected. Provide your justification as a JSON string. Provide your confidence score as a real JSON number in the range `[0..1]`.\n- In terms of the JSON format we would like you to provide, the object itself will be deserialied based on the following schema. \n- We begin exactly at the top: the data should not be nested under a parent named 'fields' or anything similar.\n\n## Here is the schema to use:\n\nObject {\n    \"fields\": Object {\n        \"crate_name\": Object {\n            \"generation_instructions\": String(\"\\\"This string should be the name of our crate, *verbatim*, trimmed for use as a toml field\\\"\"),\n            \"required\": Bool(true),\n            \"type\": String(\"string\"),\n        },\n        \"full_readme_markdown\": Object {\n            \"generation_instructions\": String(\"\\\"This string should be valid markdown representing the readme for this crate.\\\\n\\\\n Please make it terse, useful, and designed for an industrious commercially savy consumer of industrious nature. \\\\n\\\\n Advanced vocabulary and concepts are welcome. \\\\n\\\\n If this crate involves concepts from mathematics and/or physics, please describe and document them here.\\\"\"),\n            \"required\": Bool(true),\n            \"type\": String(\"string\"),\n        },\n        \"package_categories\": Object {\n            \"generation_instructions\": String(\"\\\"These categories will be used in our Cargo.toml file.\\\\n\\\\n It is important that users of this crate can find it on crates.io.\\\\n\\\\n Choose maximum 5 categories and make sure they are actually meaningful for our crate.\\\\n\\\\n These categories should only be chosen from among the legal crates.io categories. \\\\n\\\\n The ONLY legal categoreis are:\\\\n\\\\n``\\\\n accessibility\\\\n aerospace\\\\n algorithms\\\\n api-bindings\\\\n asynchronous\\\\n authentication\\\\n caching\\\\n command-line-interface\\\\n command-line-utilities\\\\n compilers\\\\n compression\\\\n computer-vision\\\\n concurrency\\\\n config\\\\n cryptography\\\\n data-structures\\\\n database\\\\n database-implementations\\\\n date-and-time\\\\n development-tools\\\\n email\\\\n embedded\\\\n emulators\\\\n encoding\\\\n external-ffi-bindings\\\\n filesystem\\\\n finance\\\\n game-development\\\\n game-engines\\\\n games\\\\n graphics\\\\n gui\\\\n hardware-support\\\\n internationalization\\\\n localization\\\\n mathematics\\\\n memory-management\\\\n multimedia\\\\n network-programming\\\\n no-std\\\\n os\\\\n parser-implementations\\\\n parsing\\\\n rendering\\\\n rust-patterns\\\\n science\\\\n simulation\\\\n template-engine\\\\n text-editors\\\\n text-processing\\\\n value-formatting\\\\n virtualization\\\\n visualization\\\\n wasm\\\\n web-programming\\\\n ``\\\\n\\\\n DO NOT specify a category that is not on this list.\\\"\"),\n            \"required\": Bool(true),\n            \"type\": String(\"array_of_strings\"),\n        },\n        \"package_description\": Object {\n            \"generation_instructions\": String(\"\\\"We will place this package_description in our Cargo.toml file so the users of this crate\\\\n know what it does.\\\\n\\\\n The discription should be technical, clear, and useful. It should be terse.\\\"\"),\n            \"required\": Bool(true),\n            \"type\": String(\"string\"),\n        },\n        \"package_keywords\": Object {\n            \"generation_instructions\": String(\"\\\"These keywords will be used in our Cargo.toml file so the users of this crate can easily\\\\n find it in the package system. Keywords should be useful, varied, meaningful, and reflect\\\\n the contents of our crate. They should make it easy to find. Please provide exactly five.\\\"\"),\n            \"required\": Bool(true),\n            \"type\": String(\"array_of_strings\"),\n        },\n    },\n    \"struct_docs\": String(\" This structure is a directive indicating which fields we need you to provide for us in your response to our query.\\n\"),\n    \"struct_name\": String(\"AiReadmeWriterDesiredOutput\"),\n    \"type\": String(\"struct\"),\n}\n\n## Please keep the following in mind:\n\nEntry phrasing:\n\n- Ensure entries are concise and focused.\n- Ensure there are no vague phrases (e.g., avoid starting with \"Illustrates the something something...\"; instead, use direct details like \"The hanging green vines on the garden wall\").\n\nEnsure Clarity and Consistency:\n\n- Use clear, grammatically correct sentences.\n- Maintain a consistent tone and style throughout.\n\nEnrich Content:\n\n- Communicate additional information where appropriate to enhance depth and value.\n- If a mathematical, physical, or otherwise technical background is helpful, please provide it.\n- Ensure that the content is comprehensive and meets all requirements.\n\nFocus Language:\n\n- Use deliberate and precise language.\n- Avoid vague verbs and keep the maximally intelligent and detail oriented audience in mind. \n- We explicitly ban the words `hush`, `subtle`, `mythic`, and `aura`. Please keep your vocabulary choices rigorous.\n- Do not use modern cultural references \n- Do not generically reference ideas which do not belong in the global environment.\n\n## Present the Final JSON:\n\n- Format the output as a JSON object.\n- Include all fields properly named from the schema we sent you.\n\nEnsure Proper Formatting:\n\n- Use proper JSON syntax with keys and arrays.\n- Ensure that all entries are correctly placed in their respective places.\n\nProvide only the final JSON data as specified by the schema. \n\nDo not include any schema generation instructions, meta-fields, nested-templates (unless directly asked) or extraneous information. \n\nProvide only the populated fields and their values, conforming exactly to the required structure without embedding any intermediate annotations or placeholders.\n\nYour output should only consist of the JSON object. do *not* include a preamble or postamble to your response. \n\nWe seek to successfully parse your response directly as JSON.\n\nFor the final answer, output the result only as a valid JSON object, wrapped inside triple backticks with json immediately after the opening backticks.\nThe JSON must be parser-ready:\n– No additional text before or after the block\n– No markdown or prose outside the fenced block\n– No HTML escaping of quotes, slashes, or other characters\n– Indentation and whitespace preserved exactly as written\n– The content between the fences must be valid JSON as per RFC 8259","role":"system"},{"content":"We have a rust crate named 'bitcoin-serialize' 0.1.19. \n\nHere is the interface:\n/**\n| Mode for encoding VarInts.\n| \n| Currently there is no support for signed\n| encodings. The default mode will not\n| compile with signed values, and the\n| legacy \"nonnegative signed\" mode will\n| accept signed values, but improperly\n| encode and decode them if they are negative.\n| In the future, the Default mode could\n| be extended to support negative numbers\n| in a backwards compatible way, and additional\n| modes could be added to support different\n| varint formats (e.g. zigzag encoding).\n|\n*/\n#[derive(Clone,Debug,ConstParamTy,PartialEq,Eq)]\npub enum VarIntMode {\n    Default,\n    NonNegativeSigned,\n}\n\npub trait ModeConstraint<const M: VarIntMode, I> {}\n\n\npub trait BtcSerialize<Stream> {\n    fn serialize(&self, s: &mut Stream);\n}\n\n\n/// **Common interface implemented by every formatter.**\n///\n/// A formatter is responsible for writing a value of type `T` to a\n/// byte‑stream (`ser`) and reading it back (`unser`).  This is the glue\n/// that lets the `Wrapper` and `VectorFormatter` compose formatters in a\n/// type‑safe way.\npub trait ValueFormatter<T> {\n    fn ser<S: Write>(&mut self, s: &mut S, value: &T);\n    fn unser<S: Read>(&mut self, s: &mut S, value: &mut T);\n}\n\n\npub trait True {}\n\n\n/// Replace the previous definition (which took `&self`) with a\n/// mutable‐reference API so implementations can actually write the\n/// value that has just been read from the stream.\npub trait BtcUnserialize<Stream> {\n    fn unserialize(&mut self, s: &mut Stream);\n}\n\n\n/// Trait to provide a blanket implementation for tuples up to a\n/// reasonable arity (here 4 – extend if needed).\npub trait SerializeMany<Stream> {\n    fn serialize_many(&self, s: &mut Stream);\n}\n\n\n/// Mirror of `SerializeMany` for reading.\npub trait UnserializeMany<Stream> {\n    fn unserialize_many(&mut self, s: &mut Stream);\n}\n\n/// Convenience alias: always big‑endian.\npub type BigEndianFormatter<const BYTES: i32> = CustomUintFormatter<BYTES, true>;\n\nmacro_rules! ternary { {\n    ($condition:expr,$if_true:expr,$if_false:expr) => {\n        match $condition {\n            true => $if_true,\n            false => $if_false,\n        }\n    }\n} }\n\n\n#[macro_export]\nmacro_rules! varint_mode { {\n    ($obj:expr, $mode:ident) => {\n        $crate::var_int_formatter::VarIntFormatter::<{\n            $crate::var_int_mode::VarIntMode::$mode\n        }>::new($obj)\n    };\n} }\n\n\n#[macro_export]\nmacro_rules! varint { {\n    ($obj:expr) => {\n        $crate::var_int_formatter::VarIntFormatter::<{\n            $crate::var_int_mode::VarIntMode::Default\n        }>::new($obj)\n    };\n} }\n\n\n#[macro_export]\nmacro_rules! compactsize { {\n    ($obj:expr) => {\n        $crate::compact_size_formatter::CompactSizeFormatter::<true>::new($obj)\n    };\n} }\n\n\n#[macro_export]\nmacro_rules! limited_string { {\n    ($obj:expr, $n:ident) => {\n        $crate::limited_string_formatter::LimitedStringFormatter::<$n> { item: $obj }\n    };\n} }\n\n\n#[macro_export]\nmacro_rules! __impl_read_or_write { {\n    ($s:expr, $marker:expr, $tuple_mut:expr, $tuple_const:expr) => {{\n        if $marker.for_read() {\n            /* read‑phase → forward **mutable** tuple */\n            $crate::many::ser_read_write_many_with_action_unserialize(\n                $s,\n                $crate::action::SerActionUnserialize {},\n                &mut $tuple_mut,\n            )\n        } else {\n            /* write‑phase → forward **immutable** tuple */\n            $crate::many::ser_read_write_many_with_action_serialize(\n                $s,\n                $crate::action::SerActionSerialize {},\n                &$tuple_const,\n            )\n        }\n    }};\n} }\n\n\n#[macro_export]\nmacro_rules! readwrite { {\n    ( $s:expr, $marker:expr, $( $elem:expr ),* $(,)? ) => {{\n        // One tuple – may itself contain mutable references\n        let mut __rw_tuple = ( $( $elem ),* );\n\n        if $marker.for_read() {\n            /* read phase -------------------------------------------------- */\n            $crate::many::ser_read_write_many_with_action_unserialize(\n                $s,\n                $crate::action::SerActionUnserialize {},\n                &mut __rw_tuple,\n            )\n        } else {\n            /* write phase ------------------------------------------------- */\n            $crate::many::ser_read_write_many_with_action_serialize(\n                $s,\n                $crate::action::SerActionSerialize {},\n                &__rw_tuple,       // immutable borrow is enough\n            )\n        }\n    }};\n} }\n\n\n#[macro_export]\nmacro_rules! readwriteas { {\n    ( $s:expr, $marker:expr, $ty:ty, $obj:expr ) => {{\n        let mut __tmp: $ty = unsafe { core::mem::transmute_copy(&$obj) };\n        readwrite!($s, $marker, __tmp);\n        $obj = unsafe { core::mem::transmute_copy(&__tmp) };\n    }};\n} }\n\n\n#[macro_export]\nmacro_rules! ser_read { {\n    ( $s:expr, $marker:expr, $obj:expr, |$stm:ident, $val:ident| $body:block ) => {{\n        $crate::read_write::ser_read($s, $marker, $obj, |$stm, mut $val| $body)\n    }};\n} }\n\n\n#[macro_export]\nmacro_rules! ser_write { {\n    ( $s:expr, $marker:expr, $obj:expr, |$stm:ident, $val:ident| $body:block ) => {{\n        $crate::read_write::ser_write_with_action_serialize(\n            $s,\n            $marker,\n            $obj,\n            |$stm, $val| $body,\n        )\n    }};\n} }\n\n\n/**\n| Implement the Ser and Unser methods\n| needed for implementing a formatter\n| (see Using below).\n| \n| Both Ser and Unser are delegated to a\n| single static method SerializationOps,\n| which is polymorphic in the serialized/deserialized\n| type (allowing it to be const when serializing,\n| and non-const when deserializing).\n| Example use:\n| -----------\n| @code\n| struct FooFormatter {\n|   FORMATTER_METHODS(Class, obj) { READWRITE(obj.val1, VARINT(obj.val2)); }\n| }\n|\n| would define a class FooFormatter that\n| defines a serialization of Class objects\n| consisting of serializing its val1\n| member using the default serialization,\n| and its val2 member using\n| VARINT serialization. That FooFormatter\n| can then be used in statements like\n| READWRITE(Using<FooFormatter>(obj.bla)).\n*/\n#[macro_export]\nmacro_rules! formatter_methods { {\n    ($cls:ident, $obj:ident) => {\n        fn ser<Stream: std::io::Write>(&self, s: &mut Stream) {\n            Self::serialization_ops(self, s, $crate::action::SerActionSerialize {})\n        }\n        fn unser<Stream: std::io::Read>(&mut self, s: &mut Stream) {\n            Self::serialization_ops(self, s, $crate::action::SerActionUnserialize {})\n        }\n        fn serialization_ops<Stream, Op>(\n            &mut self,\n            s: &mut Stream,\n            ser_action: Op,\n        ) where\n            Stream: std::io::Read + std::io::Write,\n            Op: crate::action::SerActionSerialize + crate::action::SerActionUnserialize,\n        {\n            let $obj = self;\n            // user‑supplied body follows the macro invocation\n        }\n    };\n} }\n\n\n/**\n| Implement the BtcSerialize and BtcUnserialize\n| methods by delegating to a single templated\n| static method that takes the to-be-(de)serialized\n| object as a parameter.\n| \n| This approach has the advantage that\n| the constness of the object becomes\n| a template parameter, and thus allows\n| a single implementation that sees the\n| object as const for serializing and\n| non-const for deserializing, without\n| casts.\n|\n*/\n#[macro_export]\nmacro_rules! serialize_methods { {\n    ($cls:ident, $obj:ident) => {\n        impl<Stream: std::io::Write> $crate::serialize::BtcSerialize<Stream> for $cls {\n            fn serialize(&self, s: &mut Stream) {\n                let mut me = self.clone();\n                me.ser(s);\n            }\n        }\n        impl<Stream: std::io::Read> $crate::unserialize::BtcUnserialize<Stream> for $cls {\n            fn unserialize(&mut self, s: &mut Stream) {\n                self.unser(s);\n            }\n        }\n    };\n} }\n\n/**\n| Support for SERIALIZE_METHODS and\n| READWRITE macro.\n|\n*/\npub struct SerActionSerialize  { }\n\n\npub struct SerActionUnserialize  { }\n\n\n/**\n| Serialization wrapper class for integers\n| in VarInt format.\n|\n*/\npub struct VarIntFormatter<const Mode: VarIntMode>  { }\n\n\npub struct CheckVarIntMode<const Mode: VarIntMode>  { }\n\n\n/// Bit-exact IEEE-754 `f64` serializer used by Core:\n/// writes the raw `u64` payload **little-endian**.\n#[derive(Default, Copy, Clone)]\npub struct EncodedDoubleFormatter  ;\n\n\n/// Format a collection (`Vec<T>` or any [`Vec`]‑like wrapper) whose **elements**\n/// must themselves be (de)serialised with a dedicated formatter `F`.\n///\n/// This mirrors Bitcoin Core’s original implementation, including the 5 MiB\n/// incremental allocation safeguard against OOM‑DoS vectors.\npub struct VectorFormatter<F>  {\n    _marker: PhantomData<fn() -> F>,\n}\n\n\n/// Wrapper that forces (de)serialisation of the enclosed object to go\n/// through a user‑supplied `Formatter`.\n///\n/// Construct via [`using`](crate::serialize::using).\npub struct Wrapper<'a, F, T>  {\n    object:  &'a mut T,\n    _marker: PhantomData<F>,\n}\n\n\npub struct If<const B: bool>  ;\n\n\n/**\n| Formatter for integers in CompactSize\n| format.\n|\n*/\npub struct CompactSizeFormatter<const RangeCheck: bool>  { }\n\n\n/// Default formatter. Serializes objects as themselves.\n/// \n/// The vector/prevector serialization code passes this to VectorFormatter to enable reusing that\n/// logic. \n///\n/// It shouldn't be needed elsewhere.\n#[derive(Default)]\npub struct DefaultFormatter  ;\n\n\n/**\n| **CustomUintFormatter**\n|\n| A generic formatter for fixed‑width unsigned\n| integers and C‑style enums.  It supports:\n| * **BYTES** – number of encoded bytes\n|   (compile‑time range‑checked: 1 – 8);\n| * **BIG_ENDIAN** – endianness (default:\n|   little‑endian = `false`; set `true`\n|   for network / big‑endian order).\n| The value is range‑checked against the\n| maximum representable with the chosen\n| width before serialisation and after\n| deserialisation.\n*/\npub struct CustomUintFormatter<const BYTES: i32, const BIG_ENDIAN: bool = false>  ;\n\n\n/// Count‑only stream used by `GetSerializeSize`.\n///\n/// ::GetSerializeSize implementations\n/// \n/// Computing the serialized size of objects is done through a special stream object of type\n/// CSizeComputer, which only records the number of bytes written to it.\n/// If your Serialize or SerializationOp method has non-trivial overhead for serialization, it may\n/// be worthwhile to implement a specialized version for\n/// CSizeComputer, which uses the s.seek() method to record bytes that would be written instead.\npub struct SizeComputer  {\n    n_size:    usize,\n    n_version: i32,\n}\n\n\n///-------------------------------\npub struct LimitedStringFormatter<'a, const Limit: usize>  {\n    item: &'a mut String,\n}\n\n/// Execute a *read* operation (`fn_`) during a **serialize** phase.  \n/// Exists for parity with the C++ helpers; the closure performs the\n/// actual work.\n#[inline]\npub fn ser_read_with_action_serialize<Stream, T, F>(\n    s:           &mut Stream,\n    _ser_action: SerActionSerialize,\n    obj:         T,\n    fn_:         F\n) where\n    Stream: Write,\n    F: FnOnce(&mut Stream, T)\n{\n    trace!(\"ser_read_with_action_serialize\");\n    fn_(s, obj);\n}\n\n\n/// Execute a *read* operation (`fn_`) during an **unserialize** phase.\n#[inline]\npub fn ser_read<Stream, T, F>(\n    s:           &mut Stream,\n    _ser_action: SerActionUnserialize,\n    obj:         T,\n    fn_:         F\n) where\n    Stream: Read,\n    F: FnOnce(&mut Stream, T)\n{\n    trace!(\"ser_read\");\n    fn_(s, obj);\n}\n\n\n/// Execute a *write* operation (`fn_`) during a **serialize** phase.\n#[inline]\npub fn ser_write_with_action_serialize<Stream, T, F>(\n    s:           &mut Stream,\n    _ser_action: SerActionSerialize,\n    obj:         T,\n    fn_:         F\n) where\n    Stream: Write,\n    F: FnOnce(&mut Stream, T)\n{\n    trace!(\"ser_write_with_action_serialize\");\n    fn_(s, obj);\n}\n\n\n/// Execute a *write* operation (`fn_`) during an **unserialize** phase.  \n/// This is typically a no‑op but is defined for completeness.\n#[inline]\npub fn ser_write_with_action_unserialize<Stream, T, F>(\n    _s:          &mut Stream,\n    _ser_action: SerActionUnserialize,\n    _obj:        T,\n    _fn_:        F\n) where\n    Stream: Read,\n    F: FnOnce(&mut Stream, T)\n{\n    trace!(\"ser_write_with_action_unserialize (noop)\");\n}\n\n\npub fn get_serialize_size<T>(t: &T, n_version: Option<i32>) -> usize where T: BtcSerialize<crate::size_computer::SizeComputer>\n{\n    let n_version: i32 = n_version.unwrap_or(0);\n    (SizeComputer::new(n_version) << t).size()\n}\n\n\n/// Compute the combined serialised size of an arbitrary tuple of values.\n///\n/// ```ignore\n/// let sz = get_serialize_size_many(0, &(header, tx_count, &txs[..]));\n/// ```\npub fn get_serialize_size_many<Args>(n_version: i32, args: &Args) -> usize where\n    Args: SerializeMany<SizeComputer>\n{\n    let mut sc = SizeComputer::new(n_version);\n    args.serialize_many(&mut sc);\n    sc.size()\n}\n\n\n#[inline]\npub fn write_u32_le<W: Write>(w: &mut W, v: u32) -> IoResult<()> {\n    w.write_all(&v.to_le_bytes())\n}\n\n\n#[inline]\npub fn read_u32_le<R: Read>(r: &mut R) -> IoResult<u32> {\n    let mut buf = [0u8; 4];\n    r.read_exact(&mut buf)?;\n    Ok(u32::from_le_bytes(buf))\n}\n\n\n#[inline]\npub fn write_encoded_f64<W: Write>(w: &mut W, v: f64) -> IoResult<()> {\n    let bits = v.to_bits();\n    w.write_all(&bits.to_be_bytes())\n}\n\n\n#[inline]\npub fn read_encoded_f64<R: Read>(r: &mut R) -> IoResult<f64> {\n    let mut buf = [0u8; 8];\n    r.read_exact(&mut buf)?;\n    let bits = u64::from_be_bytes(buf);\n    Ok(f64::from_bits(bits))\n}\n\n\n/**\n| Safely convert odd char pointer types\n| to standard ones.\n|\n*/\n#[inline]\npub fn char_cast(c: *mut u8) -> *mut u8 {\n    trace!(pointer = ?c, \"char_cast\");\n    c\n}\n\n\n#[inline]\npub fn encode_double(v: f64) -> u64 {\n    v.to_bits() \n}\n\n\n#[inline]\npub fn decode_double(x: u64) -> f64 {\n    f64::from_bits(x) \n}\n\n\npub fn write_vec_f64_fmt<S: Write>(s: &mut S, v: &Vec<f64>) {\n    let mut vf = VectorFormatter::<EncodedDoubleFormatter>::default();\n    vf.ser(s, v);\n}\n\n\npub fn read_vec_f64_fmt<S: Read>(s: &mut S) -> Vec<f64> {\n    let mut vf = VectorFormatter::<EncodedDoubleFormatter>::default();\n    let mut out = Vec::<f64>::default();\n    vf.unser(s, &mut out);\n    out\n}\n\n\npub fn write_matrix_f64_fmt<S: Write>(s: &mut S, m: &Vec<Vec<f64>>) {\n    let mut mf = VectorFormatter::<VectorFormatter<EncodedDoubleFormatter>>::default();\n    mf.ser(s, m);\n}\n\n\npub fn read_matrix_f64_fmt<S: Read>(s: &mut S) -> Vec<Vec<f64>> {\n    let mut mf = VectorFormatter::<VectorFormatter<EncodedDoubleFormatter>>::default();\n    let mut out = Vec::<Vec<f64>>::default();\n    mf.unser(s, &mut out);\n    out\n}\n\n\n/// Construct a `Wrapper` that forces (de)serialisation of `t` to go\n/// through the given `Formatter`.\n///\n/// This mirrors Bitcoin Core’s `Using<Formatter>(obj)` helper.\n/// Cause serialization/deserialization of an object to be done using a specified formatter class.\n/// \n/// To use this, you need a class Formatter that has public functions Ser(stream, const object&)\n/// for serialization, and Unser(stream, object&) for deserialization. Serialization routines\n/// (inside\n/// READWRITE, or directly with << and >> operators), can then use Using<Formatter>(object).\n/// This works by constructing a Wrapper<Formatter, T>-wrapped version of object, where T is const\n/// during serialization, and non-const during deserialization, which maintains const correctness.\n/// Helper identical in spirit to Bitcoin Core’s `Using<Formatter>(obj)`.\n/// ```ignore\n/// let mut value = 42u64;\n/// stream << using::<VarIntFormatter<VarIntMode::Default>, _>(&mut value);\n/// ```\n#[inline]\npub fn using<'a, F, T>(t: &'a mut T) -> Wrapper<'a, F, T> {\n    Wrapper::new(t)\n}\n\n\n/**\n| Compact Size\n| \n| Size < 253 -- 1 byte\n| Size <= USHRT_MAX -- 3 bytes (253 + 2 bytes)\n| Size <= UINT_MAX -- 5 bytes (254 + 4 bytes)\n| Size > UINT_MAX -- 9 bytes (255 + 8 bytes)\n|\n*/\n#[inline]\npub fn get_size_of_compact_size(n_size: u64) -> u32 {\n    let sz = if n_size < 253 {\n        1\n    } else if n_size <= u16::MAX as u64 {\n        1 + 2\n    } else if n_size <= u32::MAX as u64 {\n        1 + 4\n    } else {\n        1 + 8\n    };\n    trace!(n_size, sz, \"get_size_of_compact_size\");\n    sz\n}\n\n\npub fn write_compact_size<Stream: Write>(os: &mut Stream, n_size: u64) {\n    trace!(n_size, \"write_compact_size → start\");\n    if n_size < 253 {\n        ser_writedata8(os, n_size as u8);\n    } else if n_size <= u16::MAX as u64 {\n        ser_writedata8(os, 253);\n        ser_writedata16(os, n_size as u16);\n    } else if n_size <= u32::MAX as u64 {\n        ser_writedata8(os, 254);\n        ser_writedata32(os, n_size as u32);\n    } else {\n        ser_writedata8(os, 255);\n        ser_writedata64(os, n_size);\n    }\n    trace!(\"write_compact_size → done\");\n}\n\n\n/**\n| Decode a CompactSize-encoded variable-length\n| integer.\n| \n| As these are primarily used to encode\n| the size of vector-like serializations,\n| by default a range check is performed.\n| When used as a generic number encoding,\n| range_check should be set to false.\n|\n*/\npub fn read_compact_size<Stream: Read>(is: &mut Stream, range_check: Option<bool>) -> u64 {\n    let range_check = range_check.unwrap_or(true);\n    let ch_size = ser_readdata8(is);\n    let mut n_size_ret: u64 = match ch_size {\n        0..=252 => ch_size as u64,\n        253 => {\n            let v = ser_readdata16(is) as u64;\n            if v < 253 {\n                error!(\"non‑canonical CompactSize (ch=253)\");\n                panic!(\"non‑canonical ReadCompactSize()\");\n            }\n            v\n        }\n        254 => {\n            let v = ser_readdata32(is) as u64;\n            if v < 0x10000 {\n                error!(\"non‑canonical CompactSize (ch=254)\");\n                panic!(\"non‑canonical ReadCompactSize()\");\n            }\n            v\n        }\n        _ => {\n            let v = ser_readdata64(is);\n            if v < 0x1_0000_0000 {\n                error!(\"non‑canonical CompactSize (ch=255)\");\n                panic!(\"non‑canonical ReadCompactSize()\");\n            }\n            v\n        }\n    };\n\n    if range_check && n_size_ret > MAX_SIZE {\n        error!(n_size_ret, \"CompactSize exceeds MAX_SIZE\");\n        panic!(\"ReadCompactSize(): size too large\");\n    }\n\n    trace!(n_size_ret, \"read_compact_size\");\n    n_size_ret\n}\n\n\n/**\n| Convert the reference base type to X,\n| without changing constness or reference\n| type.\n|\n*/\npub fn read_write_as_helper<X>(x: &mut X) -> &mut X {\n    x\n}\n\n\n/**\n| Lowest-level serialization and conversion.\n| \n| -----------\n| @note\n| Sizes of these types are verified in\n| the tests\n|\n*/\n#[inline]\npub fn ser_writedata8<Stream: Write>(s: &mut Stream, obj: u8) {\n    trace!(value = obj, \"ser_writedata8\");\n    s.write_all(&[obj])\n        .expect(\"I/O error while writing u8\");\n}\n\n\n#[inline]\npub fn ser_writedata16<Stream: Write>(s: &mut Stream, obj: u16) {\n    trace!(value = obj, \"ser_writedata16 (LE)\");\n    s.write_all(&obj.to_le_bytes())\n        .expect(\"I/O error while writing u16\");\n}\n\n\n#[inline]\npub fn ser_writedata_16be<Stream: Write>(s: &mut Stream, obj: u16) {\n    trace!(value = obj, \"ser_writedata_16be (BE)\");\n    s.write_all(&obj.to_be_bytes())\n        .expect(\"I/O error while writing u16‑be\");\n}\n\n\n#[inline]\npub fn ser_writedata32<Stream: Write>(s: &mut Stream, obj: u32) {\n    trace!(value = obj, \"ser_writedata32 (LE)\");\n    s.write_all(&obj.to_le_bytes())\n        .expect(\"I/O error while writing u32\");\n}\n\n\n#[inline]\npub fn ser_writedata_32be<Stream: Write>(s: &mut Stream, obj: u32) {\n    trace!(value = obj, \"ser_writedata_32be (BE)\");\n    s.write_all(&obj.to_be_bytes())\n        .expect(\"I/O error while writing u32‑be\");\n}\n\n\n#[inline]\npub fn ser_writedata64<Stream: Write>(s: &mut Stream, obj: u64) {\n    trace!(value = obj, \"ser_writedata64 (LE)\");\n    s.write_all(&obj.to_le_bytes())\n        .expect(\"I/O error while writing u64\");\n}\n\n\n#[inline]\npub fn ser_readdata8<Stream: Read>(s: &mut Stream) -> u8 {\n    let mut buf = [0u8; 1];\n    s.read_exact(&mut buf).expect(\"I/O error while reading u8\");\n    let v = buf[0];\n    trace!(value = v, \"ser_readdata8\");\n    v\n}\n\n\n#[inline]\npub fn ser_readdata16<Stream: Read>(s: &mut Stream) -> u16 {\n    let mut buf = [0u8; 2];\n    s.read_exact(&mut buf).expect(\"I/O error while reading u16\");\n    let v = u16::from_le_bytes(buf);\n    trace!(value = v, \"ser_readdata16 (LE)\");\n    v\n}\n\n\n#[inline]\npub fn ser_readdata_16be<Stream: Read>(s: &mut Stream) -> u16 {\n    let mut buf = [0u8; 2];\n    s.read_exact(&mut buf).expect(\"I/O error while reading u16‑be\");\n    let v = u16::from_be_bytes(buf);\n    trace!(value = v, \"ser_readdata_16be (BE)\");\n    v\n}\n\n\n#[inline]\npub fn ser_readdata32<Stream: Read>(s: &mut Stream) -> u32 {\n    let mut buf = [0u8; 4];\n    s.read_exact(&mut buf).expect(\"I/O error while reading u32\");\n    let v = u32::from_le_bytes(buf);\n    trace!(value = v, \"ser_readdata32 (LE)\");\n    v\n}\n\n\n#[inline]\npub fn ser_readdata_32be<Stream: Read>(s: &mut Stream) -> u32 {\n    let mut buf = [0u8; 4];\n    s.read_exact(&mut buf).expect(\"I/O error while reading u32‑be\");\n    let v = u32::from_be_bytes(buf);\n    trace!(value = v, \"ser_readdata_32be (BE)\");\n    v\n}\n\n\n#[inline]\npub fn ser_readdata64<Stream: Read>(s: &mut Stream) -> u64 {\n    let mut buf = [0u8; 8];\n    s.read_exact(&mut buf).expect(\"I/O error while reading u64\");\n    let v = u64::from_le_bytes(buf);\n    trace!(value = v, \"ser_readdata64 (LE)\");\n    v\n}\n\n\npub fn inclusive_range_1_to_8<const Bytes: i32>() -> bool {\n    Bytes > 0 && Bytes <= 8 \n}\n\n\n#[inline]\npub fn get_size_of_var_int<I, const Mode: VarIntMode>(mut n: I) -> u32 where\n    (): ModeConstraint<Mode, I>,\n    I: Into<u128> + Copy\n{\n    let mut n128: u128 = n.into();\n    let mut count = 1;\n    while n128 > 0x7F {\n        n128 = (n128 >> 7) - 1;\n        count += 1;\n    }\n    count\n}\n\n\npub fn write_var_int<Stream, I, const Mode: VarIntMode>(os: &mut Stream, n: I) where\n    (): ModeConstraint<Mode, I>,\n    Stream: Write,\n    I: Into<u128> + Copy\n{\n    let mut val: u128 = n.into();\n    let mut bytes = Vec::<u8>::new();\n\n    loop {\n        bytes.push(((val & 0x7F) as u8) | if bytes.is_empty() { 0 } else { 0x80 });\n        if val <= 0x7F { break; }\n        val = (val >> 7) - 1;\n    }\n    for b in bytes.iter().rev() { ser_writedata8(os, *b); }\n}\n\n\npub fn read_var_int<Stream, I, const Mode: VarIntMode>(is: &mut Stream) -> I where\n    (): ModeConstraint<Mode, I>,\n    Stream: Read,\n    I: TryFrom<u128>,\n    <I as TryFrom<u128>>::Error: core::fmt::Debug\n{\n    let mut n: u128 = 0;\n    loop {\n        let ch = ser_readdata8(is);\n        if n > (u128::MAX >> 7) { panic!(\"ReadVarInt(): size too large\"); }\n        n = (n << 7) | u128::from(ch & 0x7F);\n        if ch & 0x80 != 0 {\n            if n == u128::MAX { panic!(\"ReadVarInt(): size too large\"); }\n            n += 1;\n        } else {\n            break;\n        }\n    }\n    I::try_from(n).expect(\"ReadVarInt(): value does not fit target type\")\n}\n\n\n#[inline]\npub fn write_compact_size_with_size_computer(s: &mut SizeComputer, n_size: u64) {\n    let sz = get_size_of_compact_size(n_size);\n    trace!(bytes = sz, \"write_compact_size_with_size_computer\");\n    s.seek(sz as usize);\n}\n\n\n#[inline]\npub fn write_var_int_with_size_computer<I>(s: &mut SizeComputer, n: I) where\n    I: Into<u128> + Copy,\n    (): ModeConstraint<{ VarIntMode::Default }, I>\n{\n    let sz = get_size_of_var_int::<I, { VarIntMode::Default }>(n);\n    trace!(bytes = sz, \"write_var_int_with_size_computer\");\n    s.seek(sz as usize);\n}\n\n\n/**\n| Map a value x that is uniformly distributed in\n| the range [0, 2^64) to a value uniformly\n| distributed in [0, n) by returning the upper 64\n| bits of x * n.\n|\n| See:\n| https://lemire.me/blog/2016/06/27/a-fast-alternative-to-the-modulo-reduction/\n*/\npub fn map_into_range(x: u64, n: u64) -> u64 {\n    #[cfg(__SIZEOF_INT128__)]\n    {\n        return (x as u128 * n as u128) >> 64;\n    }\n\n    // To perform the calculation on 64-bit\n    // numbers without losing the result to\n    // overflow, split the numbers into the\n    // most significant and least significant\n    // 32 bits and perform multiplication\n    // piece-wise.\n    //\n    // See:\n    // https://stackoverflow.com/a/26855440\n    let x_hi:    u64 = x >> 32;\n    let x_lo:    u64 = x & 0xFFFFFFFF;\n    let n_hi:    u64 = n >> 32;\n    let n_lo:    u64 = n & 0xFFFFFFFF;\n    let ac:      u64 = x_hi * n_hi;\n    let ad:      u64 = x_hi * n_lo;\n    let bc:      u64 = x_lo * n_hi;\n    let bd:      u64 = x_lo * n_lo;\n    let mid34:   u64 = (bd >> 32) + (bc & 0xFFFFFFFF) + (ad & 0xFFFFFFFF);\n    let upper64: u64 = ac + (bc >> 32) + (ad >> 32) + (mid34 >> 32);\n\n    upper64\n}\n\n\n/// Base case – nothing to serialise.\n#[inline]\npub fn serialize_many_base<Stream>(_s: &mut Stream) {}\n\n\n/// Serialise the first argument, then recurse.  This emulates the C++\n/// variadic template `SerializeMany`.\npub fn serialize_many<Stream, A, Rest>(s: &mut Stream, arg: &A, rest: &Rest) where\n    Stream: Write,\n    A: BtcSerialize<Stream>,\n    Rest: SerializeMany<Stream>\n{\n    arg.serialize(s);\n    rest.serialize_many(s);\n}\n\n\n/// Base case for unserialisation.\n#[inline]\npub fn unserialize_many_base<Stream>(_s: &mut Stream) {}\n\n\n/// Unserialise the first argument, then recurse.\n#[inline]\npub fn unserialize_many<Stream, A, Rest>(s: &mut Stream, arg: &mut A, rest: &mut Rest) where\n    Stream: Read,\n    A: BtcUnserialize<Stream>,\n    Rest: UnserializeMany<Stream>\n{\n    arg.unserialize(s);\n    rest.unserialize_many(s);\n}\n\n\n#[inline]\npub fn ser_read_write_many_with_action_serialize<Stream, T>(s: &mut Stream, _act: SerActionSerialize, args: &T) where\n    Stream: Write,\n    T: SerializeMany<Stream>\n{\n    trace!(\"ser_read_write_many_with_action_serialize\");\n    args.serialize_many(s);\n}\n\n\n#[inline]\npub fn ser_read_write_many_with_action_unserialize<Stream, T>(s: &mut Stream, _act: SerActionUnserialize, args: &mut T) where\n    Stream: Read,\n    T: UnserializeMany<Stream>\n{\n    trace!(\"ser_read_write_many_with_action_unserialize\");\n    args.unserialize_many(s);\n}\n\nimpl SerActionSerialize {\n\n    /// `Serialize`‐phase marker – always **false** because we are _writing_.\n    #[inline]\n    pub fn for_read(&self) -> bool {\n        trace!(\"SerActionSerialize::for_read -> false\");\n        false\n    }\n}\n\nimpl SerActionUnserialize {\n\n    /// `BtcUnserialize`‐phase marker – always **true** because we are _reading_.\n    #[inline]\n    pub fn for_read(&self) -> bool {\n        trace!(\"SerActionUnserialize::for_read -> true\");\n        true\n    }\n}\n\nimpl<const Mode: VarIntMode> VarIntFormatter<Mode> {\n\n    /// Helper used by the `varint_mode!` / `varint!` macros:\n    ///\n    /// ```ignore\n    /// READWRITE(varint!(nVersion));\n    /// ```\n    /// Returns a [`Wrapper`] tying the supplied `item` to this formatter so\n    /// it can be fed directly into the usual `READWRITE` / `Serialize`\n    /// machinery.\n    #[inline]\n    pub fn new<'a, T>(item: &'a mut T) -> crate::wrapper::Wrapper<'a, Self, T> {\n        crate::wrapper::Wrapper::new(item)\n    }\n}\n\nimpl<const Mode: VarIntMode> Default for VarIntFormatter<Mode> {\n\n    #[inline]\n    fn default() -> Self {\n        Self {}\n    }\n}\n\nimpl<const Mode: VarIntMode, I> ValueFormatter<I> for VarIntFormatter<Mode> where\n    (): ModeConstraint<Mode, I>,\n    I: Into<u128>\n        + Copy\n        + From<u8>\n        + TryInto<u128>\n        + TryFrom<u128>\n        + std::fmt::Debug\n        + Default,\n    <I as TryFrom<u128>>::Error: std::fmt::Debug {\n\n    #[inline]\n    fn ser<S: Write>(&mut self, s: &mut S, value: &I) {\n        write_var_int::<S, I, Mode>(s, *value);\n    }\n\n    #[inline]\n    fn unser<S: Read>(&mut self, s: &mut S, value: &mut I) {\n        *value = read_var_int::<S, I, Mode>(s);\n    }\n}\n\nimpl<I: Unsigned> ModeConstraint<{ VarIntMode::Default }, I> for () {}\n\nimpl<I: Signed> ModeConstraint<{ VarIntMode::NonNegativeSigned }, I> for () {}\n\nimpl<const Mode: VarIntMode> CheckVarIntMode<Mode> {\n\n    #[inline]\n    pub fn new<I>() -> Self where\n            (): ModeConstraint<Mode, I>\n    {\n        trace!(\"CheckVarIntMode<Mode={:?}, I={}>\", Mode, std::any::type_name::<I>());\n        Self {}\n    }\n}\n\nimpl EncodedDoubleFormatter {\n\n    #[inline]\n    pub fn ser_stream<S: Write>(&mut self, s: &mut S, v: f64) {\n        let enc = encode_double(v).to_le_bytes();\n        s.write_all(&enc).expect(\"write f64-encoded u64\");\n    }\n\n    #[inline]\n    pub fn unser_stream<S: Read>(&mut self, s: &mut S, v: &mut f64) {\n        let mut buf = [0u8; core::mem::size_of::<u64>()];\n        s.read_exact(&mut buf).expect(\"read f64-encoded u64\");\n        let encoded = u64::from_le_bytes(buf);\n        *v = decode_double(encoded);\n    }\n}\n\nimpl ValueFormatter<f64> for EncodedDoubleFormatter {\n\n    #[inline]\n    fn ser<S: Write>(&mut self, s: &mut S, v: &f64) {\n        self.ser_stream(s, *v);\n    }\n\n    #[inline]\n    fn unser<S: Read>(&mut self, s: &mut S, v: &mut f64) {\n        self.unser_stream(s, v);\n    }\n}\n\nimpl<F> Default for VectorFormatter<F> {\n\n    #[inline]\n    fn default() -> Self {\n        Self {\n            _marker: PhantomData,\n        }\n    }\n}\n\nimpl<F, T> ValueFormatter<Vec<T>> for VectorFormatter<F> where\n    F: ValueFormatter<T> + Default,\n    T: Default {\n\n    fn ser<S: Write>(&mut self, s: &mut S, v: &Vec<T>) {\n        trace!(len = v.len(), \"VectorFormatter::ser\");\n        write_compact_size(s, v.len() as u64);\n    \n        let mut fmt = F::default();\n        for elem in v {\n            fmt.ser(s, elem);\n        }\n    }\n\n    fn unser<S: Read>(&mut self, s: &mut S, v: &mut Vec<T>) {\n        v.clear();\n        let total = read_compact_size(s, Some(true)) as usize;\n        trace!(expected = total, \"VectorFormatter::unser → begin\");\n    \n        let mut fmt = F::default();\n        let mut read_elems = 0usize;\n        while read_elems < total {\n            // Allocate in ≤ 5 MiB blocks to avoid unbounded allocations.\n            let elems_per_block =\n                1 + (MAX_VECTOR_ALLOCATE as usize - 1) / std::mem::size_of::<T>();\n            let blk = std::cmp::min(total - read_elems, elems_per_block);\n    \n            v.reserve(blk);\n            for _ in 0..blk {\n                let mut elem = T::default();\n                fmt.unser(s, &mut elem);\n                v.push(elem);\n            }\n            read_elems += blk;\n        }\n    \n        trace!(actual = v.len(), \"VectorFormatter::unser → done\");\n    }\n}\n\nimpl<Stream> BtcSerialize<Stream> for i8 where\n    Stream: Write {\n\n    #[inline]\n    fn serialize(&self, s: &mut Stream) {\n        trace!(value = *self, \"serialize i8\");\n        ser_writedata8(s, *self as u8);\n    }\n}\n\nimpl<Stream> BtcSerialize<Stream> for u8 where\n    Stream: Write {\n\n    #[inline]\n    fn serialize(&self, s: &mut Stream) {\n        trace!(value = *self, \"serialize u8\");\n        ser_writedata8(s, *self);\n    }\n}\n\nimpl<Stream> BtcSerialize<Stream> for i16 where\n    Stream: Write {\n\n    #[inline]\n    fn serialize(&self, s: &mut Stream) {\n        trace!(value = *self, \"serialize i16\");\n        ser_writedata16(s, *self as u16);\n    }\n}\n\nimpl<Stream> BtcSerialize<Stream> for u16 where\n    Stream: Write {\n\n    #[inline]\n    fn serialize(&self, s: &mut Stream) {\n        trace!(value = *self, \"serialize u16\");\n        ser_writedata16(s, *self);\n    }\n}\n\nimpl<Stream> BtcSerialize<Stream> for i32 where\n    Stream: Write {\n\n    #[inline]\n    fn serialize(&self, s: &mut Stream) {\n        trace!(value = *self, \"serialize i32\");\n        ser_writedata32(s, *self as u32);\n    }\n}\n\nimpl<Stream> BtcSerialize<Stream> for u32 where\n    Stream: Write {\n\n    #[inline]\n    fn serialize(&self, s: &mut Stream) {\n        trace!(value = *self, \"serialize u32\");\n        ser_writedata32(s, *self);\n    }\n}\n\nimpl<Stream> BtcSerialize<Stream> for i64 where\n    Stream: Write {\n\n    #[inline]\n    fn serialize(&self, s: &mut Stream) {\n        trace!(value = *self, \"serialize i64\");\n        ser_writedata64(s, *self as u64);\n    }\n}\n\nimpl<Stream> BtcSerialize<Stream> for u64 where\n    Stream: Write {\n\n    #[inline]\n    fn serialize(&self, s: &mut Stream) {\n        trace!(value = *self, \"serialize u64\");\n        ser_writedata64(s, *self);\n    }\n}\n\nimpl<Stream, const N: usize> BtcSerialize<Stream> for [u8; N] where\n    Stream: Write {\n\n    #[inline]\n    fn serialize(&self, s: &mut Stream) {\n        trace!(len = N, \"serialize [u8; N]\");\n        s.write_all(self)\n            .expect(\"I/O error while writing fixed‑length byte array\");\n    }\n}\n\nimpl<Stream> BtcSerialize<Stream> for bool where\n    Stream: Write {\n\n    #[inline]\n    fn serialize(&self, s: &mut Stream) {\n        trace!(value = *self, \"serialize bool\");\n        ser_writedata8(s, if *self { 1 } else { 0 });\n    }\n}\n\nimpl<Stream> BtcSerialize<Stream> for String where\n    Stream: Write {\n\n    fn serialize(&self, os: &mut Stream) {\n        write_compact_size(os, self.len() as u64);\n        if !self.is_empty() {\n            os.write_all(self.as_bytes())\n                .expect(\"I/O error while writing String\");\n        }\n        trace!(len = self.len(), \"serialize String\");\n    }\n}\n\nimpl<Stream, T, const N: usize> BtcSerialize<Stream> for PreVector<T, N> where\n    Stream: Write,\n    T: Default + BtcSerialize<Stream> {\n\n    /// Serialise a `PreVector` by\n    /// 1. writing its length as a CompactSize,\n    /// 2. serialising every element with the\n    ///    element’s own `BtcSerialize` impl.\n    ///\n    /// The implementation matches the DoS‑safe\n    /// element‑by‑element strategy used for\n    /// `Vec<T>` above while preserving the\n    /// original fast‑path for fixed buffers.\n    #[inline]\n    fn serialize(&self, os: &mut Stream) {\n        write_compact_size(os, self.len() as u64);\n        trace!(\n            len       = self.len(),\n            capacity  = N,\n            \"serialize PreVector\"\n        );\n    \n        for elem in self.iter() {\n            BtcSerialize::<Stream>::serialize(elem, os);\n        }\n    }\n}\n\nimpl<Stream, T, A> BtcSerialize<Stream> for Vec<T, A> where\n    Stream: Write,\n    T: BtcSerialize<Stream>,\n    A: std::alloc::Allocator + Clone {\n\n    fn serialize(&self, os: &mut Stream) {\n        write_compact_size(os, self.len() as u64);\n        trace!(len = self.len(), \"serialize Vec\");\n    \n        for elem in self {\n            BtcSerialize::<Stream>::serialize(elem, os);\n        }\n    }\n}\n\nimpl<Stream, K, V> BtcSerialize<Stream> for (K, V) where\n    Stream: Write,\n    K: BtcSerialize<Stream>,\n    V: BtcSerialize<Stream> {\n\n    fn serialize(&self, os: &mut Stream) {\n        self.0.serialize(os);\n        self.1.serialize(os);\n        trace!(\"serialize (K,V) tuple\");\n    }\n}\n\nimpl<Stream, K, V, S> BtcSerialize<Stream> for HashMap<K, V, S> where\n    Stream: Write,\n    K: BtcSerialize<Stream>,\n    V: BtcSerialize<Stream>,\n    S: std::hash::BuildHasher {\n\n    fn serialize(&self, os: &mut Stream) {\n        write_compact_size(os, self.len() as u64);\n        trace!(len = self.len(), \"serialize HashMap\");\n        for (k, v) in self {\n            k.serialize(os);\n            v.serialize(os);\n        }\n    }\n}\n\nimpl<Stream, K, S> BtcSerialize<Stream> for HashSet<K, S> where\n    Stream: Write,\n    K: BtcSerialize<Stream>,\n    S: std::hash::BuildHasher {\n\n    fn serialize(&self, os: &mut Stream) {\n        write_compact_size(os, self.len() as u64);\n        trace!(len = self.len(), \"serialize HashSet\");\n        for key in self {\n            key.serialize(os);\n        }\n    }\n}\n\nimpl<Stream, T> BtcSerialize<Stream> for Box<T> where\n    Stream: Write,\n    T: BtcSerialize<Stream> + ?Sized {\n\n    fn serialize(&self, os: &mut Stream) {\n        (**self).serialize(os);\n        trace!(\"serialize Box<T>\");\n    }\n}\n\nimpl<Stream, T> BtcSerialize<Stream> for Arc<T> where\n    Stream: Write,\n    T: BtcSerialize<Stream> + ?Sized {\n\n    fn serialize(&self, os: &mut Stream) {\n        (**self).serialize(os);\n        trace!(\"serialize Arc<T>\");\n    }\n}\n\nimpl<Stream, T> BtcSerialize<Stream> for &T where\n    Stream: std::io::Write,\n    T: BtcSerialize<Stream> + ?Sized {\n\n    #[inline]\n    fn serialize(&self, s: &mut Stream) {\n        (*self).serialize(s);\n    }\n}\n\nimpl<Stream, T> BtcSerialize<Stream> for &mut T where\n    Stream: std::io::Write,\n    T: BtcSerialize<Stream> + ?Sized {\n\n    #[inline]\n    fn serialize(&self, s: &mut Stream) {\n        (**self).serialize(s);\n    }\n}\n\nimpl<'a, F, T> Wrapper<'a, F, T> {\n\n    #[inline]\n    pub fn new(object: &'a mut T) -> Self {\n        Self {\n            object,\n            _marker: PhantomData,\n        }\n    }\n}\n\nimpl<'a, F, T, S> BtcSerialize<S> for Wrapper<'a, F, T> where\n    S: Write,\n    F: ValueFormatter<T> {\n\n    #[inline]\n    fn serialize(&self, s: &mut S) {\n        trace!(\n            fmt = %std::any::type_name::<F>(),\n            \"Wrapper::serialize\"\n        );\n        let mut fmt = F::default();\n        fmt.ser(s, &*self.object);\n    }\n}\n\nimpl<'a, F, T, S> BtcUnserialize<S> for Wrapper<'a, F, T> where\n    S: Read,\n    F: ValueFormatter<T> {\n\n    #[inline]\n    fn unserialize(&mut self, s: &mut S) {\n        trace!(\n            fmt = %std::any::type_name::<F>(),\n            \"Wrapper::unserialize\"\n        );\n        let mut fmt = F::default();\n        fmt.unser(s, &mut *self.object);\n    }\n}\n\nimpl True for If<true> {}\n\nimpl<const RangeCheck: bool> CompactSizeFormatter<RangeCheck> {\n\n    /// Counterpart to `compactsize!` macro.\n    #[inline]\n    pub fn new<'a, T>(item: &'a mut T) -> crate::wrapper::Wrapper<'a, Self, T> {\n        crate::wrapper::Wrapper::new(item)\n    }\n}\n\nimpl<const RangeCheck: bool> Default for CompactSizeFormatter<RangeCheck> {\n\n    #[inline]\n    fn default() -> Self {\n        Self {}\n    }\n}\n\nimpl<const RangeCheck: bool, I> ValueFormatter<I> for CompactSizeFormatter<RangeCheck> where\n    I: Into<u64> + TryFrom<u64> + Copy + std::fmt::Debug,\n    <I as TryFrom<u64>>::Error: std::fmt::Debug {\n\n    fn ser<S: Write>(&mut self, s: &mut S, v: &I) {\n        write_compact_size(s, (*v).into());\n    }\n\n    fn unser<S: Read>(&mut self, s: &mut S, v: &mut I) {\n        let n = read_compact_size(s, Some(RangeCheck));\n        *v = I::try_from(n).expect(\"CompactSize exceeds type range\");\n    }\n}\n\nimpl<T: for<'a> BtcUnserialize<&'a mut dyn bitcoin_imports::Read> + for<'a> BtcSerialize<&'a mut dyn bitcoin_imports::Write> > ValueFormatter<T> for DefaultFormatter {\n\n    fn ser<S: std::io::Write>(&mut self, s: &mut S, value: &T) {\n        // Erase the concrete stream type `S`.\n        let mut sink: &mut dyn std::io::Write = s;\n    \n        // Use the impls that already exist for *any* `Stream: Write`.\n        BtcSerialize::<&mut dyn std::io::Write>::serialize(\n            value,\n            &mut sink,\n        );\n    }\n\n    fn unser<S: std::io::Read>(&mut self, s: &mut S, value: &mut T) {\n        let mut src: &mut dyn std::io::Read = s;\n    \n        BtcUnserialize::<&mut dyn std::io::Read>::unserialize(\n            value,\n            &mut src,\n        );\n    }\n}\n\nimpl<const BYTES: i32, const BIG_ENDIAN: bool> Default for CustomUintFormatter<BYTES, BIG_ENDIAN> {\n\n    #[inline]\n    fn default() -> Self {\n        Self\n    }\n}\n\nimpl<I, const BYTES: i32, const BIG_ENDIAN: bool> ValueFormatter<I> for CustomUintFormatter<BYTES, BIG_ENDIAN> where\n    /* Compile‑time guarantee: 1 ≤ BYTES ≤ 8 */\n    crate::meta::If<{ crate::meta::inclusive_range_1_to_8::<BYTES>() }>: crate::meta::True,\n    /* Conversion traits */\n    I: Copy + core::fmt::Debug + TryInto<u64> + TryFrom<u64>,\n    <I as TryInto<u64>>::Error: core::fmt::Debug,\n    <I as TryFrom<u64>>::Error: core::fmt::Debug {\n\n    #[inline]\n    fn ser<S: Write>(&mut self, s: &mut S, v: &I) {\n        let max: u64 = u64::MAX >> (8 * (8 - BYTES) as usize);/* width mask */\n    \n        let raw: u64 = (*v)\n            .try_into()\n            .expect(\"CustomUintFormatter: failed to convert value to u64\");\n    \n        if raw > max {\n            error!(value = raw, max = max, \"CustomUintFormatter value out of range\");\n            panic!(\"CustomUintFormatter value out of range\");\n        }\n    \n        let full_bytes = if BIG_ENDIAN {\n            raw.to_be_bytes()\n        } else {\n            raw.to_le_bytes()\n        };\n    \n        let slice = if BIG_ENDIAN {\n            &full_bytes[8 - BYTES as usize..]\n        } else {\n            &full_bytes[..BYTES as usize]\n        };\n    \n        s.write_all(slice)\n            .expect(\"I/O error while writing CustomUintFormatter\");\n    \n        trace!(\n            bytes = BYTES,\n            big_endian = BIG_ENDIAN,\n            value = raw,\n            \"CustomUintFormatter::ser\"\n        );\n    }\n\n    #[inline]\n    fn unser<S: Read>(&mut self, s: &mut S, v: &mut I) {\n        let max: u64 = u64::MAX >> (8 * (8 - BYTES) as usize); /* width mask */\n    \n        let mut buf = [0u8; 8];\n        if BIG_ENDIAN {\n            s.read_exact(&mut buf[8 - BYTES as usize..])\n        } else {\n            s.read_exact(&mut buf[..BYTES as usize])\n        }\n        .expect(\"I/O error while reading CustomUintFormatter\");\n    \n        let raw = if BIG_ENDIAN {\n            u64::from_be_bytes(buf)\n        } else {\n            u64::from_le_bytes(buf)\n        };\n    \n        if raw > max {\n            error!(value = raw, max = max, \"CustomUintFormatter value out of range\");\n            panic!(\"CustomUintFormatter value out of range\");\n        }\n    \n        *v = I::try_from(raw)\n            .expect(\"CustomUintFormatter: target type cannot represent value\");\n    \n        trace!(\n            bytes = BYTES,\n            big_endian = BIG_ENDIAN,\n            value = raw,\n            \"CustomUintFormatter::unser\"\n        );\n    }\n}\n\nimpl SizeComputer {\n\n    pub fn new(n_version_in: i32) -> Self {\n        Self { n_size: 0, n_version: n_version_in }\n    }\n\n    /// Bump the byte counter.\n    #[inline]\n    pub fn add_bytes(&mut self, n_size: usize) {\n        trace!(bytes = n_size, \"SizeComputer::add_bytes\");\n        self.n_size += n_size;\n    }\n\n    /// C++ alias that “writes” a raw pointer/len pair.\n    #[inline]\n    pub fn write_ptr(&mut self, _psz: *const u8, n_size: usize) {\n        self.add_bytes(n_size);\n    }\n\n    /// C++ alias that pretends to seek forward `_nSize` bytes.\n    #[inline]\n    pub fn seek(&mut self, n_size: usize) {\n        self.add_bytes(n_size);\n    }\n\n    #[inline]\n    pub fn size(&self) -> usize {\n        self.n_size \n    }\n\n    #[inline]\n    pub fn get_version(&self) -> i32 {\n        self.n_version \n    }\n}\n\nimpl Write for SizeComputer {\n\n    #[inline]\n    fn write(&mut self, buf: &[u8]) -> IoResult<usize> {\n        self.add_bytes(buf.len());\n        Ok(buf.len())\n    }\n\n    #[inline]\n    fn flush(&mut self) -> IoResult<()> {\n        Ok(()) \n    }\n}\n\nimpl<'a, T> std::ops::Shl<&'a T> for SizeComputer where\n    T: BtcSerialize<SizeComputer> {\n\n    type Output = SizeComputer;\n\n    #[inline]\n    fn shl(mut self, rhs: &'a T) -> Self::Output {\n        BtcSerialize::<SizeComputer>::serialize(rhs, &mut self);\n        self\n    }\n}\n\nimpl<'a, const Limit: usize> LimitedStringFormatter<'a, Limit> {\n\n    pub fn unser<Stream>(&mut self, s: &mut Stream, v: &mut String) where\n            Stream: Read\n    {\n        let size = read_compact_size(s, Some(true)) as usize;\n        if size > Limit {\n            panic!(\"String length limit exceeded ({} > {})\", size, Limit);\n        }\n        v.clear();\n        v.reserve(size);\n        if size != 0 {\n            // SAFETY: we allocated exactly `size` bytes, read will fill them.\n            unsafe {\n                v.as_mut_vec().set_len(size);\n            }\n            s.read_exact(unsafe { v.as_mut_vec() })\n                .expect(\"I/O error while reading limited string\");\n        }\n        trace!(len = size, \"LimitedStringFormatter::unser\");\n    }\n\n    pub fn ser<Stream>(&mut self, s: &mut Stream, v: &String) where\n            Stream: Write\n    {\n        write_compact_size(s, v.len() as u64);\n        if !v.is_empty() {\n            s.write_all(v.as_bytes())\n                .expect(\"I/O error while writing limited string\");\n        }\n        trace!(len = v.len(), \"LimitedStringFormatter::ser\");\n    }\n}\n\nimpl<Stream> BtcUnserialize<Stream> for i8 where\n    Stream: Read {\n\n    #[inline]\n    fn unserialize(&mut self, s: &mut Stream) {\n        let v = ser_readdata8(s) as i8;\n        trace!(value = v, \"unserialize i8\");\n        *self = v;\n    }\n}\n\nimpl<Stream> BtcUnserialize<Stream> for u8 where\n    Stream: Read {\n\n    #[inline]\n    fn unserialize(&mut self, s: &mut Stream) {\n        let v = ser_readdata8(s);\n        trace!(value = v, \"unserialize u8\");\n        *self = v;\n    }\n}\n\nimpl<Stream> BtcUnserialize<Stream> for i16 where\n    Stream: Read {\n\n    #[inline]\n    fn unserialize(&mut self, s: &mut Stream) {\n        let v = ser_readdata16(s) as i16;\n        trace!(value = v, \"unserialize i16\");\n        *self = v;\n    }\n}\n\nimpl<Stream> BtcUnserialize<Stream> for u16 where\n    Stream: Read {\n\n    #[inline]\n    fn unserialize(&mut self, s: &mut Stream) {\n        let v = ser_readdata16(s);\n        trace!(value = v, \"unserialize u16\");\n        *self = v;\n    }\n}\n\nimpl<Stream> BtcUnserialize<Stream> for i32 where\n    Stream: Read {\n\n    #[inline]\n    fn unserialize(&mut self, s: &mut Stream) {\n        let v = ser_readdata32(s) as i32;\n        trace!(value = v, \"unserialize i32\");\n        *self = v;\n    }\n}\n\nimpl<Stream> BtcUnserialize<Stream> for u32 where\n    Stream: Read {\n\n    #[inline]\n    fn unserialize(&mut self, s: &mut Stream) {\n        let v = ser_readdata32(s);\n        trace!(value = v, \"unserialize u32\");\n        *self = v;\n    }\n}\n\nimpl<Stream> BtcUnserialize<Stream> for i64 where\n    Stream: Read {\n\n    #[inline]\n    fn unserialize(&mut self, s: &mut Stream) {\n        let v = ser_readdata64(s) as i64;\n        trace!(value = v, \"unserialize i64\");\n        *self = v;\n    }\n}\n\nimpl<Stream> BtcUnserialize<Stream> for u64 where\n    Stream: Read {\n\n    #[inline]\n    fn unserialize(&mut self, s: &mut Stream) {\n        let v = ser_readdata64(s);\n        trace!(value = v, \"unserialize u64\");\n        *self = v;\n    }\n}\n\nimpl<Stream, const N: usize> BtcUnserialize<Stream> for [u8; N] where\n    Stream: Read {\n\n    #[inline]\n    fn unserialize(&mut self, s: &mut Stream) {\n        trace!(len = N, \"unserialize [u8; N]\");\n        s.read_exact(self)\n            .expect(\"I/O error while reading fixed‑length byte array\");\n    }\n}\n\nimpl<Stream> BtcUnserialize<Stream> for bool where\n    Stream: Read {\n\n    #[inline]\n    fn unserialize(&mut self, s: &mut Stream) {\n        let v = ser_readdata8(s) != 0;\n        trace!(value = v, \"unserialize bool\");\n        *self = v;\n    }\n}\n\nimpl<Stream> BtcUnserialize<Stream> for &[u8] where\n    Stream: Read {\n\n    /// Read **exactly** `self.len()` bytes from `s` into the existing slice.\n    ///\n    /// This mirrors the “const‑cast” logic of Bitcoin Core’s\n    /// `Span<unsigned char>` deserialiser: we temporarily treat the slice’s\n    /// data as mutable, even though the reference itself is `&[u8]`.\n    /// The caller is responsible for guaranteeing that the backing memory\n    /// is writable (e.g. it was originally borrowed as `&mut [u8]` and only\n    /// viewed through an immutable lens here).\n    #[inline]\n    fn unserialize(&mut self, s: &mut Stream) {\n        let len = self.len();\n        trace!(len, \"unserialize &[u8]\");\n    \n        // SAFETY:\n        //  * `ptr` was obtained from a valid slice and is properly aligned.\n        //  * It lives as long as `*self`.\n        //  * We will not read or write out‑of‑bounds.\n        //  * The caller upholds the aliasing contract (no concurrent mutable\n        //    borrows of the same memory).\n        let ptr = self.as_ptr() as *mut u8;\n        let dst: &mut [u8] = unsafe { std::slice::from_raw_parts_mut(ptr, len) };\n    \n        s.read_exact(dst)\n            .expect(\"I/O error while reading raw byte span\");\n    }\n}\n\nimpl<Stream> BtcUnserialize<Stream> for String where\n    Stream: Read {\n\n    fn unserialize(&mut self, is: &mut Stream) {\n        let n_size = crate::read_compact_size(is, Some(true)) as usize;\n        trace!(len = n_size, \"unserialize String\");\n        self.clear();\n        self.reserve(n_size);\n        if n_size != 0 {\n            unsafe { self.as_mut_vec().set_len(n_size) };\n            is.read_exact(unsafe { self.as_mut_vec() })\n                .expect(\"I/O error while reading String\");\n        }\n    }\n}\n\nimpl<Stream, T: Default, const N: usize> BtcUnserialize<Stream> for PreVector<T, N> where\n    Stream: Read,\n    T: Clone + BtcUnserialize<Stream> {\n\n    fn unserialize(&mut self, is: &mut Stream) {\n        self.clear();\n        let total = crate::read_compact_size(is, Some(true)) as usize;\n        trace!(expected = total, \"unserialize PreVector\");\n    \n        let mut read_elems = 0usize;\n    \n        while read_elems < total {\n    \n            let elems_per_block =\n                1 + (crate::constants::MAX_VECTOR_ALLOCATE as usize - 1)\n                    / std::mem::size_of::<T>();\n    \n            let blk = std::cmp::min(total - read_elems, elems_per_block);\n    \n            self.resize(read_elems + blk, T::default()); // safe resize\n    \n            for i in read_elems..read_elems + blk {\n                BtcUnserialize::unserialize(&mut self[i], is);\n            }\n    \n            read_elems += blk;\n        }\n    }\n}\n\nimpl<Stream, T, A> BtcUnserialize<Stream> for Vec<T, A> where\n    Stream: Read,\n    T: Default,\n    A: std::alloc::Allocator + Clone,\n    T: BtcUnserialize<Stream> {\n\n    fn unserialize(&mut self, is: &mut Stream) {\n        self.clear();\n        let total = crate::read_compact_size(is, Some(true)) as usize;\n        trace!(expected = total, \"unserialize Vec\");\n    \n        let mut read_elems = 0usize;\n        while read_elems < total {\n            let elems_per_block =\n                1 + (crate::constants::MAX_VECTOR_ALLOCATE as usize - 1)\n                    / std::mem::size_of::<T>();\n            let blk = std::cmp::min(total - read_elems, elems_per_block);\n    \n            self.reserve(blk);\n            for _ in 0..blk {\n                let mut elem = T::default();\n                BtcUnserialize::unserialize(&mut elem, is);\n                self.push(elem);\n            }\n            read_elems += blk;\n        }\n    }\n}\n\nimpl<Stream, K, V> BtcUnserialize<Stream> for (K, V) where\n    Stream: Read,\n    K: BtcUnserialize<Stream> + Default,\n    V: BtcUnserialize<Stream> + Default {\n\n    fn unserialize(&mut self, is: &mut Stream) {\n        self.0.unserialize(is);\n        self.1.unserialize(is);\n        trace!(\"unserialize (K,V) tuple\");\n    }\n}\n\nimpl<Stream, K, V, S> BtcUnserialize<Stream> for HashMap<K, V, S> where\n    Stream: Read,\n    K: BtcUnserialize<Stream> + Eq + std::hash::Hash + Default,\n    V: BtcUnserialize<Stream> + Default,\n    S: std::hash::BuildHasher + Default {\n\n    fn unserialize(&mut self, is: &mut Stream) {\n        self.clear();\n        let total = crate::read_compact_size(is, Some(true)) as usize;\n        trace!(expected = total, \"unserialize HashMap\");\n    \n        for _ in 0..total {\n            let mut k = K::default();\n            k.unserialize(is);\n            let mut v = V::default();\n            v.unserialize(is);\n            self.insert(k, v);\n        }\n    }\n}\n\nimpl<Stream, K, S> BtcUnserialize<Stream> for HashSet<K, S> where\n    Stream: Read,\n    K: BtcUnserialize<Stream> + Eq + std::hash::Hash + Default,\n    S: std::hash::BuildHasher + Default {\n\n    fn unserialize(&mut self, is: &mut Stream) {\n        self.clear();\n        let total = crate::read_compact_size(is, Some(true)) as usize;\n        trace!(expected = total, \"unserialize HashSet\");\n    \n        for _ in 0..total {\n            let mut key = K::default();\n            key.unserialize(is);\n            self.insert(key);\n        }\n    }\n}\n\nimpl<Stream, T> BtcUnserialize<Stream> for Box<T> where\n    Stream: Read,\n    T: Default + BtcUnserialize<Stream> {\n\n    fn unserialize(&mut self, is: &mut Stream) {\n        let mut tmp = T::default();\n        BtcUnserialize::unserialize(&mut tmp, is);\n        *self = Box::new(tmp);\n    }\n}\n\nimpl<Stream, T> BtcUnserialize<Stream> for std::sync::Arc<T> where\n    Stream: Read,\n    T: Default + BtcUnserialize<Stream> {\n\n    fn unserialize(&mut self, is: &mut Stream) {\n        let mut tmp = T::default();\n        BtcUnserialize::unserialize(&mut tmp, is);\n        *self = std::sync::Arc::new(tmp);\n    }\n}\n\nimpl<'a, Stream, T> BtcUnserialize<Stream> for &'a mut T where\n    Stream: Read,\n    T: BtcUnserialize<Stream> + ?Sized {\n\n    #[inline]\n    fn unserialize(&mut self, s: &mut Stream) {\n        (**self).unserialize(s);\n    }\n}\n\nimpl<Stream> SerializeMany<Stream> for () {\n\n    #[inline]\n    fn serialize_many(&self, _s: &mut Stream) {}\n}\n\nimpl<Stream, A> SerializeMany<Stream> for (A,) where\n    Stream: Write,\n    A: BtcSerialize<Stream> {\n\n    fn serialize_many(&self, s: &mut Stream) {\n        self.0.serialize(s);\n    }\n}\n\nimpl<Stream, A, B> SerializeMany<Stream> for (A, B) where\n    Stream: Write,\n    A: BtcSerialize<Stream>,\n    B: BtcSerialize<Stream> {\n\n    fn serialize_many(&self, s: &mut Stream) {\n        self.0.serialize(s);\n        self.1.serialize(s);\n    }\n}\n\nimpl<Stream, A, B, C> SerializeMany<Stream> for (A, B, C) where\n    Stream: Write,\n    A: BtcSerialize<Stream>,\n    B: BtcSerialize<Stream>,\n    C: BtcSerialize<Stream> {\n\n    fn serialize_many(&self, s: &mut Stream) {\n        self.0.serialize(s);\n        self.1.serialize(s);\n        self.2.serialize(s);\n    }\n}\n\nimpl<Stream> UnserializeMany<Stream> for () {\n\n    #[inline]\n    fn unserialize_many(&mut self, _s: &mut Stream) {}\n}\n\nimpl<Stream, A> UnserializeMany<Stream> for (A,) where\n    Stream: Read,\n    A: BtcUnserialize<Stream> {\n\n    fn unserialize_many(&mut self, s: &mut Stream) {\n        self.0.unserialize(s);\n    }\n}\n\nimpl<Stream, A, B> UnserializeMany<Stream> for (A, B) where\n    Stream: Read,\n    A: BtcUnserialize<Stream>,\n    B: BtcUnserialize<Stream> {\n\n    fn unserialize_many(&mut self, s: &mut Stream) {\n        self.0.unserialize(s);\n        self.1.unserialize(s);\n    }\n}\n\nimpl<Stream, A, B, C> UnserializeMany<Stream> for (A, B, C) where\n    Stream: Read,\n    A: BtcUnserialize<Stream>,\n    B: BtcUnserialize<Stream>,\n    C: BtcUnserialize<Stream> {\n\n    fn unserialize_many(&mut self, s: &mut Stream) {\n        self.0.unserialize(s);\n        self.1.unserialize(s);\n        self.2.unserialize(s);\n    }\n}\n\nimpl<'a, Stream, T> SerializeMany<Stream> for &'a T where\n    Stream: Write,\n    T: SerializeMany<Stream> + ?Sized {\n\n    #[inline]\n    fn serialize_many(&self, s: &mut Stream) {\n        (**self).serialize_many(s);\n    }\n}\n\nimpl<'a, Stream, T> SerializeMany<Stream> for &'a mut T where\n    Stream: Write,\n    T: SerializeMany<Stream> + ?Sized {\n\n    #[inline]\n    fn serialize_many(&self, s: &mut Stream) {\n        (**self).serialize_many(s);\n    }\n}\n\nimpl<'a, Stream, T> UnserializeMany<Stream> for &'a mut T where\n    Stream: Read,\n    T: UnserializeMany<Stream> + ?Sized {\n\n    #[inline]\n    fn unserialize_many(&mut self, s: &mut Stream) {\n        (**self).unserialize_many(s);\n    }\n}\n\n\nThis crate has the following authors:\n[\n    \"klebs <none>\",\n]\nThis crate has the following rust edition:\n2021\nThis crate has the following license:\nMIT\nThis crate is held in the following repository:\nhttps://github.com/klebs6/bitcoin-rs\n","role":"user"}],"model":"gpt-5.1"}}
