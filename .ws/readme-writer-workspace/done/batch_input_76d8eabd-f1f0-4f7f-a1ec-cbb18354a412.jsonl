{"custom_id":"bitcoinleveldb-logwriter-ai-readme-request","method":"POST","url":"/v1/chat/completions","body":{"max_completion_tokens":8192,"messages":[{"content":"We would like you to write a README.md for a rust crate with maximally helpful content.\nAdditionally, we would like you to generate several fields from the Cargo.toml package section for this crate.\nWe will show you the strict json output format we would like you to provide.\nPlease tailor your response for an apex consumer of maximal intelligence.\nA reader of this README.md should have a good sense of what the crate does and how to use it after reading what you write.\nPlease include a messaage indicating that this README.md file was generated by an AI model and may not be 100% accurate however it should be pretty good.\n\n\nCarefully read and parse the information we sent you.\n\nWe want to generate all information items requested by our schema:\n\n- Read the description of each field. Use it, along with the content we sent you to generate an appropriate value for each.\n- Ensure that each generated field optimally serves its desired purpose.\n- Each item should be deep, detailed, and specific. Use optimally descriptive and useful language. Do not be too verbose.\n- Do not add any extra keys to the generated object. Generate precisely what we ask of you: no more, no less.\n- For fields which are of an enum type: pick *exactly one variant*. Do not generate any information for the unselected variants.\n- For array fields: supply a JSON list [ ... ] of items, each conforming to the correct item type.\n- For map fields: Provide a JSON object { \"key_as_string\": <value>, ... }. Keys must be valid JSON strings. Keys and Values must conform to the key and value schemas we provide to you. Fill all subfields of each and every map value.\n- If we ask you to justify a map field, provide your justification/confidence score for the entire map. Do not attempt to separately justify each map element.\n- Likewise, if we ask you to justify an array field, provide your justification/confidence score for the entire array. Do not attempt to separately justify each element.\n- Provide numeric fields as real JSON numbers (not strings).\n- For string fields: provide the value precisely as a string literal. If optional, you may set it to null.\n- If we ask you to justify or provide confidence scores for the fields of a structure, please do so carefully. For each field we ask you to justify, please explain or justify your choice clearly. Confidence scores must be specified as real JSON numbers in the range `[0..1]`.\n- If we ask to you generate an optional field, either fill it or set it to null.\n- If we ask you to justify your choice of an enum variant, please explain your choice clearly. Do not justify your decision to leave a variant unselected. Provide your justification as a JSON string. Provide your confidence score as a real JSON number in the range `[0..1]`.\n- In terms of the JSON format we would like you to provide, the object itself will be deserialied based on the following schema. \n- We begin exactly at the top: the data should not be nested under a parent named 'fields' or anything similar.\n\n## Here is the schema to use:\n\nObject {\n    \"fields\": Object {\n        \"crate_name\": Object {\n            \"generation_instructions\": String(\"\\\"This string should be the name of our crate, *verbatim*, trimmed for use as a toml field\\\"\"),\n            \"required\": Bool(true),\n            \"type\": String(\"string\"),\n        },\n        \"full_readme_markdown\": Object {\n            \"generation_instructions\": String(\"\\\"This string should be valid markdown representing the readme for this crate.\\\\n\\\\n Please make it terse, useful, and designed for an industrious commercially savy consumer of industrious nature. \\\\n\\\\n Advanced vocabulary and concepts are welcome. \\\\n\\\\n If this crate involves concepts from mathematics and/or physics, please describe and document them here.\\\"\"),\n            \"required\": Bool(true),\n            \"type\": String(\"string\"),\n        },\n        \"package_categories\": Object {\n            \"generation_instructions\": String(\"\\\"These categories will be used in our Cargo.toml file.\\\\n\\\\n It is important that users of this crate can find it on crates.io.\\\\n\\\\n Choose maximum 5 categories and make sure they are actually meaningful for our crate.\\\\n\\\\n These categories should only be chosen from among the legal crates.io categories. \\\\n\\\\n The ONLY legal categoreis are:\\\\n\\\\n``\\\\n accessibility\\\\n aerospace\\\\n algorithms\\\\n api-bindings\\\\n asynchronous\\\\n authentication\\\\n caching\\\\n command-line-interface\\\\n command-line-utilities\\\\n compilers\\\\n compression\\\\n computer-vision\\\\n concurrency\\\\n config\\\\n cryptography\\\\n data-structures\\\\n database\\\\n database-implementations\\\\n date-and-time\\\\n development-tools\\\\n email\\\\n embedded\\\\n emulators\\\\n encoding\\\\n external-ffi-bindings\\\\n filesystem\\\\n finance\\\\n game-development\\\\n game-engines\\\\n games\\\\n graphics\\\\n gui\\\\n hardware-support\\\\n internationalization\\\\n localization\\\\n mathematics\\\\n memory-management\\\\n multimedia\\\\n network-programming\\\\n no-std\\\\n os\\\\n parser-implementations\\\\n parsing\\\\n rendering\\\\n rust-patterns\\\\n science\\\\n simulation\\\\n template-engine\\\\n text-editors\\\\n text-processing\\\\n value-formatting\\\\n virtualization\\\\n visualization\\\\n wasm\\\\n web-programming\\\\n ``\\\\n\\\\n DO NOT specify a category that is not on this list.\\\"\"),\n            \"required\": Bool(true),\n            \"type\": String(\"array_of_strings\"),\n        },\n        \"package_description\": Object {\n            \"generation_instructions\": String(\"\\\"We will place this package_description in our Cargo.toml file so the users of this crate\\\\n know what it does.\\\\n\\\\n The discription should be technical, clear, and useful. It should be terse.\\\"\"),\n            \"required\": Bool(true),\n            \"type\": String(\"string\"),\n        },\n        \"package_keywords\": Object {\n            \"generation_instructions\": String(\"\\\"These keywords will be used in our Cargo.toml file so the users of this crate can easily\\\\n find it in the package system. Keywords should be useful, varied, meaningful, and reflect\\\\n the contents of our crate. They should make it easy to find. Please provide exactly five.\\\"\"),\n            \"required\": Bool(true),\n            \"type\": String(\"array_of_strings\"),\n        },\n    },\n    \"struct_docs\": String(\" This structure is a directive indicating which fields we need you to provide for us in your response to our query.\\n\"),\n    \"struct_name\": String(\"AiReadmeWriterDesiredOutput\"),\n    \"type\": String(\"struct\"),\n}\n\n## Please keep the following in mind:\n\nEntry phrasing:\n\n- Ensure entries are concise and focused.\n- Ensure there are no vague phrases (e.g., avoid starting with \"Illustrates the something something...\"; instead, use direct details like \"The hanging green vines on the garden wall\").\n\nEnsure Clarity and Consistency:\n\n- Use clear, grammatically correct sentences.\n- Maintain a consistent tone and style throughout.\n\nEnrich Content:\n\n- Communicate additional information where appropriate to enhance depth and value.\n- If a mathematical, physical, or otherwise technical background is helpful, please provide it.\n- Ensure that the content is comprehensive and meets all requirements.\n\nFocus Language:\n\n- Use deliberate and precise language.\n- Avoid vague verbs and keep the maximally intelligent and detail oriented audience in mind. \n- We explicitly ban the words `hush`, `subtle`, `mythic`, and `aura`. Please keep your vocabulary choices rigorous.\n- Do not use modern cultural references \n- Do not generically reference ideas which do not belong in the global environment.\n\n## Present the Final JSON:\n\n- Format the output as a JSON object.\n- Include all fields properly named from the schema we sent you.\n\nEnsure Proper Formatting:\n\n- Use proper JSON syntax with keys and arrays.\n- Ensure that all entries are correctly placed in their respective places.\n\nProvide only the final JSON data as specified by the schema. \n\nDo not include any schema generation instructions, meta-fields, nested-templates (unless directly asked) or extraneous information. \n\nProvide only the populated fields and their values, conforming exactly to the required structure without embedding any intermediate annotations or placeholders.\n\nYour output should only consist of the JSON object. do *not* include a preamble or postamble to your response. \n\nWe seek to successfully parse your response directly as JSON.\n\nFor the final answer, output the result only as a valid JSON object, wrapped inside triple backticks with json immediately after the opening backticks.\nThe JSON must be parser-ready:\n– No additional text before or after the block\n– No markdown or prose outside the fenced block\n– No HTML escaping of quotes, slashes, or other characters\n– Indentation and whitespace preserved exactly as written\n– The content between the fences must be valid JSON as per RFC 8259","role":"system"},{"content":"We have a rust crate named 'bitcoinleveldb-logwriter' 0.1.1. \n\nHere is the interface:\n#[derive(Getters)]\n#[getset(get = \"pub\")]\npub struct MockWritableFileCore  {\n    buffer: Vec<u8>,\n}\n\n\n#[derive(Getters)]\n#[getset(get = \"pub\")]\npub struct MockWritableFileAddRecord  {\n    buffer:            Vec<u8>,\n    fail_append_after: Option<usize>,\n    append_call_count: usize,\n    flush_call_count:  usize,\n    close_call_count:  usize,\n    sync_call_count:   usize,\n}\n\n\n#[derive(Builder)]\n#[builder(setter(into))]\npub struct LogWriter  {\n    dest:         Rc<RefCell<dyn WritableFile>>,\n    block_offset: i32,\n    type_crc:     [u32; LOG_MAX_RECORD_TYPE as usize + 1],\n}\n\n\n#[derive(Getters)]\n#[getset(get = \"pub\")]\npub struct MockWritableFileEmit  {\n    buffer:            Vec<u8>,\n    fail_append_after: Option<usize>,\n    append_call_count: usize,\n    flush_call_count:  usize,\n    close_call_count:  usize,\n    sync_call_count:   usize,\n}\n\nimpl LogWriter {\n\n    pub fn emit_physical_record(\n        &mut self,\n        t:         LogRecordType,\n        ptr:       *const u8,\n        length:    usize\n    ) -> Status\n    {\n        debug!(\n            \"LogWriter::emit_physical_record: type={:?} length={}\",\n            t,\n            length\n        );\n    \n        self.validate_record_length(length);\n        self.validate_record_fits_in_block(length);\n    \n        let crc    = self.crc32c_for_record(t, ptr, length);\n        let header = self.build_record_header(t, length, crc);\n    \n        let status = self.append_header_and_payload(&header, ptr, length);\n    \n        self.advance_block_offset(LOG_HEADER_SIZE + (length as i32));\n    \n        status\n    }\n}\n\nimpl LogWriter {\n\n    /// Add a logical record, fragmenting it into one or more physical records.\n    pub fn add_record(&mut self, slice: &Slice) -> Status {\n        info!(\n            \"LogWriter::add_record: writing logical record of size {}\",\n            slice.size()\n        );\n    \n        unsafe { self.add_record_internal(slice) }\n    }\n}\n\nimpl LogWriter {\n\n    /// Append header and payload to the underlying file and flush.\n    pub fn append_header_and_payload(\n        &self,\n        header: &[u8; LOG_HEADER_SIZE as usize],\n        ptr:    *const u8,\n        length: usize\n    ) -> Status\n    {\n        debug!(\n            \"LogWriter::append_header_and_payload: header_len={} payload_len={}\",\n            header.len(),\n            length\n        );\n    \n        let header_slice =\n            Slice::from_ptr_len(header.as_ptr(), LOG_HEADER_SIZE as usize);\n    \n        let status = {\n            let mut dest_ref = self.dest_handle().borrow_mut();\n    \n            let mut status = dest_ref.append(&header_slice);\n            if status.is_ok() && length > 0 {\n                let payload_slice = Slice::from_ptr_len(ptr, length);\n                status            = dest_ref.append(&payload_slice);\n            }\n    \n            if status.is_ok() {\n                status = dest_ref.flush();\n            }\n    \n            status\n        };\n    \n        if status.is_ok() {\n            trace!(\n                \"LogWriter::append_header_and_payload: append+flush succeeded\"\n            );\n        } else {\n            error!(\n                \"LogWriter::append_header_and_payload: append+flush failed\"\n            );\n        }\n    \n        status\n    }\n}\n\nimpl LogWriter {\n\n    /// Compute the CRC32C for the given record type and payload, including masking.\n    pub fn crc32c_for_record(\n        &self,\n        t:      LogRecordType,\n        ptr:    *const u8,\n        length: usize\n    ) -> u32\n    {\n        debug!(\n            \"LogWriter::crc32c_for_record: type={:?} length={}\",\n            t,\n            length\n        );\n    \n        unsafe {\n            let initial_crc = self.type_crc_for(t);\n            let extended    = crc32c_extend(initial_crc, ptr, length);\n            let masked      = crc32c_mask(extended);\n    \n            trace!(\n                \"LogWriter::crc32c_for_record: type={:?} initial_crc={:#010x} masked_crc={:#010x}\",\n                t,\n                initial_crc,\n                masked\n            );\n    \n            masked\n        }\n    }\n}\n\nimpl LogWriter {\n\n    /// Create a writer that will append data to \"*dest\".\n    ///\n    /// \"*dest\" must have initial length \"dest_length\".\n    /// \"*dest\" must remain live while this LogWriter is in use.\n    pub fn new(dest: Rc<RefCell<dyn WritableFile>>, dest_length: u64) -> Self {\n        info!(\n            \"LogWriter::new: dest_length={} block_size={}\",\n            dest_length,\n            LOG_BLOCK_SIZE\n        );\n    \n        let block_offset = Self::initial_block_offset_from_length(dest_length);\n        let type_crc     = Self::build_type_crc_table();\n    \n        info!(\n            \"LogWriter::new: computed initial block_offset={} type_crc_entries={}\",\n            block_offset,\n            type_crc.len()\n        );\n    \n        LogWriterBuilder::default()\n            .dest(dest)\n            .block_offset(block_offset)\n            .type_crc(type_crc)\n            .build()\n            .unwrap()\n    }\n}\n\nimpl MockWritableFileCore {\n\n    pub fn new() -> Self {\n        Self { buffer: Vec::new() }\n    }\n\n    pub fn recorded_bytes(&self) -> &[u8] {\n        &self.buffer\n    }\n}\n\nimpl Named for MockWritableFileCore {\n\n    fn name(&self) -> Cow<'_,str> {\n        Cow::Owned(\"mock_writable_file_core\".to_string())\n    }\n}\n\nimpl WritableFileAppend for MockWritableFileCore {\n\n    fn append(&mut self, data: &Slice) -> Status {\n        unsafe {\n            let ptr = *data.data();\n            let len = *data.size();\n            trace!(\n                \"MockWritableFileCore::append: ptr={:?} len={}\",\n                ptr,\n                len\n            );\n            let src = std::slice::from_raw_parts(ptr, len);\n            self.buffer.extend_from_slice(src);\n        }\n        Status::ok()\n    }\n}\n\nimpl WritableFileFlush for MockWritableFileCore {\n\n    fn flush(&mut self) -> Status {\n        trace!(\"MockWritableFileCore::flush\");\n        Status::ok()\n    }\n}\n\nimpl WritableFileClose for MockWritableFileCore {\n\n    fn close(&mut self) -> Status {\n        trace!(\"MockWritableFileCore::close\");\n        Status::ok()\n    }\n}\n\nimpl WritableFileSync for MockWritableFileCore {\n\n    fn sync(&mut self) -> Status {\n        trace!(\"MockWritableFileCore::sync\");\n        Status::ok()\n    }\n}\n\nimpl WritableFile for MockWritableFileCore {}\n\nimpl LogWriter {\n\n    /// Whether we need to start a new block because the remaining bytes are too\n    /// small to hold a header.\n    pub fn should_start_new_block(&self) -> bool {\n        let leftover = self.block_trailer_bytes_remaining();\n        let result   = leftover < LOG_HEADER_SIZE;\n        trace!(\n            \"LogWriter::should_start_new_block: leftover={} header_size={} => {}\",\n            leftover,\n            LOG_HEADER_SIZE,\n            result\n        );\n        result\n    }\n}\n\nimpl LogWriter {\n\n    /// Build the physical record header for the given type, length and CRC.\n    pub fn build_record_header(\n        &self,\n        t:      LogRecordType,\n        length: usize,\n        crc:    u32\n    ) -> [u8; LOG_HEADER_SIZE as usize]\n    {\n        debug!(\n            \"LogWriter::build_record_header: type={:?} length={} crc={:#010x}\",\n            t,\n            length,\n            crc\n        );\n    \n        let mut buf = [0u8; LOG_HEADER_SIZE as usize];\n    \n        // Length (little-endian) and type.\n        buf[4] = (length & 0xff) as u8;\n        buf[5] = ((length >> 8) & 0xff) as u8;\n        buf[6] = t as u8;\n    \n        unsafe {\n            encode_fixed32(buf.as_mut_ptr(), crc);\n        }\n    \n        trace!(\n            \"LogWriter::build_record_header: header_bytes={:02x?}\",\n            &buf[..]\n        );\n    \n        buf\n    }\n}\n\nimpl LogWriter {\n\n    /// Core implementation of `add_record`, operating directly on the slice.\n    pub fn add_record_internal(&mut self, slice: &Slice) -> Status {\n        let mut ptr  = *slice.data();\n        let mut left = *slice.size();\n    \n        let mut begin      = true;\n        let mut status_opt = None::<Status>;\n    \n        // Fragment the record if necessary and emit it.\n        //\n        // Note that if slice is empty, we still want to iterate once to\n        // emit a single zero-length record.\n        loop {\n            if self.should_start_new_block() {\n                let status = self.write_trailer_padding_if_necessary();\n                let is_ok  = status.is_ok();\n                status_opt = Some(status);\n                if !is_ok {\n                    break;\n                }\n            }\n    \n            // Invariant: we never leave < LOG_HEADER_SIZE bytes in a block.\n            debug_assert!(\n                LOG_BLOCK_SIZE - self.block_offset_value() - LOG_HEADER_SIZE >= 0\n            );\n    \n            let avail            = self.block_available_data_bytes();\n            let fragment_length  = if left < avail { left } else { avail };\n    \n            let end         = left == fragment_length;\n            let record_type = Self::choose_record_fragment_type(begin, end);\n    \n            trace!(\n                \"LogWriter::add_record_internal: emitting fragment length={} begin={} end={} type={:?}\",\n                fragment_length,\n                begin,\n                end,\n                record_type\n            );\n    \n            let status = self.emit_physical_record(record_type, ptr, fragment_length);\n            let is_ok  = status.is_ok();\n            status_opt = Some(status);\n    \n            ptr  = ptr.add(fragment_length);\n            left -= fragment_length;\n            begin = false;\n    \n            if !is_ok || left == 0 {\n                break;\n            }\n        }\n    \n        match status_opt {\n            Some(s) => s,\n            None    => Status::ok(),\n        }\n    }\n}\n\nimpl MockWritableFileAddRecord {\n\n    pub fn new() -> Self {\n        Self {\n            buffer:            Vec::new(),\n            fail_append_after: None,\n            append_call_count: 0,\n            flush_call_count:  0,\n            close_call_count:  0,\n            sync_call_count:   0,\n        }\n    }\n\n    pub fn with_fail_append_after(call_index: usize) -> Self {\n        Self {\n            fail_append_after: Some(call_index),\n            ..Self::new()\n        }\n    }\n\n    pub fn recorded_bytes(&self) -> &[u8] {\n        &self.buffer\n    }\n}\n\nimpl Named for MockWritableFileAddRecord {\n\n    fn name(&self) -> Cow<'_,str> {\n        Cow::Owned(\"mock_writable_file_add_record\".to_string())\n    }\n}\n\nimpl WritableFileAppend for MockWritableFileAddRecord {\n\n    fn append(&mut self, data: &Slice) -> Status {\n        self.append_call_count = self.append_call_count.saturating_add(1);\n    \n        if let Some(limit) = self.fail_append_after {\n            if self.append_call_count == limit {\n                debug!(\n                    \"MockWritableFileAddRecord::append: injecting IO error at call {}\",\n                    self.append_call_count\n                );\n                let msg = \"mock append error\".to_string();\n                let msg_slice = Slice::from(&msg);\n                return Status::io_error(&msg_slice, None);\n            }\n        }\n    \n        unsafe {\n            // Slice exposes pointer-to-pointer semantics; we must dereference\n            // once to obtain the underlying payload pointer and length.\n            let ptr = *data.data();\n            let len = *data.size();\n            trace!(\n                \"MockWritableFileAddRecord::append: ptr={:?} len={}\",\n                ptr,\n                len\n            );\n            let src = std::slice::from_raw_parts(ptr, len);\n            self.buffer.extend_from_slice(src);\n        }\n    \n        Status::ok()\n    }\n}\n\nimpl WritableFileFlush for MockWritableFileAddRecord {\n\n    fn flush(&mut self) -> Status {\n        self.flush_call_count = self.flush_call_count.saturating_add(1);\n        trace!(\n            \"MockWritableFileAddRecord::flush: flush_call_count={}\",\n            self.flush_call_count\n        );\n        Status::ok()\n    }\n}\n\nimpl WritableFileClose for MockWritableFileAddRecord {\n\n    fn close(&mut self) -> Status {\n        self.close_call_count = self.close_call_count.saturating_add(1);\n        trace!(\n            \"MockWritableFileAddRecord::close: close_call_count={}\",\n            self.close_call_count\n        );\n        Status::ok()\n    }\n}\n\nimpl WritableFileSync for MockWritableFileAddRecord {\n\n    fn sync(&mut self) -> Status {\n        self.sync_call_count = self.sync_call_count.saturating_add(1);\n        trace!(\n            \"MockWritableFileAddRecord::sync: sync_call_count={}\",\n            self.sync_call_count\n        );\n        Status::ok()\n    }\n}\n\nimpl WritableFile for MockWritableFileAddRecord {}\n\nimpl LogWriter {\n\n    /// Get the precomputed CRC seed for the given record type.\n    pub fn type_crc_for(&self, record_type: LogRecordType) -> u32 {\n        let crc = self.type_crc[record_type as usize];\n        trace!(\n            \"LogWriter::type_crc_for: record_type={:?} crc={:#010x}\",\n            record_type,\n            crc\n        );\n        crc\n    }\n\n    /// Accessor for the destination handle.\n    pub fn dest_handle(&self) -> &Rc<RefCell<dyn WritableFile>> {\n        trace!(\"LogWriter::dest_handle: returning destination handle\");\n        &self.dest\n    }\n\n    /// Current block offset.\n    pub fn block_offset_value(&self) -> i32 {\n        trace!(\n            \"LogWriter::block_offset_value: block_offset={}\",\n            self.block_offset\n        );\n        self.block_offset\n    }\n\n    /// Set the current block offset.\n    pub fn set_block_offset_value(&mut self, value: i32) {\n        let old = self.block_offset;\n        self.block_offset = value;\n        debug!(\n            \"LogWriter::set_block_offset_value: from {} to {}\",\n            old,\n            self.block_offset\n        );\n    }\n\n    /// Advance the current block offset by `delta`, saturating on overflow.\n    pub fn advance_block_offset(&mut self, delta: i32) {\n        let old = self.block_offset;\n        self.block_offset = self.block_offset.saturating_add(delta);\n        debug!(\n            \"LogWriter::advance_block_offset: {} + {} => {}\",\n            old,\n            delta,\n            self.block_offset\n        );\n    }\n}\n\nimpl LogWriter {\n\n    /// Validate that the record length is within the supported bounds.\n    pub fn validate_record_length(&self, length: usize) {\n        debug!(\n            \"LogWriter::validate_record_length: length={}\",\n            length\n        );\n        assert!(length <= 0xffff, \"record length too large\");\n    }\n}\n\nimpl LogWriter {\n\n    /// Build and initialize the CRC table for all supported record types.\n    pub fn build_type_crc_table() -> [u32; LOG_MAX_RECORD_TYPE as usize + 1] {\n        trace!(\n            \"LogWriter::build_type_crc_table: initializing crc table for {} record types\",\n            LOG_MAX_RECORD_TYPE as usize + 1\n        );\n    \n        let mut table = [0u32; LOG_MAX_RECORD_TYPE as usize + 1];\n    \n        unsafe {\n            init_type_crc(table.as_mut_ptr());\n        }\n    \n        trace!(\"LogWriter::build_type_crc_table: initialization complete\");\n        table\n    }\n}\n\nimpl LogWriter {\n\n    /// Compute the starting block offset from the current file length.\n    pub fn initial_block_offset_from_length(dest_length: u64) -> i32 {\n        let block_size   = LOG_BLOCK_SIZE as u64;\n        let block_offset = (dest_length % block_size) as i32;\n    \n        debug!(\n            \"LogWriter::initial_block_offset_from_length: dest_length={} block_size={} -> offset={}\",\n            dest_length,\n            block_size,\n            block_offset\n        );\n    \n        block_offset\n    }\n}\n\nimpl LogWriter {\n\n    /// Bytes available for payload in the current block, after accounting for the header.\n    pub fn block_available_data_bytes(&self) -> usize {\n        let available =\n            (LOG_BLOCK_SIZE - self.block_offset_value() - LOG_HEADER_SIZE) as usize;\n        trace!(\n            \"LogWriter::block_available_data_bytes: block_offset={} available={}\",\n            self.block_offset_value(),\n            available\n        );\n        available\n    }\n}\n\nimpl LogWriter {\n\n    /// Choose the physical record type for the current fragment.\n    pub fn choose_record_fragment_type(begin: bool, end: bool) -> LogRecordType {\n        let record_type = match (begin, end) {\n            (true,  true)  => LogRecordType::Full,\n            (true,  false) => LogRecordType::First,\n            (false, true)  => LogRecordType::Last,\n            (false, false) => LogRecordType::Middle,\n        };\n    \n        trace!(\n            \"LogWriter::choose_record_fragment_type: begin={} end={} -> {:?}\",\n            begin,\n            end,\n            record_type\n        );\n    \n        record_type\n    }\n}\n\nimpl MockWritableFileEmit {\n\n    pub fn new() -> Self {\n        Self {\n            buffer:            Vec::new(),\n            fail_append_after: None,\n            append_call_count: 0,\n            flush_call_count:  0,\n            close_call_count:  0,\n            sync_call_count:   0,\n        }\n    }\n\n    pub fn with_fail_append_after(call_index: usize) -> Self {\n        Self {\n            fail_append_after: Some(call_index),\n            ..Self::new()\n        }\n    }\n\n    pub fn recorded_bytes(&self) -> &[u8] {\n        &self.buffer\n    }\n}\n\nimpl Named for MockWritableFileEmit {\n\n    fn name(&self) -> Cow<'_,str> {\n        Cow::Owned(\"mock_writable_file_emit\".to_string())\n    }\n}\n\nimpl WritableFileAppend for MockWritableFileEmit {\n\n    fn append(&mut self, data: &Slice) -> Status {\n        self.append_call_count = self.append_call_count.saturating_add(1);\n    \n        if let Some(limit) = self.fail_append_after {\n            if self.append_call_count == limit {\n                debug!(\n                    \"MockWritableFileEmit::append: injecting IO error at call {}\",\n                    self.append_call_count\n                );\n                let msg = \"mock append error emit\".to_string();\n                let msg_slice = Slice::from(&msg);\n                return Status::io_error(&msg_slice, None);\n            }\n        }\n    \n        unsafe {\n            let ptr = *data.data();\n            let len = *data.size();\n            trace!(\n                \"MockWritableFileEmit::append: ptr={:?} len={}\",\n                ptr,\n                len\n            );\n            let src = std::slice::from_raw_parts(ptr, len);\n            self.buffer.extend_from_slice(src);\n        }\n    \n        Status::ok()\n    }\n}\n\nimpl WritableFileFlush for MockWritableFileEmit {\n\n    fn flush(&mut self) -> Status {\n        self.flush_call_count = self.flush_call_count.saturating_add(1);\n        trace!(\n            \"MockWritableFileEmit::flush: flush_call_count={}\",\n            self.flush_call_count\n        );\n        Status::ok()\n    }\n}\n\nimpl WritableFileClose for MockWritableFileEmit {\n\n    fn close(&mut self) -> Status {\n        self.close_call_count = self.close_call_count.saturating_add(1);\n        trace!(\n            \"MockWritableFileEmit::close: close_call_count={}\",\n            self.close_call_count\n        );\n        Status::ok()\n    }\n}\n\nimpl WritableFileSync for MockWritableFileEmit {\n\n    fn sync(&mut self) -> Status {\n        self.sync_call_count = self.sync_call_count.saturating_add(1);\n        trace!(\n            \"MockWritableFileEmit::sync: sync_call_count={}\",\n            self.sync_call_count\n        );\n        Status::ok()\n    }\n}\n\nimpl WritableFile for MockWritableFileEmit {}\n\nimpl LogWriter {\n\n    /// Remaining bytes in the current block (including space that may be too small\n    /// for a header).\n    pub fn block_trailer_bytes_remaining(&self) -> i32 {\n        let remaining = LOG_BLOCK_SIZE - self.block_offset_value();\n        trace!(\n            \"LogWriter::block_trailer_bytes_remaining: block_offset={} remaining={}\",\n            self.block_offset_value(),\n            remaining\n        );\n        remaining\n    }\n}\n\nimpl LogWriter {\n\n    /// Validate that the record fits entirely within the current block.\n    pub fn validate_record_fits_in_block(&self, length: usize) {\n        let block_offset = self.block_offset_value() as usize;\n        let header_size  = LOG_HEADER_SIZE as usize;\n        let block_size   = LOG_BLOCK_SIZE as usize;\n    \n        debug!(\n            \"LogWriter::validate_record_fits_in_block: block_offset={} header_size={} length={} block_size={}\",\n            block_offset,\n            header_size,\n            length,\n            block_size\n        );\n    \n        assert!(\n            block_offset + header_size + length <= block_size,\n            \"record does not fit into block\"\n        );\n    }\n}\n\nimpl LogWriter {\n\n    /// Write zero-padding in the current block trailer if there are leftover bytes\n    /// that are too small for a header, then reset the block offset to zero.\n    pub fn write_trailer_padding_if_necessary(&mut self) -> Status {\n        let leftover = self.block_trailer_bytes_remaining();\n        debug_assert!(leftover >= 0);\n    \n        if leftover >= LOG_HEADER_SIZE {\n            trace!(\n                \"LogWriter::write_trailer_padding_if_necessary: no trailer needed (leftover={})\",\n                leftover\n            );\n            return Status::ok();\n        }\n    \n        if leftover > 0 {\n            debug!(\n                \"LogWriter::write_trailer_padding_if_necessary: writing {} bytes of trailer padding\",\n                leftover\n            );\n            debug_assert_eq!(LOG_HEADER_SIZE, 7);\n    \n            let trailer_len   = leftover as usize;\n            let trailer_bytes: [u8; 6] = [0u8; 6];\n    \n            let trailer_slice =\n                Slice::from_ptr_len(trailer_bytes.as_ptr(), trailer_len);\n    \n            let mut dest_ref = self.dest_handle().borrow_mut();\n            let status       = dest_ref.append(&trailer_slice);\n    \n            if status.is_ok() {\n                trace!(\n                    \"LogWriter::write_trailer_padding_if_necessary: successfully wrote {} bytes\",\n                    trailer_len\n                );\n            } else {\n                error!(\n                    \"LogWriter::write_trailer_padding_if_necessary: failed to write {} bytes of trailer\",\n                    trailer_len\n                );\n            }\n    \n            if !status.is_ok() {\n                return status;\n            }\n        }\n    \n        self.set_block_offset_value(0);\n        trace!(\n            \"LogWriter::write_trailer_padding_if_necessary: block_offset reset to 0\"\n        );\n    \n        Status::ok()\n    }\n}\n\n\nThis crate has the following authors:\n[\n    \"YourName <you@example.com>\",\n]\nThis crate has the following rust edition:\n2024\nThis crate has the following license:\nMIT\n","role":"user"}],"model":"gpt-5.1"}}
