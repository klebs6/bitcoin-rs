{"custom_id":"bitcoin-string-ai-readme-request","method":"POST","url":"/v1/chat/completions","body":{"max_completion_tokens":8192,"messages":[{"content":"We would like you to write a README.md for a rust crate with maximally helpful content.\nAdditionally, we would like you to generate several fields from the Cargo.toml package section for this crate.\nWe will show you the strict json output format we would like you to provide.\nPlease tailor your response for an apex consumer of maximal intelligence.\nA reader of this README.md should have a good sense of what the crate does and how to use it after reading what you write.\nPlease include a messaage indicating that this README.md file was generated by an AI model and may not be 100% accurate however it should be pretty good.\n\n\nCarefully read and parse the information we sent you.\n\nWe want to generate all information items requested by our schema:\n\n- Read the description of each field. Use it, along with the content we sent you to generate an appropriate value for each.\n- Ensure that each generated field optimally serves its desired purpose.\n- Each item should be deep, detailed, and specific. Use optimally descriptive and useful language. Do not be too verbose.\n- Do not add any extra keys to the generated object. Generate precisely what we ask of you: no more, no less.\n- For fields which are of an enum type: pick *exactly one variant*. Do not generate any information for the unselected variants.\n- For array fields: supply a JSON list [ ... ] of items, each conforming to the correct item type.\n- For map fields: Provide a JSON object { \"key_as_string\": <value>, ... }. Keys must be valid JSON strings. Keys and Values must conform to the key and value schemas we provide to you. Fill all subfields of each and every map value.\n- If we ask you to justify a map field, provide your justification/confidence score for the entire map. Do not attempt to separately justify each map element.\n- Likewise, if we ask you to justify an array field, provide your justification/confidence score for the entire array. Do not attempt to separately justify each element.\n- Provide numeric fields as real JSON numbers (not strings).\n- For string fields: provide the value precisely as a string literal. If optional, you may set it to null.\n- If we ask you to justify or provide confidence scores for the fields of a structure, please do so carefully. For each field we ask you to justify, please explain or justify your choice clearly. Confidence scores must be specified as real JSON numbers in the range `[0..1]`.\n- If we ask to you generate an optional field, either fill it or set it to null.\n- If we ask you to justify your choice of an enum variant, please explain your choice clearly. Do not justify your decision to leave a variant unselected. Provide your justification as a JSON string. Provide your confidence score as a real JSON number in the range `[0..1]`.\n- In terms of the JSON format we would like you to provide, the object itself will be deserialied based on the following schema. \n- We begin exactly at the top: the data should not be nested under a parent named 'fields' or anything similar.\n\n## Here is the schema to use:\n\nObject {\n    \"fields\": Object {\n        \"crate_name\": Object {\n            \"generation_instructions\": String(\"\\\"This string should be the name of our crate, *verbatim*, trimmed for use as a toml field\\\"\"),\n            \"required\": Bool(true),\n            \"type\": String(\"string\"),\n        },\n        \"full_readme_markdown\": Object {\n            \"generation_instructions\": String(\"\\\"This string should be valid markdown representing the readme for this crate.\\\\n\\\\n Please make it terse, useful, and designed for an industrious commercially savy consumer of industrious nature. \\\\n\\\\n Advanced vocabulary and concepts are welcome. \\\\n\\\\n If this crate involves concepts from mathematics and/or physics, please describe and document them here.\\\"\"),\n            \"required\": Bool(true),\n            \"type\": String(\"string\"),\n        },\n        \"package_categories\": Object {\n            \"generation_instructions\": String(\"\\\"These categories will be used in our Cargo.toml file.\\\\n\\\\n It is important that users of this crate can find it on crates.io.\\\\n\\\\n Choose maximum 5 categories and make sure they are actually meaningful for our crate.\\\\n\\\\n These categories should only be chosen from among the legal crates.io categories. \\\\n\\\\n The ONLY legal categoreis are:\\\\n\\\\n``\\\\n accessibility\\\\n aerospace\\\\n algorithms\\\\n api-bindings\\\\n asynchronous\\\\n authentication\\\\n caching\\\\n command-line-interface\\\\n command-line-utilities\\\\n compilers\\\\n compression\\\\n computer-vision\\\\n concurrency\\\\n config\\\\n cryptography\\\\n data-structures\\\\n database\\\\n database-implementations\\\\n date-and-time\\\\n development-tools\\\\n email\\\\n embedded\\\\n emulators\\\\n encoding\\\\n external-ffi-bindings\\\\n filesystem\\\\n finance\\\\n game-development\\\\n game-engines\\\\n games\\\\n graphics\\\\n gui\\\\n hardware-support\\\\n internationalization\\\\n localization\\\\n mathematics\\\\n memory-management\\\\n multimedia\\\\n network-programming\\\\n no-std\\\\n os\\\\n parser-implementations\\\\n parsing\\\\n rendering\\\\n rust-patterns\\\\n science\\\\n simulation\\\\n template-engine\\\\n text-editors\\\\n text-processing\\\\n value-formatting\\\\n virtualization\\\\n visualization\\\\n wasm\\\\n web-programming\\\\n ``\\\\n\\\\n DO NOT specify a category that is not on this list.\\\"\"),\n            \"required\": Bool(true),\n            \"type\": String(\"array_of_strings\"),\n        },\n        \"package_description\": Object {\n            \"generation_instructions\": String(\"\\\"We will place this package_description in our Cargo.toml file so the users of this crate\\\\n know what it does.\\\\n\\\\n The discription should be technical, clear, and useful. It should be terse.\\\"\"),\n            \"required\": Bool(true),\n            \"type\": String(\"string\"),\n        },\n        \"package_keywords\": Object {\n            \"generation_instructions\": String(\"\\\"These keywords will be used in our Cargo.toml file so the users of this crate can easily\\\\n find it in the package system. Keywords should be useful, varied, meaningful, and reflect\\\\n the contents of our crate. They should make it easy to find. Please provide exactly five.\\\"\"),\n            \"required\": Bool(true),\n            \"type\": String(\"array_of_strings\"),\n        },\n    },\n    \"struct_docs\": String(\" This structure is a directive indicating which fields we need you to provide for us in your response to our query.\\n\"),\n    \"struct_name\": String(\"AiReadmeWriterDesiredOutput\"),\n    \"type\": String(\"struct\"),\n}\n\n## Please keep the following in mind:\n\nEntry phrasing:\n\n- Ensure entries are concise and focused.\n- Ensure there are no vague phrases (e.g., avoid starting with \"Illustrates the something something...\"; instead, use direct details like \"The hanging green vines on the garden wall\").\n\nEnsure Clarity and Consistency:\n\n- Use clear, grammatically correct sentences.\n- Maintain a consistent tone and style throughout.\n\nEnrich Content:\n\n- Communicate additional information where appropriate to enhance depth and value.\n- If a mathematical, physical, or otherwise technical background is helpful, please provide it.\n- Ensure that the content is comprehensive and meets all requirements.\n\nFocus Language:\n\n- Use deliberate and precise language.\n- Avoid vague verbs and keep the maximally intelligent and detail oriented audience in mind. \n- We explicitly ban the words `hush`, `subtle`, `mythic`, and `aura`. Please keep your vocabulary choices rigorous.\n- Do not use modern cultural references \n- Do not generically reference ideas which do not belong in the global environment.\n\n## Present the Final JSON:\n\n- Format the output as a JSON object.\n- Include all fields properly named from the schema we sent you.\n\nEnsure Proper Formatting:\n\n- Use proper JSON syntax with keys and arrays.\n- Ensure that all entries are correctly placed in their respective places.\n\nProvide only the final JSON data as specified by the schema. \n\nDo not include any schema generation instructions, meta-fields, nested-templates (unless directly asked) or extraneous information. \n\nProvide only the populated fields and their values, conforming exactly to the required structure without embedding any intermediate annotations or placeholders.\n\nYour output should only consist of the JSON object. do *not* include a preamble or postamble to your response. \n\nWe seek to successfully parse your response directly as JSON.\n\nFor the final answer, output the result only as a valid JSON object, wrapped inside triple backticks with json immediately after the opening backticks.\nThe JSON must be parser-ready:\n– No additional text before or after the block\n– No markdown or prose outside the fenced block\n– No HTML escaping of quotes, slashes, or other characters\n– Indentation and whitespace preserved exactly as written\n– The content between the fences must be valid JSON as per RFC 8259","role":"system"},{"content":"We have a rust crate named 'bitcoin-string' 0.1.19. \n\nHere is the interface:\n/**\n| Used by SanitizeString()\n|\n*/\npub enum SafeChars {\n    SAFE_CHARS_DEFAULT,\n    SAFE_CHARS_UA_COMMENT,\n    SAFE_CHARS_FILENAME,\n    SAFE_CHARS_URI,\n}\n\npub trait ToUpper {\n    fn to_upper(&self) -> Self;\n}\n\n\npub trait ToLower {\n    fn to_lower(&self) -> Self;\n}\n\npub type TranslationFn = fn(&str) -> String;\n\nlazy_static! {\n    static ref G_TRANSLATION_FUN_DOES_NOT_ALIAS: RwLock<Option<TranslationFn>> = RwLock::new(None);\n}\n\n\nlazy_static!{\n    pub static ref SAFE_CHARS: Box<[String]> = \n        Box::new([\n            CHARS_ALPHA_NUM.to_owned() + \" .,;-_/:?@()\",            // SAFE_CHARS_DEFAULT\n            CHARS_ALPHA_NUM.to_owned() + \" .,;-_?@\",                // SAFE_CHARS_UA_COMMENT\n            CHARS_ALPHA_NUM.to_owned() + \".-_\",                     // SAFE_CHARS_FILENAME\n            CHARS_ALPHA_NUM.to_owned() + \"!*'();:@&=+$,/?#[]-_.~%\", // SAFE_CHARS_URI\n        ]);\n}\n\n/// A message that carries both the untranslated English text (`original`)\n/// and the user‑language translation (`translated`).\n///\n/// * In the GUI we show **translated text** and fall back to `original` when\n///   no translation is available.\n/// * In the log and on `stderr` we show **English only**.\n#[derive(Debug, Clone, Default, Getters, Setters)]\n#[getset(get = \"pub\")]\npub struct BilingualStr  {\n    original:   String,\n    translated: String,\n}\n\n/**\n| Helper function for ParseFixedPoint\n|\n*/\n#[inline]\npub fn process_mantissa_digit(ch: u8, mantissa: &mut i64, mantissa_tzeros: &mut i32) -> bool {\n    tracing::trace!(\n        target: \"parse_fixed_point\",\n        ch,\n        mantissa_before = *mantissa,\n        mantissa_tzeros_before = *mantissa_tzeros,\n        \"processing mantissa digit\",\n    );\n\n    if ch == b'0' {\n        *mantissa_tzeros += 1;\n        tracing::trace!(\n            mantissa = *mantissa,\n            mantissa_tzeros = *mantissa_tzeros,\n            \"encountered zero digit – incrementing trailing‑zero counter\",\n        );\n        true\n    } else {\n        for iter in 0..=*mantissa_tzeros {\n            if *mantissa > (UPPER_BOUND / 10) {\n                tracing::warn!(\n                    mantissa = *mantissa,\n                    mantissa_tzeros = *mantissa_tzeros,\n                    \"overflow detected while scaling mantissa (iteration = {iter})\",\n                );\n                return false;\n            }\n            *mantissa *= 10;\n            tracing::trace!(\n                iter,\n                scaled_mantissa = *mantissa,\n                \"scaled mantissa by 10 due to trailing zeros/non‑zero digit\",\n            );\n        }\n\n        *mantissa += (ch - b'0') as i64;\n        *mantissa_tzeros = 0;\n        tracing::trace!(\n            mantissa_after = *mantissa,\n            \"added non‑zero digit and reset trailing‑zero counter\",\n        );\n        true\n    }\n}\n\n\n/// Generic helper that reproduces the exact control‑flow of the original C++\n/// `ParseIntegral`.  \n/// * Rejects the legacy “`+-`” prefix.  \n/// * Accepts one leading `'+'` by stripping it before parsing.  \n/// * Requires the *entire* string to be a valid, in‑range integer.  \n///\n/// On success, the parsed value is written to `out` **iff** the pointer is\n/// non‑null and the function returns `true`.\npub fn parse_integral<T>(str_: &str, out: *mut T) -> bool where\n    T: std::str::FromStr + Copy + std::fmt::Debug,\n    <T as std::str::FromStr>::Err: std::fmt::Debug\n{\n    trace!(input = %str_, \"parse_integral entered\");\n\n    // Reject the historical “+-” sequence verbatim.\n    if str_.len() >= 2 && &str_[..1] == \"+\" && &str_[1..2] == \"-\" {\n        debug!(\"leading '+-' sequence detected – refusing to parse\");\n        return false;\n    }\n\n    // Strip a single leading '+' (matches strtol/strtoul behaviour).\n    let slice = if str_.starts_with('+') { &str_[1..] } else { str_ };\n\n    match slice.parse::<T>() {\n        Ok(val) => {\n            if !out.is_null() {\n                // SAFETY: caller provided a mutable pointer they own, mirroring the C++ API.\n                unsafe { *out = val };\n                info!(?val, \"parsed value stored through out‑pointer\");\n            } else {\n                debug!(\"out pointer is null – result intentionally discarded\");\n            }\n            true\n        }\n        Err(e) => {\n            error!(%slice, error = ?e, \"failed to parse integral\");\n            false\n        }\n    }\n}\n\n\n/// Strict 32‑bit signed parse.\npub fn parse_int32(str_: &String, out: *mut i32) -> bool {\n    parse_integral::<i32>(str_.as_str(), out)\n}\n\n\n/// Strict 64‑bit signed parse.\npub fn parse_int64(str_: &String, out: *mut i64) -> bool {\n    parse_integral::<i64>(str_.as_str(), out)\n}\n\n\n/// Strict 8‑bit unsigned parse.\npub fn parse_uint8(str_: &str, out: *mut u8) -> bool {\n    parse_integral::<u8>(str_, out)\n}\n\n\n/// Strict 16‑bit unsigned parse.\npub fn parse_uint16(str_: &str, out: *mut u16) -> bool {\n    parse_integral::<u16>(str_, out)\n}\n\n\n/// Strict 32‑bit unsigned parse.\npub fn parse_uint32(str_: &str, out: *mut u32) -> bool {\n    parse_integral::<u32>(str_, out)\n}\n\n\n/// Strict 64‑bit unsigned parse.\npub fn parse_uint64(str_: &str, out: *mut u64) -> bool {\n    parse_integral::<u64>(str_, out)\n}\n\n\n#[inline]\npub fn trim_string(str_: &String, pattern: Option<&str>) -> String {\n    trace!(target: \"string_utils\", input = %str_, ?pattern, \"Starting trim_string\");\n    //note: removed \\f and \\v from the c++ default\n    //pattern\n    let pattern: &str = pattern.unwrap_or(\" \\n\\r\\t\");\n    let trimmed = str_\n        .trim_matches(|c| pattern.contains(c))\n        .to_string();\n    trace!(target: \"string_utils\", output = %trimmed, \"Completed trim_string\");\n    trimmed\n}\n\n\n#[inline]\npub fn remove_prefix(str_: &String, prefix: &String) -> String {\n    trace!(\n        target: \"string_utils\",\n        input = %str_,\n        prefix = %prefix,\n        \"Starting remove_prefix\"\n    );\n    let out = if str_.starts_with(prefix) {\n        str_[prefix.len()..].to_string()\n    } else {\n        str_.clone()\n    };\n    trace!(target: \"string_utils\", output = %out, \"Completed remove_prefix\");\n    out\n}\n\n\npub fn join(list: &Vec<String>, separator: &str) -> String {\n    trace!(\n        target: \"string_utils\",\n        list_len = list.len(),\n        separator = %separator,\n        \"Starting join\"\n    );\n    let out = list.join(separator);\n    trace!(target: \"string_utils\", output = %out, \"Completed join\");\n    out\n}\n\n\n/**\n| Create an unordered multi-line list\n| of items.\n|\n*/\n#[inline]\npub fn make_unordered_list(items: &Vec<String>) -> String {\n    trace!(\n        target: \"string_utils\",\n        items_len = items.len(),\n        \"Starting make_unordered_list\"\n    );\n    let out = items\n        .iter()\n        .map(|item| format!(\"- {}\", item))\n        .collect::<Vec<String>>()\n        .join(\"\\n\");\n    trace!(target: \"string_utils\", output = %out, \"Completed make_unordered_list\");\n    out\n}\n\n\n/**\n| Check if a string does not contain any\n| embedded NUL (\\0) characters\n|\n*/\n#[inline]\npub fn valid_as_cstring(str_: &str) -> bool {\n    trace!(target: \"string_utils\", input = ?str_, \"Starting valid_as_cstring\");\n    let valid = !str_.as_bytes().contains(&0);\n    trace!(target: \"string_utils\", valid, \"Completed valid_as_cstring\");\n    valid\n}\n\n\n/**\n| Locale-independent version of std::to_string\n|\n*/\npub fn to_string<T: std::fmt::Display>(t: &T) -> String {\n    trace!(target: \"string_utils\", \"Starting to_string\");\n    let out = format!(\"{}\", t);\n    trace!(target: \"string_utils\", output = %out, \"Completed to_string\");\n    out\n}\n\n\n/**\n| Check whether a container begins with\n| the given prefix.\n|\n*/\n#[inline]\npub fn has_prefix<T1, const PREFIX_LEN: usize>(obj: &T1, prefix: &[u8; PREFIX_LEN]) -> bool where\n    T1: AsRef<[u8]>\n{\n    let buf = obj.as_ref();\n    trace!(\n        target: \"string_utils\",\n        obj_len = buf.len(),\n        prefix_len = PREFIX_LEN,\n        \"Starting has_prefix\"\n    );\n    let result = buf.len() >= PREFIX_LEN && &buf[..PREFIX_LEN] == prefix;\n    trace!(target: \"string_utils\", result, \"Completed has_prefix\");\n    result\n}\n\n\n/// Parse number as fixed point according to JSON number syntax.\n/// \n/// See https://json.org/number.gif\n/// ----------- @note\n/// The result must be in the range (-10^18,10^18), otherwise an overflow error will trigger.\n/// ----------- @return\n/// true on success, false on error.\n///\n/// ----------- @ note\n/// Parse a JSON‐syntax number into a signed 64‑bit fixed‑point value.\n/// * `val`      – Text representation of the number (JSON number grammar).\n/// * `decimals` – Number of implied decimal places in the *target* fixed‑point type.\n/// * `amount_out` – Destination for the parsed mantissa; may be a null pointer.\n/// Returns **`true`** on success or **`false`** if the input is out‑of‑range,\n/// malformed, or cannot be represented with the requested precision.\n/// The resulting integer is guaranteed to lie strictly inside the range\n/// `(-10¹⁸, 10¹⁸)`.\npub fn parse_fixed_point(val: &str, decimals: i32, amount_out: *mut i64) -> bool {\n    const UPPER_BOUND: i64 = 1_000_000_000_000_000_000 - 1; // 10¹⁸ − 1\n\n    debug!(input = %val, decimals, \"parse_fixed_point: start\");\n\n    let mut mantissa: i64 = 0;\n    let mut exponent: i64 = 0;\n    let mut mantissa_tzeros: i32 = 0;\n    let mut mantissa_sign = false;\n    let mut exponent_sign = false;\n    let mut ptr: usize = 0;\n    let end = val.len();\n    let mut point_ofs: i32 = 0;\n    let bytes = val.as_bytes();\n\n    /* sign */\n    if ptr < end && bytes[ptr] == b'-' {\n        mantissa_sign = true;\n        ptr += 1;\n    }\n\n    /* integer part */\n    if ptr < end {\n        match bytes[ptr] {\n            b'0' => ptr += 1, /* single zero */\n            b'1'..=b'9' => {\n                while ptr < end && bytes[ptr].is_ascii_digit() {\n                    if !process_mantissa_digit(bytes[ptr], &mut mantissa, &mut mantissa_tzeros) {\n                        error!(\"mantissa overflow while scanning integer part\");\n                        return false;\n                    }\n                    ptr += 1;\n                }\n            }\n            _ => return false, /* expected digit */\n        }\n    } else {\n        return false; /* empty string or bare '-' */\n    }\n\n    /* fractional part */\n    if ptr < end && bytes[ptr] == b'.' {\n        ptr += 1;\n        if ptr < end && bytes[ptr].is_ascii_digit() {\n            while ptr < end && bytes[ptr].is_ascii_digit() {\n                if !process_mantissa_digit(bytes[ptr], &mut mantissa, &mut mantissa_tzeros) {\n                    error!(\"mantissa overflow while scanning fractional part\");\n                    return false;\n                }\n                ptr += 1;\n                point_ofs += 1;\n            }\n        } else {\n            return false; /* expected digit after '.' */\n        }\n    }\n\n    /* exponent */\n    if ptr < end && (bytes[ptr] == b'e' || bytes[ptr] == b'E') {\n        ptr += 1;\n        if ptr < end && bytes[ptr] == b'+' {\n            ptr += 1;\n        } else if ptr < end && bytes[ptr] == b'-' {\n            exponent_sign = true;\n            ptr += 1;\n        }\n\n        if ptr < end && bytes[ptr].is_ascii_digit() {\n            while ptr < end && bytes[ptr].is_ascii_digit() {\n                if exponent > UPPER_BOUND / 10 {\n                    error!(\"exponent overflow\");\n                    return false;\n                }\n                exponent = exponent * 10 + (bytes[ptr] - b'0') as i64;\n                ptr += 1;\n            }\n        } else {\n            return false; /* expected digit after 'e' or 'E' */\n        }\n    }\n\n    if ptr != end {\n        return false; /* trailing garbage */\n    }\n\n    /* apply exponent sign and adjust for decimal point + trimmed zeros */\n    if exponent_sign {\n        exponent = -exponent;\n    }\n    exponent = exponent - point_ofs as i64 + mantissa_tzeros as i64;\n\n    /* apply mantissa sign */\n    if mantissa_sign {\n        mantissa = -mantissa;\n    }\n\n    /* convert to unified fixed‑point value */\n    exponent += decimals as i64;\n    if exponent < 0 || exponent >= 18 {\n        return false; /* under‑ or overflow */\n    }\n\n    for _ in 0..(exponent as usize) {\n        if mantissa > UPPER_BOUND / 10 || mantissa < -UPPER_BOUND / 10 {\n            error!(\"mantissa overflow during scaling\");\n            return false;\n        }\n        mantissa *= 10;\n    }\n\n    if mantissa > UPPER_BOUND || mantissa < -UPPER_BOUND {\n        return false; /* final overflow check */\n    }\n\n    if !amount_out.is_null() {\n        // SAFETY: caller opted‑in by providing a non‑null pointer.\n        unsafe { *amount_out = mantissa };\n    }\n\n    debug!(result = mantissa, \"parse_fixed_point: success\");\n    true\n}\n\n\n/// Convert **`str_`** to an integral value of type **`T`**.\n///\n/// * Rejects leading or trailing whitespace.\n/// * Rejects a leading **`+`**.\n/// * Accepts a leading **`-`** *only* for signed integer targets.\n/// * Rejects any trailing characters.\n/// Returns `None` if parsing fails or the value is out‑of‑range.\npub fn to_integral<T>(str_: &str) -> Option<T> where\n    T: num_traits::PrimInt + std::str::FromStr + std::fmt::Debug\n{\n    // Disallow leading/trailing whitespace.\n    if str_.trim() != str_ {\n        trace!(target: \"to_integral\", input = str_, \"whitespace rejected\");\n        return None;\n    }\n\n    // Explicitly forbid a leading ‘+’.\n    if str_.starts_with('+') {\n        trace!(target: \"to_integral\", input = str_, \"leading '+' rejected\");\n        return None;\n    }\n\n    match str_.parse::<T>() {\n        Ok(val) => {\n            debug!(target: \"to_integral\", input = str_, ?val, \"parse successful\");\n            Some(val)\n        }\n        Err(_) => {\n            trace!(target: \"to_integral\", input = str_, \"parse failed\");\n            None\n        }\n    }\n}\n\n\n/// Tests if the given character byte represents an ASCII decimal digit (0‑9).\n#[inline]\npub fn is_digit(c: u8) -> bool {\n    let res = c >= b'0' && c <= b'9';\n    trace!(\"is_digit({}) = {}\", c, res);\n    res\n}\n\n\n/// Tests if the given character byte is one of the ASCII whitespace characters:\n/// space, form‑feed (`\\f`), newline (`\\n`), carriage return (`\\r`),\n/// horizontal tab (`\\t`), or vertical tab (`\\v`).\n#[inline]\npub fn is_space(c: u8) -> bool {\n    let res = matches!(c, b' ' | b'\\n' | b'\\r' | b'\\t' | 0x0C /* '\\f' */ | 0x0B /* '\\v' */);\n    trace!(\"is_space({}) = {}\", c, res);\n    res\n}\n\n\n/// Encode bytes to Base64 (RFC 4648, with `=` padding).\npub fn encode_base64_bytes(input: &[u8]) -> String {\n    const TABLE: &[u8; 64] =\n        b\"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/\";\n    trace!(\"encode_base64_bytes: len={}\", input.len());\n\n    let mut out = String::with_capacity(((input.len() + 2) / 3) * 4);\n    convert_bits::<8, 6, true, _, _>(input.iter().copied(), |v| {\n        out.push(TABLE[v as usize] as char)\n    });\n    while out.len() % 4 != 0 {\n        out.push('=');\n    }\n    out\n}\n\n\n/// Encode a UTF‑8 string to Base64.\npub fn encode_base64(s: &String) -> String {\n    encode_base64_bytes(s.as_bytes())\n}\n\n\n/// Encode bytes to Base32 (lower‑case RFC 4648 alphabet).\n///\n/// When `pad` is `true`, output is padded with `=` to a multiple of 8.\npub fn encode_base32_bytes(input: &[u8], pad: Option<bool>) -> String {\n    const TABLE: &[u8; 32] = b\"abcdefghijklmnopqrstuvwxyz234567\";\n    let pad = pad.unwrap_or(true);\n    trace!(\n        \"encode_base32_bytes: len={}, pad={}\",\n        input.len(),\n        pad\n    );\n\n    let mut out = String::with_capacity(((input.len() + 4) / 5) * 8);\n    convert_bits::<8, 5, true, _, _>(input.iter().copied(), |v| {\n        out.push(TABLE[v as usize] as char)\n    });\n    if pad {\n        while out.len() % 8 != 0 {\n            out.push('=');\n        }\n    }\n    out\n}\n\n\n/// Base32 encode.\n/// \n/// If `pad` is true, then the output will be padded with '=' so that its length is a multiple of 8.\n///\n/// Encode arbitrary bytes to Base32.\npub fn encode_base32(input: &[u8], pad: Option<bool>) -> String {\n    encode_base32_bytes(input, pad)\n}\n\n\n/**\n| Do not use these functions to represent\n| or parse monetary amounts to or from\n| \n| JSON but use AmountFromValue and ValueFromAmount\n| for that.\n|\n*/\npub fn format_money(n: Amount) -> String {\n    trace!(\"format_money: input = {}\", n);\n    const_assert!(COIN > 1);\n\n    let mut quotient = n / COIN;\n    let mut remainder = n % COIN;\n\n    /* work with positive values for string‑formatting */\n    let negative = n < 0;\n    if negative {\n        quotient = -quotient;\n        remainder = -remainder;\n    }\n\n    let mut out = format!(\"{quotient}.{remainder:08}\");\n\n    /* trim super‑fluous trailing ‘0’s, but never past the decimal point */\n    while out.ends_with('0') {\n        let len = out.len();\n        /* stop if the previous character is the decimal point */\n        if len >= 2 && out.as_bytes()[len - 2] == b'.' {\n            break;\n        }\n        out.pop();\n    }\n\n    if negative {\n        out.insert(0, '-');\n    }\n    trace!(\"format_money: output = {}\", out);\n    out\n}\n\n\n/// Remove unsafe chars. Safe chars chosen to allow simple messages/URLs/email addresses, but\n/// avoid anything even possibly remotely dangerous like & or >\n/// \n/// ----------- @param[in] str\n/// The string to sanitize ---------- @param[in] rule\n/// The set of safe chars to choose (default: least restrictive)\n/// ----------- @return\n/// A new string without unsafe chars\n/// ------------------------------------- @note\n///\n/// Remove unsafe characters from `str_` according to the chosen `rule`.\n/// The implementation follows the original C++ control‑flow literally:\n/// iterate over every character and copy it to the result only if it occurs\n/// in the selected entry of `SAFE_CHARS`.\n#[tracing::instrument(level = \"trace\", skip(str_, rule))]\npub fn sanitize_string(str_: &str, rule: Option<i32>) -> String {\n    let mut selected_rule = rule.unwrap_or(SafeChars::SAFE_CHARS_DEFAULT as i32);\n\n    // Clamp to a known rule; the C++ code silently assumed callers were well‑behaved,\n    // but we add a warning and fall back to the default if we receive nonsense.\n    if selected_rule < 0 || selected_rule as usize >= SAFE_CHARS.len() {\n        warn!(\n            selected_rule,\n            \"invalid SafeChars value supplied – falling back to SAFE_CHARS_DEFAULT\"\n        );\n        selected_rule = SafeChars::SAFE_CHARS_DEFAULT as i32;\n    }\n\n    let safe_chars = &SAFE_CHARS[selected_rule as usize];\n    let mut result = String::with_capacity(str_.len());\n\n    for ch in str_.chars() {\n        if safe_chars.contains(ch) {\n            result.push(ch);\n        } else {\n            trace!(unsafe_char = %ch, \"filtered out unsafe character\");\n        }\n    }\n\n    result\n}\n\n\n/// Capitalize the first character of the provided ASCII string.\n///\n/// Only bytes in the standard 7‑bit ASCII range are affected; the function is\n/// locale‑independent.\npub fn capitalize(str_: &str) -> String {\n    trace!(\"capitalize: input = {}\", str_);\n    if str_.is_empty() {\n        return str_.to_owned();\n    }\n\n    let mut bytes = str_.as_bytes().to_vec();\n    if let Some(first) = bytes.get_mut(0) {\n        if (*first >= b'a') && (*first <= b'z') {\n            *first = *first - b'a' + b'A';\n        }\n    }\n\n    // SAFETY: the original input is valid UTF‑8 and we only mutate byte 0 in\n    // the ASCII range, so the result is still valid UTF‑8.\n    String::from_utf8(bytes).expect(\"ASCII is valid UTF‑8\")\n}\n\n\n/// Mark a [`BilingualStr`] as untranslated: `original == translated`.\n#[inline]\npub fn untranslated(original: &str) -> BilingualStr {\n    trace!(\"untranslated: {}\", original);\n    BilingualStr {\n        original: original.to_owned(),\n        translated: original.to_owned(),\n    }\n}\n\n\npub fn set_translation_fn(f: Option<TranslationFn>) {\n    trace!(\"set_translation_fn: {:?}\", f.is_some());\n    let mut guard = G_TRANSLATION_FUN_DOES_NOT_ALIAS.write();\n    *guard = f;\n}\n\n\npub fn bilingual_tr(psz: &str) -> BilingualStr {\n    let guard = G_TRANSLATION_FUN_DOES_NOT_ALIAS.read();\n\n    let translated = guard\n        .as_ref()\n        .map(|f| f(psz))\n        .unwrap_or_else(|| psz.to_owned());\n\n    trace!(\"_(): \\\"{}\\\" → \\\"{}\\\"\", psz, translated);\n\n    BilingualStr {\n        original: psz.to_owned(),\n        translated,\n    }\n}\n\n\n/// Decode Base32 into raw bytes (RFC 4648); works on NUL‑terminated C strings.\n///\n/// This is the low‑level worker used by the higher‑level helpers. It\n/// mirrors the upstream behaviour: it accepts padded input, treats any\n/// non‑alphabet character as the start of the padding run, and enforces\n/// the standard length/padding rules.\npub fn decode_base32_bytes(p: *const u8, pf_invalid: Option<*mut bool>) -> Vec<u8> {\n    trace!(\"decode_base32_bytes: start\");\n\n    // SAFETY: caller guarantees `p` is a valid C‑string or NULL.\n    let bytes = unsafe {\n        if p.is_null() {\n            if let Some(ptr) = pf_invalid {\n                *ptr = true;\n            }\n            return Vec::new();\n        }\n        CStr::from_ptr(p as *const std::os::raw::c_char).to_bytes()\n    };\n\n    /* first segment: collect 5‑bit symbols */\n    let mut symbols = Vec::<u8>::with_capacity(bytes.len());\n    let mut idx = 0;\n    for &b in bytes {\n        match decode_base32_val(b) {\n            Some(v) => {\n                symbols.push(v);\n                idx += 1;\n            }\n            None => break,\n        }\n    }\n\n    /* 5 → 8 */\n    let mut ret = Vec::<u8>::with_capacity((symbols.len() * 5) / 8);\n    let mut valid =\n        convert_bits::<5, 8, false, _, _>(symbols.into_iter(), |c| ret.push(c));\n\n    /* padding check */\n    let pad_slice = &bytes[idx..];\n    for &b in pad_slice {\n        if b != b'=' {\n            valid = false;\n            break;\n        }\n    }\n    valid &= bytes.len() % 8 == 0 && pad_slice.len() < 8;\n\n    if let Some(ptr) = pf_invalid {\n        unsafe { *ptr = !valid };\n    }\n    debug!(\"decode_base32_bytes: valid={valid}\");\n    ret\n}\n\n\n/// Decode a Rust `&str` that is padded RFC4648 Base32 into raw bytes.\n///\n/// This is a safer, byte‑oriented alternative that does **not** attempt\n/// UTF‑8 decoding; callers that need text can interpret the bytes\n/// themselves. It preserves and reports validity via `pf_invalid`.\npub fn decode_base32_bytes_strict(s: &str, pf_invalid: Option<*mut bool>) -> Vec<u8> {\n    trace!(\"decode_base32_bytes_strict: start\");\n\n    // Reject interior NUL up‑front to mirror the C‑string semantics.\n    let embedded_nul = s.as_bytes().contains(&0);\n\n    // Prepare NUL‑terminated copy and call the C‑string worker.\n    let mut buf: Vec<u8> = Vec::with_capacity(s.len() + 1);\n    buf.extend_from_slice(s.as_bytes());\n    buf.push(0);\n\n    let mut low_invalid = false;\n    let raw = decode_base32_bytes(buf.as_ptr(), Some(&mut low_invalid as *mut bool));\n\n    let invalid = embedded_nul || low_invalid;\n    if let Some(ptr) = pf_invalid {\n        unsafe { *ptr = invalid };\n    }\n\n    debug!(len = raw.len(), invalid, \"decode_base32_bytes_strict: done\");\n    raw\n}\n\n\n/// Variant used by Tor/I2P code paths: lower‑case alphabet, no '=', and\n/// non‑zero tail bits rejected. This mirrors the custom decoders we had\n/// in `set_tor` and `set_i2p`, but centralises the behaviour here.\n///\n/// Input is a Rust `&str` and we operate directly on raw bytes without\n/// any UTF‑8 post‑processing.\npub fn decode_base32_bytes_nopad_lower(s: &str, pf_invalid: Option<*mut bool>) -> Vec<u8> {\n    trace!(len = s.len(), \"decode_base32_bytes_nopad_lower: start\");\n\n    let mut acc: u32 = 0;\n    let mut bits: u32 = 0;\n    let mut out: Vec<u8> = Vec::with_capacity((s.len() * 5 + 7) / 8);\n    let mut invalid = false;\n\n    for (i, ch) in s.chars().enumerate() {\n        let c = ch.to_ascii_lowercase() as u8;\n        let val = match c {\n            b'a'..=b'z' => (c - b'a') as u32,\n            b'2'..=b'7' => (c - b'2') as u32 + 26,\n            _ => {\n                invalid = true;\n                warn!(index = i, ch = c as u32, \"Invalid base32 character (nopad-lower)\");\n                break;\n            }\n        };\n\n        acc = (acc << 5) | val;\n        bits += 5;\n\n        while bits >= 8 {\n            let byte = ((acc >> (bits - 8)) & 0xFF) as u8;\n            out.push(byte);\n            bits -= 8;\n        }\n    }\n\n    if !invalid && bits > 0 {\n        // For unpadded base32, leftover bits must be zero.\n        let mask = (1u32 << bits) - 1;\n        if (acc & mask) != 0 {\n            invalid = true;\n            warn!(remaining_bits = bits, \"Non‑zero leftover bits in base32 tail (nopad-lower)\");\n        }\n    }\n\n    if let Some(ptr) = pf_invalid {\n        unsafe { *ptr = invalid };\n    }\n\n    if invalid {\n        out.clear();\n    }\n\n    debug!(decoded_len = out.len(), invalid, \"decode_base32_bytes_nopad_lower: done\");\n    out\n}\n\n\n/// Decode padded Base32 into a UTF‑8 string.\n///\n/// This is the legacy string‑oriented API which keeps its semantics:\n/// it decodes to bytes and then attempts `String::from_utf8`, returning\n/// the empty string on failure. For binary payloads (like Tor/I2P) the\n/// byte‑level helpers above should be preferred.\npub fn decode_base32(s: &str, pf_invalid: Option<*mut bool>) -> String {\n    trace!(\"decode_base32: start\");\n\n    // Detect interior NULs up‑front so we can mirror the upstream\n    // behaviour that treats them as a hard failure.\n    let embedded_nul = s.as_bytes().contains(&0);\n\n    /* prepare NUL‑terminated copy */\n    let mut buf: Vec<u8> = Vec::with_capacity(s.len() + 1);\n    buf.extend_from_slice(s.as_bytes());\n    buf.push(0);\n\n    /* run the core decoder while capturing its validity flag */\n    let mut local_invalid = false;\n    let raw = decode_base32_bytes(\n        buf.as_ptr(),\n        Some(&mut local_invalid as *mut bool),\n    );\n\n    /* combine flags: either the low‑level decoder found an error\n       *or* we discovered interior NUL bytes in the Rust slice       */\n    let invalid = embedded_nul || local_invalid;\n    if let Some(ptr) = pf_invalid {\n        // SAFETY: caller opted‑in by supplying a pointer.\n        unsafe { *ptr = invalid };\n    }\n\n    String::from_utf8(raw).unwrap_or_default()\n}\n\n\n/**\n| LocaleIndependentAtoi is provided for backwards\n| compatibility reasons.\n|\n| New code should use ToIntegral or the ParseInt*\n| functions which provide parse error feedback.\n| The goal of LocaleIndependentAtoi is to\n| replicate the exact defined behaviour of atoi\n| and atoi64 as they behave under the \"C\" locale.\n*/\npub fn locale_independent_atoi<T>(s: &str) -> T where\n    T: std::str::FromStr<Err = std::num::ParseIntError> + Default\n{\n    trace!(\"locale_independent_atoi: input = \\\"{}\\\"\", s);\n    let trimmed = s.trim();\n\n    /* emulate C `atoi` handling of leading “+” and “+-” */\n    let cleaned = if trimmed.starts_with('+') {\n        if trimmed.get(1..2) == Some(\"-\") {\n            trace!(\"locale_independent_atoi: detected \\\"+-\\\" sequence → 0\");\n            return T::default();\n        }\n        &trimmed[1..]\n    } else {\n        trimmed\n    };\n\n    match cleaned.parse::<T>() {\n        Ok(v) => v,\n        Err(_) => {\n            trace!(\"locale_independent_atoi: parse error → 0\");\n            T::default()\n        }\n    }\n}\n\n\n/**\n| Parse an amount denoted in full coins.\n| E.g. \"0.0034\" supplied on the command\n| line. *\n|\n*/\npub fn parse_money(money_string: &String) -> Option<Amount> {\n    trace!(target: \"parse_money\", ?money_string, \"starting parse\");\n\n    /* 1. C‑string validation */\n    if !valid_as_cstring(money_string) {\n        trace!(\"embedded NUL detected – invalid C‑string\");\n        return None;\n    }\n\n    /* 2. trim leading / trailing space */\n    let s = money_string.trim();\n    if s.is_empty() {\n        trace!(\"string empty after trim\");\n        return None;\n    }\n\n    /* 3. scan integral + fractional parts */\n    let mut str_whole = String::with_capacity(10);\n    let mut n_units: i64 = 0;\n    let mut chars = s.chars().peekable();\n\n    while let Some(ch) = chars.next() {\n        if ch == '.' {\n            let mut n_mult: i64 = COIN / 10;\n            while let (Some(&d), true) = (chars.peek(), n_mult > 0) {\n                if d.is_ascii_digit() {\n                    n_units += n_mult * (d as i64 - '0' as i64);\n                    n_mult /= 10;\n                    chars.next();\n                } else {\n                    break;\n                }\n            }\n            break;\n        }\n\n        if ch.is_ascii_whitespace() || !ch.is_ascii_digit() {\n            trace!(%ch, \"invalid character in integral part\");\n            return None;\n        }\n        str_whole.push(ch);\n    }\n\n    /* trailing garbage */\n    if chars.next().is_some() {\n        trace!(\"extraneous trailing characters detected\");\n        return None;\n    }\n\n    /* guards */\n    if str_whole.len() > 10 || !(0..=COIN).contains(&n_units) {\n        trace!(\"integral or fractional part out of range\");\n        return None;\n    }\n\n    /* integral parse */\n    let n_whole: i64 = if str_whole.is_empty() {\n        0\n    } else {\n        match str_whole.parse() {\n            Ok(v) => v,\n            Err(e) => {\n                error!(error = %e, \"failed to parse integral part\");\n                return None;\n            }\n        }\n    };\n\n    /* compose final amount */\n    let value = match n_whole.checked_mul(COIN).and_then(|v| v.checked_add(n_units)) {\n        Some(v) => v,\n        None => {\n            trace!(\"overflow composing final amount\");\n            return None;\n        }\n    };\n\n    if !money_range(&value) {\n        trace!(value, \"value outside valid money range\");\n        return None;\n    }\n\n    trace!(value, \"parse successful\");\n    Some(value)\n}\n\n\n#[inline]\npub fn hex_digit(c: u8) -> i8 {\n    util_hexdigit[c as usize]\n}\n\n\n/// Returns `true` iff every char is hex and the length is even.\npub fn is_hex(s: &str) -> bool {\n    if s.is_empty() || s.len() % 2 != 0 {\n        return false;\n    }\n    s.bytes().all(|b| hex_digit(b) >= 0)\n}\n\n\n/// Returns `true` iff `s` is a (possibly “0x”‑prefixed) hex literal.\npub fn is_hex_number(mut s: &str) -> bool {\n    if s.starts_with(\"0x\") || s.starts_with(\"0X\") {\n        s = &s[2..];\n    }\n    !s.is_empty() && s.bytes().all(|b| hex_digit(b) >= 0)\n}\n\n\n/// Parse a hexadecimal dump (ignores ASCII whitespace).\npub fn parse_hex(psz: &str) -> Vec<u8> {\n    use crate::check::is_space;\n\n    let mut out = Vec::<u8>::with_capacity(psz.len() / 2);\n    let bytes = psz.as_bytes();\n    let mut idx = 0;\n\n    while idx < bytes.len() {\n        /* skip whitespace */\n        while idx < bytes.len() && is_space(bytes[idx]) {\n            idx += 1;\n        }\n        if idx + 2 > bytes.len() {\n            break;\n        }\n        let high = hex_digit(bytes[idx]);\n        let low = hex_digit(bytes[idx + 1]);\n        if high < 0 || low < 0 {\n            break;\n        }\n        out.push(((high as u8) << 4) | (low as u8));\n        idx += 2;\n    }\n    trace!(\"parse_hex: parsed {} bytes\", out.len());\n    out\n}\n\n\n/// Lower‑case hex string from raw bytes.\npub fn hex_str(data: &[u8]) -> String {\n    const HEXMAP: &[u8; 16] = b\"0123456789abcdef\";\n    let mut out = String::with_capacity(data.len() * 2);\n    for &b in data {\n        out.push(HEXMAP[(b >> 4) as usize] as char);\n        out.push(HEXMAP[(b & 0xF) as usize] as char);\n    }\n    out\n}\n\n\n/// Generic bit‑group converter used by the Base{32,64} encoders/decoders.\n///\n/// * `FROM` – size of input symbol in bits  \n/// * `TO`   – size of output symbol in bits  \n/// * `PAD`  – whether residual bits are zero‑padded (`true`)\n/// Returns `false` when the input violates the size/overflow rules described\n/// by BIP‑173 (§5) and RFC 4648.  \n/// The supplied `out` callback is invoked for every produced symbol.\npub fn convert_bits<\n    const FROM: usize,\n    const TO: usize,\n    const PAD: bool,\n    I,\n    O,\n>(input: I, mut out: O) -> bool where\n    I: IntoIterator<Item = u8>,\n    O: FnMut(u8)\n{\n    trace!(\"convert_bits<{FROM},{TO},{PAD}>: start\");\n    debug_assert!(FROM > 0 && FROM <= 8 && TO > 0 && TO <= 8);\n\n    let max_v: usize = (1 << TO) - 1;\n    let max_acc: usize = (1 << (FROM + TO - 1)) - 1;\n\n    let mut acc: usize = 0;\n    let mut bits: usize = 0;\n\n    for value in input {\n        if (value as usize) >> FROM != 0 {\n            trace!(\"convert_bits: value overflow = {value}\");\n            return false; // symbol too large for FROM‑bit representation\n        }\n        acc = ((acc << FROM) | value as usize) & max_acc;\n        bits += FROM;\n        while bits >= TO {\n            bits -= TO;\n            let out_sym = ((acc >> bits) & max_v) as u8;\n            trace!(\"convert_bits: emit {out_sym}\");\n            out(out_sym);\n        }\n    }\n\n    if PAD {\n        if bits > 0 {\n            let out_sym = ((acc << (TO - bits)) & max_v) as u8;\n            trace!(\"convert_bits: pad emit {out_sym}\");\n            out(out_sym);\n        }\n        true\n    } else if bits < FROM && ((acc << (TO - bits)) & max_v) == 0 {\n        true\n    } else {\n        trace!(\"convert_bits: non‑zero leftover bits = {bits}\");\n        false\n    }\n}\n\n\n/// Timing‑attack‑resistant comparison.\n///\n/// The running time is proportional to the length of **`a`** only,\n/// which thwarts simple timing side‑channel attacks.\n/// The function accepts anything that can be borrowed as a byte‑slice\n/// (`&[u8]`) so it works for `Vec<u8>`, `&[u8]`, fixed‑size arrays,\n/// `String`, `&str`, etc.\npub fn timing_resistant_equal<T>(a: &T, b: &T) -> bool where\n    T: AsRef<[u8]> + ?Sized\n{\n    let a_bytes = a.as_ref();\n    let b_bytes = b.as_ref();\n\n    // Short‑circuit for the most divergent case.\n    if b_bytes.is_empty() {\n        trace!(\n            target: \"timing_resistant_equal\",\n            a_len = a_bytes.len(),\n            b_len = 0,\n            \"b is empty – result = {}\",\n            a_bytes.is_empty()\n        );\n        return a_bytes.is_empty();\n    }\n\n    // Step one: accumulate the length difference.\n    let mut acc: usize = a_bytes.len() ^ b_bytes.len();\n\n    // Step two: walk *only* over `a` so timing is length‑dependent on `a`.\n    for (i, &byte_a) in a_bytes.iter().enumerate() {\n        let byte_b = b_bytes[i % b_bytes.len()];\n        acc |= (byte_a ^ byte_b) as usize;\n    }\n\n    let result = acc == 0;\n    debug!(\n        target: \"timing_resistant_equal\",\n        a_len = a_bytes.len(),\n        b_len = b_bytes.len(),\n        equal = result,\n        \"comparison complete\"\n    );\n    result\n}\n\n\n/// Decode Base64 into raw bytes (RFC 4648); works on NUL‑terminated C strings.\npub fn decode_base64_bytes(p: *const u8, pf_invalid: Option<*mut bool>) -> Vec<u8> {\n    trace!(\"decode_base64_bytes: start\");\n\n    // SAFETY: caller guarantees `p` is a valid C‑string or NULL.\n    let bytes = unsafe {\n        if p.is_null() {\n            if let Some(ptr) = pf_invalid {\n                *ptr = true;\n            }\n            return Vec::new();\n        }\n        CStr::from_ptr(p as *const std::os::raw::c_char).to_bytes()\n    };\n\n    let mut symbols = Vec::<u8>::with_capacity(bytes.len());\n    let mut idx = 0;\n    for &b in bytes {\n        match decode_base64_val(b) {\n            Some(v) => {\n                symbols.push(v);\n                idx += 1;\n            }\n            None => break,\n        }\n    }\n\n    let mut ret = Vec::<u8>::with_capacity((symbols.len() * 3) / 4);\n    let mut valid =\n        convert_bits::<6, 8, false, _, _>(symbols.into_iter(), |c| ret.push(c));\n\n    /* padding check */\n    let pad_slice = &bytes[idx..];\n    for &b in pad_slice {\n        if b != b'=' {\n            valid = false;\n            break;\n        }\n    }\n    valid &= bytes.len() % 4 == 0 && pad_slice.len() < 4;\n\n    if let Some(ptr) = pf_invalid {\n        unsafe { *ptr = !valid };\n    }\n    debug!(\"decode_base64_bytes: valid={valid}\");\n    ret\n}\n\n\n/// Decode Base64 returning a UTF‑8 `String`.\npub fn decode_base64(s: &str, pf_invalid: Option<&mut bool>) -> String {\n    trace!(\"decode_base64: start\");\n\n    let embedded_nul = s.as_bytes().contains(&0);\n\n    /* prepare NUL‑terminated copy */\n    let mut buf: Vec<u8> = Vec::with_capacity(s.len() + 1);\n    buf.extend_from_slice(s.as_bytes());\n    buf.push(0);\n\n    /* run the core decoder */\n    let mut local_invalid = false;\n    let raw = decode_base64_bytes(\n        buf.as_ptr(),\n        Some(&mut local_invalid as *mut bool),\n    );\n\n    let invalid = embedded_nul || local_invalid;\n    if let Some(flag) = pf_invalid {\n        *flag = invalid;\n    }\n\n    String::from_utf8(raw).unwrap_or_default()\n}\n\nimpl ToLower for String {\n\n    /**\n    | Returns the lowercase equivalent of\n    | the given string.\n    | \n    | This function is locale independent.\n    | It only converts uppercase characters\n    | in the standard 7-bit ASCII range.\n    | This is a feature, not a limitation.\n    | -----------\n    | @param[in] str\n    | the string to convert to lowercase.\n    | @return\n    | lowercased equivalent of str\n    |\n    */\n    fn to_lower(&self) -> String {\n        trace!(\"to_lower(String): input = {}\", self);\n        let mut out = String::with_capacity(self.len());\n        for &byte in self.as_bytes() {\n            let lowered = if (byte >= b'A') && (byte <= b'Z') {\n                byte - b'A' + b'a'\n            } else {\n                byte\n            };\n            out.push(lowered as char);\n        }\n        out\n    }\n}\n\nimpl ToUpper for String {\n\n    /**\n    | Returns the uppercase equivalent of\n    | the given string.\n    | \n    | This function is locale independent.\n    | It only converts lowercase characters\n    | in the standard 7-bit ASCII range.\n    | This is a feature, not a limitation.\n    | -----------\n    | @param[in] str\n    | the string to convert to uppercase.\n    | @return\n    | UPPERCASED EQUIVALENT OF str\n    |\n    */\n    fn to_upper(&self) -> String {\n        trace!(\"to_upper(String): input = {}\", self);\n        let mut out = String::with_capacity(self.len());\n        for &byte in self.as_bytes() {\n            let uppered = if (byte >= b'a') && (byte <= b'z') {\n                byte - b'a' + b'A'\n            } else {\n                byte\n            };\n            out.push(uppered as char);\n        }\n        out\n    }\n}\n\nimpl ToLower for u8 {\n\n    /**\n    | Converts the given character to its\n    | lowercase equivalent.\n    | \n    | This function is locale independent.\n    | It only converts uppercase characters\n    | in the standard 7-bit ASCII range.\n    | This is a feature, not a limitation.\n    | -----------\n    | @param[in] c\n    | the character to convert to lowercase.\n    | @return\n    | the lowercase equivalent of c; or the\n    | argument if no conversion is possible.\n    |\n    */\n    #[inline]\n    fn to_lower(&self) -> u8 {\n        let c = *self;\n        if (c >= b'A') && (c <= b'Z') {\n            c - b'A' + b'a'\n        } else {\n            c\n        }\n    }\n}\n\nimpl ToUpper for u8 {\n\n    /**\n    | Converts the given character to its\n    | uppercase equivalent.\n    | \n    | This function is locale independent.\n    | It only converts lowercase characters\n    | in the standard 7-bit ASCII range.\n    | This is a feature, not a limitation.\n    | -----------\n    | @param[in] c\n    | the character to convert to uppercase.\n    | @return\n    | the uppercase equivalent of c; or the\n    | argument if no conversion is possible.\n    |\n    */\n    #[inline]\n    fn to_upper(&self) -> u8 {\n        let c = *self;\n        if (c >= b'a') && (c <= b'z') {\n            c - b'a' + b'A'\n        } else {\n            c\n        }\n    }\n}\n\nimpl AddAssign<&BilingualStr> for BilingualStr {\n\n    #[inline]\n    fn add_assign(&mut self, other: &BilingualStr) {\n        trace!(\n            \"BilingualStr::add_assign: self = ({}, {}), other = ({}, {})\",\n            self.original,\n            self.translated,\n            other.original,\n            other.translated\n        );\n        self.original += &other.original;\n        self.translated += &other.translated;\n    }\n}\n\nimpl BilingualStr {\n\n    /// Returns `true` when the *original* string is empty.\n    #[inline]\n    pub fn empty(&self) -> bool {\n        self.original.is_empty()\n    }\n\n    /// Clear both the original and the translated strings.\n    #[inline]\n    pub fn clear(&mut self) {\n        trace!(\"BilingualStr::clear before = {:?}\", self);\n        self.original.clear();\n        self.translated.clear();\n        debug!(\"BilingualStr::clear after  = {:?}\", self);\n    }\n}\n\nimpl Add<&BilingualStr> for BilingualStr {\n\n    type Output = BilingualStr;\n\n    #[inline]\n    fn add(mut self, other: &BilingualStr) -> Self::Output {\n        self += other;\n        self\n    }\n}\n\nimpl From<&str> for BilingualStr {\n\n    #[inline]\n    fn from(s: &str) -> Self {\n        untranslated(s)\n    }\n}\n\n\nmod tinyformat {\n    /// Format with `format!`, once for each language half.\n    ///\n    /// ```ignore\n    /// let hello = bilingual_format!(\"Hello, {}\", name);\n    /// ```\n    #[macro_export]\n    macro_rules! bilingual_format { {\n            ($tmpl:expr $(, $arg:expr)* $(,)?) => {{\n                let bs: &BilingualStr = &$tmpl;\n                BilingualStr {\n                    original: format!(bs.original.as_str() $(, $arg)*),\n                    translated: format!(bs.translated.as_str() $(, $arg)*),\n                }\n            }};\n        } }\n\n    /// When direct macro use is infeasible, fall back to this helper.\n    pub fn format(bs: &BilingualStr, args_original: String, args_translated: String) -> BilingualStr {\n        // Note: buyers beware – the two `String` parameters must already contain\n        // all replacements performed externally. This keeps implementation\n        // simple while covering the limited in‑tree use‑cases.\n        BilingualStr {\n            original: args_original,\n            translated: args_translated,\n        }\n    }\n}\n\n\nThis crate has the following authors:\n[\n    \"klebs <none>\",\n]\nThis crate has the following rust edition:\n2021\nThis crate has the following license:\nMIT\nThis crate is held in the following repository:\nhttps://github.com/klebs6/bitcoin-rs\n","role":"user"}],"model":"gpt-5.1"}}
