{"custom_id":"bitcoin-hash-ai-readme-request","method":"POST","url":"/v1/chat/completions","body":{"max_completion_tokens":8192,"messages":[{"content":"We would like you to write a README.md for a rust crate with maximally helpful content.\nAdditionally, we would like you to generate several fields from the Cargo.toml package section for this crate.\nWe will show you the strict json output format we would like you to provide.\nPlease tailor your response for an apex consumer of maximal intelligence.\nA reader of this README.md should have a good sense of what the crate does and how to use it after reading what you write.\nPlease include a messaage indicating that this README.md file was generated by an AI model and may not be 100% accurate however it should be pretty good.\n\n\nCarefully read and parse the information we sent you.\n\nWe want to generate all information items requested by our schema:\n\n- Read the description of each field. Use it, along with the content we sent you to generate an appropriate value for each.\n- Ensure that each generated field optimally serves its desired purpose.\n- Each item should be deep, detailed, and specific. Use optimally descriptive and useful language. Do not be too verbose.\n- Do not add any extra keys to the generated object. Generate precisely what we ask of you: no more, no less.\n- For fields which are of an enum type: pick *exactly one variant*. Do not generate any information for the unselected variants.\n- For array fields: supply a JSON list [ ... ] of items, each conforming to the correct item type.\n- For map fields: Provide a JSON object { \"key_as_string\": <value>, ... }. Keys must be valid JSON strings. Keys and Values must conform to the key and value schemas we provide to you. Fill all subfields of each and every map value.\n- If we ask you to justify a map field, provide your justification/confidence score for the entire map. Do not attempt to separately justify each map element.\n- Likewise, if we ask you to justify an array field, provide your justification/confidence score for the entire array. Do not attempt to separately justify each element.\n- Provide numeric fields as real JSON numbers (not strings).\n- For string fields: provide the value precisely as a string literal. If optional, you may set it to null.\n- If we ask you to justify or provide confidence scores for the fields of a structure, please do so carefully. For each field we ask you to justify, please explain or justify your choice clearly. Confidence scores must be specified as real JSON numbers in the range `[0..1]`.\n- If we ask to you generate an optional field, either fill it or set it to null.\n- If we ask you to justify your choice of an enum variant, please explain your choice clearly. Do not justify your decision to leave a variant unselected. Provide your justification as a JSON string. Provide your confidence score as a real JSON number in the range `[0..1]`.\n- In terms of the JSON format we would like you to provide, the object itself will be deserialied based on the following schema. \n- We begin exactly at the top: the data should not be nested under a parent named 'fields' or anything similar.\n\n## Here is the schema to use:\n\nObject {\n    \"fields\": Object {\n        \"crate_name\": Object {\n            \"generation_instructions\": String(\"\\\"This string should be the name of our crate, *verbatim*, trimmed for use as a toml field\\\"\"),\n            \"required\": Bool(true),\n            \"type\": String(\"string\"),\n        },\n        \"full_readme_markdown\": Object {\n            \"generation_instructions\": String(\"\\\"This string should be valid markdown representing the readme for this crate.\\\\n\\\\n Please make it terse, useful, and designed for an industrious commercially savy consumer of industrious nature. \\\\n\\\\n Advanced vocabulary and concepts are welcome. \\\\n\\\\n If this crate involves concepts from mathematics and/or physics, please describe and document them here.\\\"\"),\n            \"required\": Bool(true),\n            \"type\": String(\"string\"),\n        },\n        \"package_categories\": Object {\n            \"generation_instructions\": String(\"\\\"These categories will be used in our Cargo.toml file.\\\\n\\\\n It is important that users of this crate can find it on crates.io.\\\\n\\\\n Choose maximum 5 categories and make sure they are actually meaningful for our crate.\\\\n\\\\n These categories should only be chosen from among the legal crates.io categories. \\\\n\\\\n The ONLY legal categoreis are:\\\\n\\\\n``\\\\n accessibility\\\\n aerospace\\\\n algorithms\\\\n api-bindings\\\\n asynchronous\\\\n authentication\\\\n caching\\\\n command-line-interface\\\\n command-line-utilities\\\\n compilers\\\\n compression\\\\n computer-vision\\\\n concurrency\\\\n config\\\\n cryptography\\\\n data-structures\\\\n database\\\\n database-implementations\\\\n date-and-time\\\\n development-tools\\\\n email\\\\n embedded\\\\n emulators\\\\n encoding\\\\n external-ffi-bindings\\\\n filesystem\\\\n finance\\\\n game-development\\\\n game-engines\\\\n games\\\\n graphics\\\\n gui\\\\n hardware-support\\\\n internationalization\\\\n localization\\\\n mathematics\\\\n memory-management\\\\n multimedia\\\\n network-programming\\\\n no-std\\\\n os\\\\n parser-implementations\\\\n parsing\\\\n rendering\\\\n rust-patterns\\\\n science\\\\n simulation\\\\n template-engine\\\\n text-editors\\\\n text-processing\\\\n value-formatting\\\\n virtualization\\\\n visualization\\\\n wasm\\\\n web-programming\\\\n ``\\\\n\\\\n DO NOT specify a category that is not on this list.\\\"\"),\n            \"required\": Bool(true),\n            \"type\": String(\"array_of_strings\"),\n        },\n        \"package_description\": Object {\n            \"generation_instructions\": String(\"\\\"We will place this package_description in our Cargo.toml file so the users of this crate\\\\n know what it does.\\\\n\\\\n The discription should be technical, clear, and useful. It should be terse.\\\"\"),\n            \"required\": Bool(true),\n            \"type\": String(\"string\"),\n        },\n        \"package_keywords\": Object {\n            \"generation_instructions\": String(\"\\\"These keywords will be used in our Cargo.toml file so the users of this crate can easily\\\\n find it in the package system. Keywords should be useful, varied, meaningful, and reflect\\\\n the contents of our crate. They should make it easy to find. Please provide exactly five.\\\"\"),\n            \"required\": Bool(true),\n            \"type\": String(\"array_of_strings\"),\n        },\n    },\n    \"struct_docs\": String(\" This structure is a directive indicating which fields we need you to provide for us in your response to our query.\\n\"),\n    \"struct_name\": String(\"AiReadmeWriterDesiredOutput\"),\n    \"type\": String(\"struct\"),\n}\n\n## Please keep the following in mind:\n\nEntry phrasing:\n\n- Ensure entries are concise and focused.\n- Ensure there are no vague phrases (e.g., avoid starting with \"Illustrates the something something...\"; instead, use direct details like \"The hanging green vines on the garden wall\").\n\nEnsure Clarity and Consistency:\n\n- Use clear, grammatically correct sentences.\n- Maintain a consistent tone and style throughout.\n\nEnrich Content:\n\n- Communicate additional information where appropriate to enhance depth and value.\n- If a mathematical, physical, or otherwise technical background is helpful, please provide it.\n- Ensure that the content is comprehensive and meets all requirements.\n\nFocus Language:\n\n- Use deliberate and precise language.\n- Avoid vague verbs and keep the maximally intelligent and detail oriented audience in mind. \n- We explicitly ban the words `hush`, `subtle`, `mythic`, and `aura`. Please keep your vocabulary choices rigorous.\n- Do not use modern cultural references \n- Do not generically reference ideas which do not belong in the global environment.\n\n## Present the Final JSON:\n\n- Format the output as a JSON object.\n- Include all fields properly named from the schema we sent you.\n\nEnsure Proper Formatting:\n\n- Use proper JSON syntax with keys and arrays.\n- Ensure that all entries are correctly placed in their respective places.\n\nProvide only the final JSON data as specified by the schema. \n\nDo not include any schema generation instructions, meta-fields, nested-templates (unless directly asked) or extraneous information. \n\nProvide only the populated fields and their values, conforming exactly to the required structure without embedding any intermediate annotations or placeholders.\n\nYour output should only consist of the JSON object. do *not* include a preamble or postamble to your response. \n\nWe seek to successfully parse your response directly as JSON.\n\nFor the final answer, output the result only as a valid JSON object, wrapped inside triple backticks with json immediately after the opening backticks.\nThe JSON must be parser-ready:\n– No additional text before or after the block\n– No markdown or prose outside the fenced block\n– No HTML escaping of quotes, slashes, or other characters\n– Indentation and whitespace preserved exactly as written\n– The content between the fences must be valid JSON as per RFC 8259","role":"system"},{"content":"We have a rust crate named 'bitcoin-hash' 0.1.20. \n\nHere is the interface:\npub type MapAssumeUtxo = HashMap<i32,AssumeUtxoData>;\n\nlazy_static!{\n    static ref HASHER_TAPSIGHASH: HashWriter = tagged_hash(\"TapSighash\");\n    static ref HASHER_TAPLEAF:    HashWriter = tagged_hash(\"TapLeaf\");\n    static ref HASHER_TAPBRANCH:  HashWriter = tagged_hash(\"TapBranch\");\n    static ref HASHER_TAPTWEAK:   HashWriter = tagged_hash(\"TapTweak\");\n}\n\n/// An outpoint - a combination of a transaction\n/// hash and an index n into its vout\n#[derive(Clone, Serialize, Deserialize, Getters, MutGetters)]\n#[getset(get=\"pub\")]\npub struct OutPoint  {\n    hash: u256,\n    n:    u32,\n}\n\n\npub struct FilterHeaderHasher  { }\n\n\n#[derive(Clone)]\npub struct SaltedOutpointHasher  {\n    k0:     u64,\n    k1:     u64,\n    hasher: SipHasher,\n}\n\n\npub struct SaltedTxidHasher  {\n    k0: u64,\n    k1: u64,\n}\n\n\n/**\n| We're hashing a nonce into the entries\n| themselves, so we don't need extra blinding\n| in the set hash computation.\n| \n| This may exhibit platform endian dependent\n| behavior but because these are nonced\n| hashes (random) and this state is only\n| ever used locally it is safe.\n| All that matters is local consistency.\n|\n*/\npub struct SignatureCacheHasher  { }\n\n\n/**\n| Implementation of Hash named requirement\n| for types that internally store a byte\n| array. This may be used as the hash function\n| in std::unordered_set or std::unordered_map\n| over such types.\n| \n| Internally, this uses a random instance\n| of SipHash-2-4.\n|\n*/\n#[derive(Debug,Clone)]\npub struct ByteVectorHash  {\n    k0:     u64,\n    k1:     u64,\n    hasher: SipHasher,\n}\n\n\n/**\n| A hasher class for Bitcoin's 256-bit\n| hash (double SHA-256).\n|\n*/\n#[derive(Default)]\npub struct Hash256  {\n    sha: Sha256,\n}\n\n\npub struct SaltedSipHasher  {\n    k0: u64,\n    k1: u64,\n}\n\n\n/// Reads data from an underlying stream,\n/// while hashing the read data.\n///\n/// Stream wrapper that feeds every byte read\n/// into an internal `HashWriter`.\npub struct HashVerifier<S>  {\n    base:   HashWriter,\n    source: S,\n}\n\n\npub struct BlockHasher  { }\n\n\n/**\n| A hasher class for Bitcoin's 160-bit\n| hash (SHA-256 + RIPEMD-160).\n|\n*/\npub struct Hash160  {\n    sha: Sha256,\n}\n\n\n/**\n| A writer stream (for serialization)\n| that computes a 256-bit hash.\n|\n*/\npub struct HashWriter  {\n    ctx:       Sha256,\n    n_type:    i32,\n    n_version: i32,\n}\n\n\npub struct AssumeUtxoHash  {\n    base: BaseHash<u256>,\n}\n\n\n/**\n| Holds configuration for use during\n| UTXO snapshot load and validation.\n| The contents here are security critical,\n| since they dictate which UTXO snapshots\n| are recognized as valid.\n|\n*/\npub struct AssumeUtxoData  {\n    hash_serialized: AssumeUtxoHash,\n    n_chain_tx:      u32,\n}\n\n\n/// Thin wrapper around a fixed‑width hash type that\n/// mirrors Bitcoin Core’s `BaseHash` helpers while\n/// integrating with Rust’s trait ecosystem.\n///\n/// All methods are fully in‑line with the original\n/// C++ semantics (pointer helpers are retained for\n/// 1‑to‑1 porting convenience, even though they are\n/// rarely needed in safe Rust).\n#[derive(Debug,Clone, Getters)]\npub struct BaseHash<HashType> where\n    HashType: Clone\n        + Default\n        + Debug\n        + AsRef<[u8]>\n        + AsMut<[u8]>\n        + Ord\n        + core::fmt::Display {\n    hash: HashType,\n}\n\n/// Little‑endian helper – identical to Bitcoin Core’s `ReadLE64`.\n#[inline]\npub fn read_le64(bytes: &[u8]) -> u64 {\n    let mut tmp = [0u8; 8];\n    tmp.copy_from_slice(&bytes[..8]);\n    u64::from_le_bytes(tmp)\n}\n\n\n#[instrument(level = \"trace\", skip_all)]\npub fn murmur_hash3(n_hash_seed: u32, data_to_hash: &[u8]) -> u32 {\n    const C1: u32 = 0xcc9e2d51;\n    const C2: u32 = 0x1b873593;\n\n    let mut h1 = n_hash_seed;\n    let nblocks = data_to_hash.len() / 4;\n\n    // body\n    for chunk in data_to_hash[..nblocks * 4].chunks_exact(4) {\n        let mut k1 = u32::from_le_bytes(chunk.try_into().expect(\"chunk length is 4\"));\n        k1 = k1.wrapping_mul(C1);\n        k1 = k1.rotate_left(15);\n        k1 = k1.wrapping_mul(C2);\n\n        h1 ^= k1;\n        h1 = h1.rotate_left(13);\n        h1 = h1\n            .wrapping_mul(5)\n            .wrapping_add(0xe654_6b64);\n    }\n\n    // tail\n    let mut k1 = 0u32;\n    match data_to_hash.len() & 3 {\n        3 => {\n            k1 ^= (data_to_hash[nblocks * 4 + 2] as u32) << 16;\n            k1 ^= (data_to_hash[nblocks * 4 + 1] as u32) << 8;\n            k1 ^= data_to_hash[nblocks * 4] as u32;\n            k1 = k1.wrapping_mul(C1);\n            k1 = k1.rotate_left(15);\n            k1 = k1.wrapping_mul(C2);\n            h1 ^= k1;\n        }\n        2 => {\n            k1 ^= (data_to_hash[nblocks * 4 + 1] as u32) << 8;\n            k1 ^= data_to_hash[nblocks * 4] as u32;\n            k1 = k1.wrapping_mul(C1);\n            k1 = k1.rotate_left(15);\n            k1 = k1.wrapping_mul(C2);\n            h1 ^= k1;\n        }\n        1 => {\n            k1 ^= data_to_hash[nblocks * 4] as u32;\n            k1 = k1.wrapping_mul(C1);\n            k1 = k1.rotate_left(15);\n            k1 = k1.wrapping_mul(C2);\n            h1 ^= k1;\n        }\n        _ => {}\n    }\n\n    // finalization\n    h1 ^= data_to_hash.len() as u32;\n    h1 ^= h1 >> 16;\n    h1 = h1.wrapping_mul(0x85eb_ca6b);\n    h1 ^= h1 >> 13;\n    h1 = h1.wrapping_mul(0xc2b2_ae35);\n    h1 ^= h1 >> 16;\n\n    h1\n}\n\n\n/**\n| Compute the 160‑bit (SHA‑256 ➜ RIPEMD‑160) hash of any value that\n| can expose its bytes through `AsRef<[u8]>`.\n|\n| Accepts `?Sized` inputs so callers may pass plain slices.\n*/\n#[inline]\npub fn hash160<T>(in1: &T) -> u160 where\n    T: AsRef<[u8]> + ?Sized\n{\n    let mut out = [0u8; RIPEMD160_OUTPUT_SIZE];\n    Hash160 { sha: Sha256::new() }\n        .write(in1.as_ref())\n        .finalize(&mut out);\n\n    #[allow(clippy::useless_conversion)]\n    u160::from_le_bytes(out)\n}\n\n\n/**\n| Return a `HashWriter` primed for tagged hashes\n| (as specified in BIP‑340).\n|\n| The returned object will have `SHA256(tag)`\n| written to it twice (= 64 bytes).\n*/\npub fn tagged_hash(tag: &str) -> HashWriter {\n    // Hash the tag once …\n    let mut taghash = [0u8; 32];\n    let mut sha = Sha256::new();\n    sha.write(tag.as_bytes());\n    sha.finalize(&mut taghash);\n\n    // … prime a writer with the tag hash twice.\n    let mut writer = HashWriter::new(SER_GETHASH as i32, 0);\n    writer.write(&taghash);\n    writer.write(&taghash);\n    writer\n}\n\n\n/**\n| Compute the 256-bit hash of an object.\n|\n*/\n#[inline]\npub fn hash1<T: AsRef<[u8]>>(in1: T) -> u256 {\n    let mut buf = [0u8; 32];\n    Hash256::default()\n        .write(in1.as_ref())\n        .finalize(&mut buf);\n    u256::from_le_bytes(buf)\n}\n\n\n/**\n| Compute the 256-bit hash of the concatenation\n| of two objects.\n|\n*/\n#[inline]\npub fn hash2<T1: AsRef<[u8]>, T2: AsRef<[u8]>>(in1: T1, in2: T2) -> u256 {\n    let mut buf = [0u8; 32];\n    Hash256::default()\n        .write(in1.as_ref())\n        .write(in2.as_ref())\n        .finalize(&mut buf);\n    u256::from_le_bytes(buf)\n}\n\n\n/// Compute the 256‑bit hash of a binary blob that can expose its\n/// bytes through `AsRef<[u8]>`. Type/version parameters are\n/// currently ignored because the Rust port serialises directly from\n/// the caller‑supplied slice.\n#[inline]\npub fn serialize_hash<T>(obj: &T, _n_type: Option<i32>, _n_version: Option<i32>) -> u256 where\n    T: AsRef<[u8]> + ?Sized\n{\n    hash1(obj.as_ref())\n}\n\n\n#[inline]\npub fn rotl32(x: u32, r: i8) -> u32 {\n    x.rotate_left(r as u32)\n}\n\nimpl OutPoint {\n\n    #[instrument(level = \"debug\")]\n    pub fn new(hash_in: &u256, n_in: u32) -> Self {\n        Self {\n            hash: hash_in.clone(),\n            n:    n_in,\n        }\n    }\n\n    #[instrument(level = \"trace\", skip(self))]\n    pub fn set_null(&mut self) {\n        self.hash = u256::default();\n        self.n = OUT_POINT_NULL_INDEX;\n    }\n\n    #[inline]\n    #[instrument(level = \"trace\", skip(self))]\n    pub fn is_null(&self) -> bool {\n        self.hash == u256::default() && self.n == OUT_POINT_NULL_INDEX\n    }\n\n    /// Human‑readable representation identical to Bitcoin Core’s\n    /// `OutPoint::ToString()`: the first ten hex digits of the txid\n    /// plus the vout index.\n    #[instrument(level = \"trace\", skip(self))]\n    pub fn to_string(&self) -> String {\n        let h = self.hash.to_string();           // 64‑char hex\n        format!(\"OutPoint({}, {})\", &h[..10], self.n)\n    }\n}\n\nimpl fmt::Display for OutPoint {\n\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        let h = self.hash.to_string();\n        write!(f, \"OutPoint({}, {})\", &h[..10], self.n)\n    }\n}\n\nimpl Default for OutPoint {\n\n    #[instrument(level = \"trace\")]\n    fn default() -> Self {\n        Self {\n            hash: u256::default(),\n            n:    OUT_POINT_NULL_INDEX,\n        }\n    }\n}\n\nimpl PartialEq for OutPoint {\n\n    #[inline]\n    fn eq(&self, other: &Self) -> bool {\n        self.hash == other.hash && self.n == other.n\n    }\n}\n\nimpl Eq for OutPoint {}\n\nimpl PartialOrd for OutPoint {\n\n    #[inline]\n    fn partial_cmp(&self, other: &Self) -> Option<Ordering> {\n        Some(self.cmp(other))\n    }\n}\n\nimpl Ord for OutPoint {\n\n    #[inline]\n    fn cmp(&self, other: &Self) -> Ordering {\n        match self.hash.cmp(&other.hash) {\n            Ordering::Equal => self.n.cmp(&other.n),\n            ord => ord,\n        }\n    }\n}\n\nimpl Hash for OutPoint {\n\n    #[instrument(level = \"trace\", skip(self, state))]\n    fn hash<H: Hasher>(&self, state: &mut H) {\n        state.write(self.hash.as_ref());\n        state.write(&self.n.to_le_bytes());\n    }\n}\n\nimpl RecursiveDynamicUsage for OutPoint {\n\n    #[inline]\n    fn recursive_dynamic_usage(&self) -> usize {\n        0\n    }\n}\n\nimpl FilterHeaderHasher {\n\n    #[instrument(level = \"debug\", skip(self, hash))]\n    pub fn invoke(&self, hash: &u256) -> usize {\n        read_le64(hash.as_ref()) as usize\n    }\n}\n\nimpl Default for SaltedOutpointHasher {\n\n    #[instrument(level = \"trace\")]\n    fn default() -> Self {\n        let mut rng = rand::rngs::OsRng::default();\n        let k0 = rng.next_u64();\n        let k1 = rng.next_u64();\n        Self {\n            k0,\n            k1,\n            hasher: SipHasher::new_with_keys(k0, k1),\n        }\n    }\n}\n\nimpl BuildHasher for SaltedOutpointHasher {\n\n    type Hasher = Self;\n\n    #[instrument(level = \"trace\", skip(self))]\n    fn build_hasher(&self) -> Self::Hasher {\n        Self {\n            k0:     self.k0,\n            k1:     self.k1,\n            hasher: SipHasher::new_with_keys(self.k0, self.k1),\n        }\n    }\n}\n\nimpl Hasher for SaltedOutpointHasher {\n\n    #[inline]\n    fn finish(&self) -> u64 {\n        self.hasher.clone().finish()\n    }\n\n    #[inline]\n    fn write(&mut self, bytes: &[u8]) {\n        self.hasher.write(bytes);\n    }\n}\n\nimpl SaltedOutpointHasher {\n\n    /// Having the hash allows libstdc++'s unordered_map to recalculate the hash during rehash, so\n    /// it does not have to cache the value. \n    ///\n    /// This reduces node's memory by sizeof(size_t). The required recalculation has a slight\n    /// performance penalty (around 1.6%), but this is compensated by memory savings of about 9%\n    /// which allow for a larger dbcache setting.\n    /// \n    /// -----------\n    /// @note\n    /// see https://gcc.gnu.org/onlinedocs/gcc-9.2.0/libstdc++/manual/manual/unordered_associative.html\n    /// Hash an `OutPoint` (txid + vout index) with an extra 32‑bit word, mirroring Bitcoin Core’s\n    /// `SipHashUint256Extra`.\n    #[instrument(level = \"debug\", skip(self, id))]\n    pub fn invoke(&self, id: &OutPoint) -> usize {\n        let mut h = SipHasher::new_with_keys(self.k0, self.k1);\n        h.write(id.hash().as_ref());\n        h.write(&id.n().to_le_bytes());\n        h.finish() as usize\n    }\n}\n\nimpl Default for SaltedTxidHasher {\n\n    #[instrument(level = \"trace\")]\n    fn default() -> Self {\n        let mut rng = rand::rngs::OsRng::default();\n        Self {\n            k0: rng.next_u64(),\n            k1: rng.next_u64(),\n        }\n    }\n}\n\nimpl SaltedTxidHasher {\n\n    /// Hash a 256‑bit transaction id with SipHash‑2‑4.\n    #[instrument(level = \"debug\", skip(self, txid))]\n    pub fn invoke(&self, txid: &u256) -> usize {\n        let mut h = SipHasher::new_with_keys(self.k0, self.k1);\n        h.write(txid.as_ref());\n        h.finish() as usize\n    }\n}\n\nimpl SignatureCacheHasher {\n\n    #[instrument(level = \"debug\", skip(self, key))]\n    pub fn invoke<const HASH_SELECT: u8>(&self, key: &u256) -> u32 {\n        debug_assert!(HASH_SELECT < 8);\n        let start = (HASH_SELECT as usize) * 4;\n        let mut tmp = [0u8; 4];\n        tmp.copy_from_slice(&<u256 as AsRef<[u8]>>::as_ref(key)[start..start + 4]);\n        u32::from_le_bytes(tmp)\n    }\n}\n\nimpl bitcoin_cuckoo_cache::EightWayHasher<u256> for SignatureCacheHasher {\n\n    #[inline]\n    fn hashes(&self, key: &u256) -> [u32; 8] {\n        [\n            self.invoke::<0>(key),\n            self.invoke::<1>(key),\n            self.invoke::<2>(key),\n            self.invoke::<3>(key),\n            self.invoke::<4>(key),\n            self.invoke::<5>(key),\n            self.invoke::<6>(key),\n            self.invoke::<7>(key),\n        ]\n    }\n}\n\nimpl Default for ByteVectorHash {\n\n    /// Generates process‑wide random SipHash keys.\n    #[instrument(level = \"trace\")]\n    fn default() -> Self {\n        let mut rng = rand::rngs::OsRng::default();\n        let k0 = rng.next_u64();\n        let k1 = rng.next_u64();\n        Self {\n            k0,\n            k1,\n            hasher: SipHasher::new_with_keys(k0, k1),\n        }\n    }\n}\n\nimpl BuildHasher for ByteVectorHash {\n\n    type Hasher = Self;\n\n    #[instrument(level = \"trace\")]\n    fn build_hasher(&self) -> Self::Hasher {\n        Self {\n            k0:     self.k0,\n            k1:     self.k1,\n            hasher: SipHasher::new_with_keys(self.k0, self.k1),\n        }\n    }\n}\n\nimpl Hasher for ByteVectorHash {\n\n    #[inline]\n    fn finish(&self) -> u64 {\n        self.hasher.clone().finish()\n    }\n\n    #[inline]\n    fn write(&mut self, bytes: &[u8]) {\n        self.hasher.write(bytes);\n    }\n}\n\nimpl ByteVectorHash {\n\n    /// Convenience helper that hashes a complete byte‑vector in one call.\n    #[instrument(level = \"trace\", skip_all)]\n    pub fn invoke(&self, input: &[u8]) -> usize {\n        let mut h = SipHasher::new_with_keys(self.k0, self.k1);\n        h.write(input);\n        h.finish() as usize\n    }\n}\n\nimpl Hash256 {\n\n    #[instrument(level = \"trace\", skip(self, input))]\n    pub fn write(&mut self, input: &[u8]) -> &mut Self {\n        self.sha.write(input);\n        self\n    }\n\n    #[instrument(level = \"trace\", skip(self, output))]\n    pub fn finalize(&mut self, output: &mut [u8; Hash256::OUTPUT_SIZE]) {\n        debug_assert_eq!(output.len(), Hash256::OUTPUT_SIZE);\n    \n        let mut buf = [0u8; SHA256_OUTPUT_SIZE];\n        self.sha.finalize(&mut buf);\n    \n        self.sha.reset();\n        self.sha.write(&buf);\n        self.sha.finalize(output);\n    }\n\n    #[instrument(level = \"trace\", skip(self))]\n    pub fn reset(&mut self) -> &mut Self {\n        self.sha.reset();\n        self\n    }\n}\n\nimpl Default for SaltedSipHasher {\n\n    #[instrument(level = \"trace\")]\n    fn default() -> Self {\n        let mut rng = rand::rngs::OsRng::default();\n        Self {\n            k0: rng.next_u64(),\n            k1: rng.next_u64(),\n        }\n    }\n}\n\nimpl SaltedSipHasher {\n\n    #[instrument(level = \"debug\", skip(self, script))]\n    pub fn invoke(&self, script: &[u8]) -> usize {\n        let mut h = SipHasher::new_with_keys(self.k0, self.k1);\n        h.write(script);\n        h.finish() as usize\n    }\n}\n\nimpl<S> HashVerifier<S> where\n    S: Debug + Read {\n\n    #[instrument(level = \"trace\")]\n    pub fn new(source: S) -> Self {\n        Self {\n            base: HashWriter::new(SER_GETHASH as i32, 0),\n            source,\n        }\n    }\n\n    #[instrument(level = \"trace\", skip(self, buf))]\n    pub fn read(&mut self, buf: &mut [u8]) -> std::io::Result<()> {\n        self.source.read_exact(buf)?;\n        self.base.write(buf);\n        Ok(())\n    }\n\n    #[instrument(level = \"trace\", skip(self))]\n    pub fn ignore(&mut self, mut n: usize) -> std::io::Result<()> {\n        let mut tmp = [0u8; 1024];\n        while n != 0 {\n            let now = n.min(tmp.len());\n            self.read(&mut tmp[..now])?;\n            n -= now;\n        }\n        Ok(())\n    }\n}\n\nimpl<Src, T> Shr<&mut T> for HashVerifier<Src> where\n    Src: Read + Debug,\n    T: AsMut<[u8]> {\n\n    type Output = HashVerifier<Src>;\n\n    /// Read exactly `obj.as_mut().len()` bytes from the wrapped\n    /// stream, hash them, and store them in `obj`.\n    #[inline]\n    fn shr(mut self, rhs: &mut T) -> Self::Output {\n        let buf = rhs.as_mut();\n        // Ignore I/O errors – propagate via panic just like C++’s\n        // stream exceptions.\n        self.read(buf).expect(\"HashVerifier::read failed\");\n        self\n    }\n}\n\nimpl BlockHasher {\n\n    /**\n    | this used to call `GetCheapHash()` in\n    | uint256, which was later moved; the cheap\n    | hash function simply calls ReadLE64()\n    | however, so the end result is identical\n    */\n    #[instrument(level = \"debug\", skip(self, hash))]\n    pub fn invoke(&self, hash: &u256) -> usize {\n        read_le64(hash.as_ref()) as usize\n    }\n}\n\nimpl Hash160 {\n\n    #[instrument(level = \"trace\", skip(self, output))]\n    pub fn finalize(&mut self, output: &mut [u8; Hash160::OUTPUT_SIZE]) {\n        debug_assert_eq!(output.len(), Hash160::OUTPUT_SIZE);\n    \n        /* first SHA‑256 pass */\n        let mut sha_buf = [0u8; SHA256_OUTPUT_SIZE];\n        self.sha.finalize(&mut sha_buf);\n    \n        /* second RIPEMD‑160 pass */\n        let mut ripemd = Ripemd160::new();\n        ripemd.update(&sha_buf);\n    \n        // The back‑end `finalize` consumes the target buffer by value,\n        // so we allocate a local scratch array, let the back‑end fill\n        // it, and then copy the result into the caller‑supplied slice.\n        let mut digest = [0u8; Hash160::OUTPUT_SIZE];\n        ripemd.finalize(&mut digest);\n        *output = digest;\n    }\n\n    #[instrument(level = \"trace\", skip(self, input))]\n    pub fn write(&mut self, input: &[u8]) -> &mut Self {\n        self.sha.write(input);\n        self\n    }\n\n    #[instrument(level = \"trace\", skip(self))]\n    pub fn reset(&mut self) -> &mut Self {\n        self.sha.reset();\n        self\n    }\n}\n\nimpl<T> Shl<&T> for HashWriter where\n    T: AsRef<[u8]> + ?Sized {\n\n    type Output = HashWriter;\n\n    #[inline]\n    fn shl(mut self, rhs: &T) -> Self::Output {\n        self.write(rhs.as_ref());\n        self\n    }\n}\n\nimpl HashWriter {\n\n    /// Create a new writer with the given *type* and *version*.\n    #[instrument(level = \"trace\")]\n    pub fn new(n_type_in: i32, n_version_in: i32) -> Self {\n        Self {\n            ctx: Sha256::new(),\n            n_type: n_type_in,\n            n_version: n_version_in,\n        }\n    }\n\n    #[inline]\n    pub fn get_type(&self) -> i32 {\n        self.n_type\n    }\n\n    #[inline]\n    pub fn get_version(&self) -> i32 {\n        self.n_version\n    }\n\n    #[instrument(level = \"trace\", skip(self, pch))]\n    pub fn write(&mut self, pch: &[u8]) {\n        self.ctx.write(pch);\n    }\n\n    /**\n    | Compute the double-SHA256 hash of all\n    | data written to this object.\n    | \n    | Invalidates this object.\n    |\n    */\n    #[instrument(level = \"debug\", skip(self))]\n    pub fn get_hash(&mut self) -> u256 {\n        let mut first = [0u8; 32];\n        self.ctx.finalize(&mut first);\n    \n        self.ctx.reset();\n        self.ctx.write(&first);\n        let mut second = [0u8; 32];\n        self.ctx.finalize(&mut second);\n    \n        u256::from_le_bytes(second)\n    }\n\n    /**\n    | Compute the SHA256 hash of all data written\n    | to this object.\n    | \n    | Invalidates this object.\n    |\n    */\n    #[instrument(level = \"debug\", skip(self))]\n    pub fn getsha256(&mut self) -> u256 {\n        let mut buf = [0u8; 32];\n        self.ctx.finalize(&mut buf);\n        u256::from_le_bytes(buf)\n    }\n\n    /**\n    | Returns the first 64 bits from the resulting\n    | hash.\n    |\n    */\n    #[instrument(level = \"trace\", skip(self))]\n    pub fn get_cheap_hash(&mut self) -> u64 {\n        let digest = self.get_hash();\n        let mut tmp = [0u8; 8];\n        tmp.copy_from_slice(&<u256 as AsRef<[u8]>>::as_ref(&digest)[..8]);\n        u64::from_le_bytes(tmp)\n    }\n}\n\nimpl AssumeUtxoHash {\n\n    /// Construct a new [`AssumeUtxoHash`] from the supplied 256‑bit hash.\n    #[instrument(level = \"debug\", skip(hash))]\n    pub fn new(hash: &u256) -> Self {\n        Self {\n            base: BaseHash::new(hash),\n        }\n    }\n}\n\nimpl<HashType> Default for BaseHash<HashType> where\n    HashType: Clone\n        + Default\n        + Debug\n        + AsRef<[u8]>\n        + AsMut<[u8]>\n        + Ord\n        + core::fmt::Display {\n\n    #[instrument(level = \"trace\")]\n    fn default() -> Self {\n        trace!(\"BaseHash<…>::default()\");\n        Self {\n            hash: HashType::default(),\n        }\n    }\n}\n\nimpl<HashType> BaseHash<HashType> where\n    HashType: Clone\n        + Default\n        + Debug\n        + AsRef<[u8]>\n        + AsMut<[u8]>\n        + Ord\n        + core::fmt::Display {\n\n    /// Create a new `BaseHash` by cloning `input`.\n    #[instrument(level = \"debug\")]\n    pub fn new(input: &HashType) -> Self {\n        Self {\n            hash: input.clone(),\n        }\n    }\n\n    /// Return the number of bytes in the underlying hash.\n    #[inline]\n    #[instrument(level = \"trace\", skip(self))]\n    pub fn size(&self) -> usize {\n        self.hash.as_ref().len()\n    }\n\n    #[inline]\n    #[instrument(level = \"trace\", skip(self))]\n    pub fn begin(&self) -> *const u8 {\n        self.hash.as_ref().as_ptr()\n    }\n\n    #[inline]\n    #[instrument(level = \"trace\", skip(self))]\n    pub fn begin_mut(&mut self) -> *mut u8 {\n        self.hash.as_mut().as_mut_ptr()\n    }\n\n    #[inline]\n    #[instrument(level = \"trace\", skip(self))]\n    pub fn end(&self) -> *const u8 {\n        // SAFETY: adding the exact length is safe\n        unsafe { self.begin().add(self.size()) }\n    }\n\n    #[inline]\n    #[instrument(level = \"trace\", skip(self))]\n    pub fn end_mut(&mut self) -> *mut u8 {\n        // SAFETY: adding the exact length is safe\n        unsafe { self.begin_mut().add(self.size()) }\n    }\n\n    #[inline]\n    #[instrument(level = \"trace\", skip(self))]\n    pub fn data(&self) -> *const u8 {\n        self.begin()\n    }\n\n    #[inline]\n    #[instrument(level = \"trace\", skip(self))]\n    pub fn data_mut(&mut self) -> *mut u8 {\n        self.begin_mut()\n    }\n\n    #[inline]\n    #[instrument(level = \"trace\", skip(self))]\n    pub fn to_string(&self) -> String {\n        self.hash.to_string()\n    }\n}\n\nimpl<HashType> Into<Vec<u8>> for BaseHash<HashType> where\n    HashType: Clone\n        + Default\n        + Debug\n        + AsRef<[u8]>\n        + AsMut<[u8]>\n        + Ord\n        + core::fmt::Display {\n\n    #[instrument(level = \"trace\", skip(self))]\n    fn into(self) -> Vec<u8> {\n        self.hash.as_ref().to_vec()\n    }\n}\n\nimpl<HashType> PartialEq for BaseHash<HashType> where\n    HashType: Clone\n        + Default\n        + Debug\n        + AsRef<[u8]>\n        + AsMut<[u8]>\n        + Ord\n        + core::fmt::Display {\n\n    #[inline]\n    fn eq(&self, other: &Self) -> bool {\n        self.hash == other.hash\n    }\n}\n\nimpl<HashType> Eq for BaseHash<HashType> where\n    HashType: Clone\n        + Default\n        + Debug\n        + AsRef<[u8]>\n        + AsMut<[u8]>\n        + Ord\n        + core::fmt::Display {}\n\nimpl<HashType> PartialOrd for BaseHash<HashType> where\n    HashType: Clone\n        + Default\n        + Debug\n        + AsRef<[u8]>\n        + AsMut<[u8]>\n        + Ord\n        + core::fmt::Display {\n\n    #[inline]\n    fn partial_cmp(&self, other: &Self) -> Option<Ordering> {\n        Some(self.cmp(other))\n    }\n}\n\nimpl<HashType> Ord for BaseHash<HashType> where\n    HashType: Clone\n        + Default\n        + Debug\n        + AsRef<[u8]>\n        + AsMut<[u8]>\n        + Ord\n        + core::fmt::Display {\n\n    #[inline]\n    fn cmp(&self, other: &Self) -> Ordering {\n        self.hash.cmp(&other.hash)\n    }\n}\n\n/// Deref so downstream code can transparently\n/// treat a `BaseHash` as the inner hash type.\n/// Deref so downstream code can transparently\n/// treat a `BaseHash` as the inner hash type.\nimpl<HashType> Deref for BaseHash<HashType> where\n    HashType: Clone\n        + Default\n        + Debug\n        + AsRef<[u8]>\n        + AsMut<[u8]>\n        + Ord\n        + core::fmt::Display {\n\n    type Target = HashType;\n\n    #[inline]\n    fn deref(&self) -> &Self::Target {\n        &self.hash\n    }\n}\n\nimpl<HashType> DerefMut for BaseHash<HashType> where\n    HashType: Clone\n        + Default\n        + Debug\n        + AsRef<[u8]>\n        + AsMut<[u8]>\n        + Ord\n        + core::fmt::Display {\n\n    #[inline]\n    fn deref_mut(&mut self) -> &mut Self::Target {\n        &mut self.hash\n    }\n}\n\n\nThis crate has the following authors:\n[\n    \"klebs <none>\",\n]\nThis crate has the following rust edition:\n2021\nThis crate has the following license:\nMIT\nThis crate is held in the following repository:\nhttps://github.com/klebs6/bitcoin-rs\n","role":"user"}],"model":"gpt-5.1"}}
