{"custom_id":"bitcoinleveldb-cache-ai-readme-request","method":"POST","url":"/v1/chat/completions","body":{"max_completion_tokens":8192,"messages":[{"content":"We would like you to write a README.md for a rust crate with maximally helpful content.\nAdditionally, we would like you to generate several fields from the Cargo.toml package section for this crate.\nWe will show you the strict json output format we would like you to provide.\nPlease tailor your response for an apex consumer of maximal intelligence.\nA reader of this README.md should have a good sense of what the crate does and how to use it after reading what you write.\nPlease include a messaage indicating that this README.md file was generated by an AI model and may not be 100% accurate however it should be pretty good.\n\n\nCarefully read and parse the information we sent you.\n\nWe want to generate all information items requested by our schema:\n\n- Read the description of each field. Use it, along with the content we sent you to generate an appropriate value for each.\n- Ensure that each generated field optimally serves its desired purpose.\n- Each item should be deep, detailed, and specific. Use optimally descriptive and useful language. Do not be too verbose.\n- Do not add any extra keys to the generated object. Generate precisely what we ask of you: no more, no less.\n- For fields which are of an enum type: pick *exactly one variant*. Do not generate any information for the unselected variants.\n- For array fields: supply a JSON list [ ... ] of items, each conforming to the correct item type.\n- For map fields: Provide a JSON object { \"key_as_string\": <value>, ... }. Keys must be valid JSON strings. Keys and Values must conform to the key and value schemas we provide to you. Fill all subfields of each and every map value.\n- If we ask you to justify a map field, provide your justification/confidence score for the entire map. Do not attempt to separately justify each map element.\n- Likewise, if we ask you to justify an array field, provide your justification/confidence score for the entire array. Do not attempt to separately justify each element.\n- Provide numeric fields as real JSON numbers (not strings).\n- For string fields: provide the value precisely as a string literal. If optional, you may set it to null.\n- If we ask you to justify or provide confidence scores for the fields of a structure, please do so carefully. For each field we ask you to justify, please explain or justify your choice clearly. Confidence scores must be specified as real JSON numbers in the range `[0..1]`.\n- If we ask to you generate an optional field, either fill it or set it to null.\n- If we ask you to justify your choice of an enum variant, please explain your choice clearly. Do not justify your decision to leave a variant unselected. Provide your justification as a JSON string. Provide your confidence score as a real JSON number in the range `[0..1]`.\n- In terms of the JSON format we would like you to provide, the object itself will be deserialied based on the following schema. \n- We begin exactly at the top: the data should not be nested under a parent named 'fields' or anything similar.\n\n## Here is the schema to use:\n\nObject {\n    \"fields\": Object {\n        \"crate_name\": Object {\n            \"generation_instructions\": String(\"\\\"This string should be the name of our crate, *verbatim*, trimmed for use as a toml field\\\"\"),\n            \"required\": Bool(true),\n            \"type\": String(\"string\"),\n        },\n        \"full_readme_markdown\": Object {\n            \"generation_instructions\": String(\"\\\"This string should be valid markdown representing the readme for this crate.\\\\n\\\\n Please make it terse, useful, and designed for an industrious commercially savy consumer of industrious nature. \\\\n\\\\n Advanced vocabulary and concepts are welcome. \\\\n\\\\n If this crate involves concepts from mathematics and/or physics, please describe and document them here.\\\"\"),\n            \"required\": Bool(true),\n            \"type\": String(\"string\"),\n        },\n        \"package_categories\": Object {\n            \"generation_instructions\": String(\"\\\"These categories will be used in our Cargo.toml file.\\\\n\\\\n It is important that users of this crate can find it on crates.io.\\\\n\\\\n Choose maximum 5 categories and make sure they are actually meaningful for our crate.\\\\n\\\\n These categories should only be chosen from among the legal crates.io categories. \\\\n\\\\n The ONLY legal categoreis are:\\\\n\\\\n``\\\\n accessibility\\\\n aerospace\\\\n algorithms\\\\n api-bindings\\\\n asynchronous\\\\n authentication\\\\n caching\\\\n command-line-interface\\\\n command-line-utilities\\\\n compilers\\\\n compression\\\\n computer-vision\\\\n concurrency\\\\n config\\\\n cryptography\\\\n data-structures\\\\n database\\\\n database-implementations\\\\n date-and-time\\\\n development-tools\\\\n email\\\\n embedded\\\\n emulators\\\\n encoding\\\\n external-ffi-bindings\\\\n filesystem\\\\n finance\\\\n game-development\\\\n game-engines\\\\n games\\\\n graphics\\\\n gui\\\\n hardware-support\\\\n internationalization\\\\n localization\\\\n mathematics\\\\n memory-management\\\\n multimedia\\\\n network-programming\\\\n no-std\\\\n os\\\\n parser-implementations\\\\n parsing\\\\n rendering\\\\n rust-patterns\\\\n science\\\\n simulation\\\\n template-engine\\\\n text-editors\\\\n text-processing\\\\n value-formatting\\\\n virtualization\\\\n visualization\\\\n wasm\\\\n web-programming\\\\n ``\\\\n\\\\n DO NOT specify a category that is not on this list.\\\"\"),\n            \"required\": Bool(true),\n            \"type\": String(\"array_of_strings\"),\n        },\n        \"package_description\": Object {\n            \"generation_instructions\": String(\"\\\"We will place this package_description in our Cargo.toml file so the users of this crate\\\\n know what it does.\\\\n\\\\n The discription should be technical, clear, and useful. It should be terse.\\\"\"),\n            \"required\": Bool(true),\n            \"type\": String(\"string\"),\n        },\n        \"package_keywords\": Object {\n            \"generation_instructions\": String(\"\\\"These keywords will be used in our Cargo.toml file so the users of this crate can easily\\\\n find it in the package system. Keywords should be useful, varied, meaningful, and reflect\\\\n the contents of our crate. They should make it easy to find. Please provide exactly five.\\\"\"),\n            \"required\": Bool(true),\n            \"type\": String(\"array_of_strings\"),\n        },\n    },\n    \"struct_docs\": String(\" This structure is a directive indicating which fields we need you to provide for us in your response to our query.\\n\"),\n    \"struct_name\": String(\"AiReadmeWriterDesiredOutput\"),\n    \"type\": String(\"struct\"),\n}\n\n## Please keep the following in mind:\n\nEntry phrasing:\n\n- Ensure entries are concise and focused.\n- Ensure there are no vague phrases (e.g., avoid starting with \"Illustrates the something something...\"; instead, use direct details like \"The hanging green vines on the garden wall\").\n\nEnsure Clarity and Consistency:\n\n- Use clear, grammatically correct sentences.\n- Maintain a consistent tone and style throughout.\n\nEnrich Content:\n\n- Communicate additional information where appropriate to enhance depth and value.\n- If a mathematical, physical, or otherwise technical background is helpful, please provide it.\n- Ensure that the content is comprehensive and meets all requirements.\n\nFocus Language:\n\n- Use deliberate and precise language.\n- Avoid vague verbs and keep the maximally intelligent and detail oriented audience in mind. \n- We explicitly ban the words `hush`, `subtle`, `mythic`, and `aura`. Please keep your vocabulary choices rigorous.\n- Do not use modern cultural references \n- Do not generically reference ideas which do not belong in the global environment.\n\n## Present the Final JSON:\n\n- Format the output as a JSON object.\n- Include all fields properly named from the schema we sent you.\n\nEnsure Proper Formatting:\n\n- Use proper JSON syntax with keys and arrays.\n- Ensure that all entries are correctly placed in their respective places.\n\nProvide only the final JSON data as specified by the schema. \n\nDo not include any schema generation instructions, meta-fields, nested-templates (unless directly asked) or extraneous information. \n\nProvide only the populated fields and their values, conforming exactly to the required structure without embedding any intermediate annotations or placeholders.\n\nYour output should only consist of the JSON object. do *not* include a preamble or postamble to your response. \n\nWe seek to successfully parse your response directly as JSON.\n\nFor the final answer, output the result only as a valid JSON object, wrapped inside triple backticks with json immediately after the opening backticks.\nThe JSON must be parser-ready:\n– No additional text before or after the block\n– No markdown or prose outside the fenced block\n– No HTML escaping of quotes, slashes, or other characters\n– Indentation and whitespace preserved exactly as written\n– The content between the fences must be valid JSON as per RFC 8259","role":"system"},{"content":"We have a rust crate named 'bitcoinleveldb-cache' 0.1.19. \n\nHere is the interface:\n/**\n| A Cache is an interface that maps keys to\n| values.  It has internal synchronization and\n| may be safely accessed concurrently from\n| multiple threads.  It may automatically evict\n| entries to make room for new entries.  Values\n| have a specified charge against the cache\n| capacity.  For example, a cache where the\n| values are variable length strings, may use the\n| length of the string as the charge for the\n| string.\n|\n| A builtin cache implementation with\n| a least-recently-used eviction policy is\n| provided.  Clients may use their own\n| implementations if they want something more\n| sophisticated (like scan-resistance, a custom\n| eviction policy, variable cache sizing, etc.)\n*/\npub trait CacheInterface {}\n\n\npub trait CacheInsert {\n    fn insert(\n        &mut self,\n        key_:      &Slice,\n        value:     *mut c_void,\n        charge:    usize,\n        deleter:   CacheDeleterFn\n    ) -> *mut CacheHandle;\n}\n\n\npub trait CacheLookup {\n    fn lookup(&mut self, key_: &Slice) -> *mut CacheHandle;\n}\n\n\npub trait CacheRelease {\n    fn release(&mut self, handle: *mut CacheHandle);\n}\n\n\npub trait CacheValue {\n    fn value(&mut self, handle: *mut CacheHandle) -> *mut c_void;\n}\n\n\npub trait CacheErase {\n    fn erase(&mut self, key_: &Slice);\n}\n\n\npub trait CacheNewId {\n    fn new_id(&mut self) -> u64;\n}\n\n\npub trait CachePrune {\n    fn prune(&mut self);\n}\n\n\npub trait CacheTotalCharge {\n    fn total_charge(&self) -> usize;\n}\n\npub type CacheDeleterFn = fn(key_: &Slice, value: *mut c_void);\n\n#[derive(Default)]\npub struct Cache  {\n    rep: Rc<RefCell<CacheRep>>,\n}\n\n\n/// Internal payload stored as the cache value during tests.\n///\n/// This lets the deleter know **both** which `CacheTest` fixture\n/// owns the entry and what logical integer value was stored,\n/// without relying on any global mutable state.\n#[derive(Getters, Setters, Builder)]\n#[getset(get = \"pub(crate)\", set = \"pub(crate)\")]\npub struct CacheTestValue  {\n    fixture: *mut CacheTest,\n    value:   i32,\n}\n\n\n#[derive(MutGetters, Getters, Setters, Builder)]\n#[getset(get_mut=\"pub\", get=\"pub\", set=\"pub(crate)\")]\npub struct CacheTest  {\n    deleted_keys:   Vec<i32>,\n    deleted_values: Vec<i32>,\n    cache:          *mut Cache,\n}\n\n\n/**\n| Opaque handle to an entry stored in the\n| cache.\n|\n| Fields are private; access is via the\n| generated getters/setters from `getset`\n| and the builder from `derive_builder`.\n*/\n#[derive(Getters, Setters, Builder)]\n#[getset(get = \"pub(crate)\", set = \"pub(crate)\")]\npub struct CacheHandle  {\n    key:      Vec<u8>,\n    value:    *mut c_void,\n    deleter:  CacheDeleterFn,\n    charge:   usize,\n    refs:     u32,\n    in_cache: bool,\n    last_use: u64,\n}\n\n\n#[derive(Getters, Setters, Builder, Default)]\n#[getset(get = \"pub(crate)\", set = \"pub(crate)\")]\npub struct CacheRep  {\n    capacity: usize,\n    usage:    usize,\n    entries:  HashMap<Vec<u8>, *mut CacheHandle>,\n    next_id:  u64,\n    clock:    u64,\n}\n\n/**\n| Create a new cache with a fixed size capacity.\n|\n| This implementation of Cache uses a\n| least-recently-used eviction policy.\n*/\npub fn new_lru_cache(capacity: usize) -> *mut Cache {\n    info!(\"new_lru_cache: creating cache with capacity={}\", capacity);\n    let rep = CacheRep::with_capacity(capacity);\n    let cache = Cache {\n        rep: Rc::new(RefCell::new(rep)),\n    };\n    Box::into_raw(Box::new(cache))\n}\n\n\npub fn encode_key(k: i32) -> Vec<u8> {\n    // Little-endian fixed32 encoding, matching PutFixed32\n    let v = k as u32;\n    let b0 = (v & 0xff) as u8;\n    let b1 = ((v >> 8) & 0xff) as u8;\n    let b2 = ((v >> 16) & 0xff) as u8;\n    let b3 = ((v >> 24) & 0xff) as u8;\n    vec![b0, b1, b2, b3]\n}\n\n\npub fn decode_key(k: &Slice) -> i32 {\n    unsafe {\n        assert_eq!(*k.size(), 4, \"decode_key expects 4-byte key\");\n        let data = k.data();\n        assert!(!data.is_null(), \"decode_key got null data pointer\");\n        let bytes = std::slice::from_raw_parts(*data as *const u8, 4);\n        let v0 = bytes[0] as u32;\n        let v1 = (bytes[1] as u32) << 8;\n        let v2 = (bytes[2] as u32) << 16;\n        let v3 = (bytes[3] as u32) << 24;\n        let v = v0 | v1 | v2 | v3;\n        v as i32\n    }\n}\n\n\n/// Legacy helper used only by tests; production code should\n/// treat cache values as opaque `*mut c_void`.\n///\n/// Here, `v` is expected to be a pointer to `CacheTestValue`\n/// created by `CacheTest::insert*`.\npub fn decode_value(v: *mut c_void) -> i32 {\n    unsafe {\n        if v.is_null() {\n            error!(\"decode_value: called with null value pointer\");\n            0\n        } else {\n            let payload = v as *mut crate::cache_test::CacheTestValue;\n            let logical = *(*payload).value();\n            trace!(\"decode_value: {:?} -> {}\", v, logical);\n            logical\n        }\n    }\n}\n\n\n/// Kept for completeness; not used by the current tests. It still\n/// performs a simple integer->pointer reinterpretation, matching\n/// the original minimal helper semantics.\npub fn encode_value(v: uintptr_t) -> *mut c_void {\n    let ptr = v as usize as *mut c_void;\n    trace!(\"encode_value: v={} -> {:?}\", v, ptr);\n    ptr\n}\n\n\n/// Kept for compatibility with the original C++-style tests.\n/// It is now a no-op because the fixture pointer is carried\n/// inside `CacheTestValue` instead of a global.\npub fn set_current_cache_test(test: *mut CacheTest) {\n    trace!(\n        \"cache_test::set_current_cache_test: registering fixture {:?} (no-op)\",\n        test\n    );\n}\n\nimpl Drop for Cache {\n\n    /**\n    | Destroys all existing entries by calling\n    | the \"deleter\" function that was passed\n    | to the constructor.\n    */\n    fn drop(&mut self) {\n        debug!(\"Cache::drop: destroying cache instance\");\n        let mut rep = self.rep.borrow_mut();\n        rep.clear_all();\n        let final_usage = *rep.usage();\n        debug!(\"Cache::drop: completed, usage={}\", final_usage);\n    }\n}\n\nimpl Cache {\n\n    pub fn lru_remove(&mut self, e: *mut CacheHandle) {\n        trace!(\"Cache::lru_remove: called on handle {:?}\", e);\n        let _ = e;\n    }\n\n    pub fn lru_append(&mut self, e: *mut CacheHandle) {\n        trace!(\"Cache::lru_append: called on handle {:?}\", e);\n        let _ = e;\n    }\n\n    pub fn unref(&mut self, e: *mut CacheHandle) {\n        trace!(\"Cache::unref: delegating to CacheRep::unref_entry\");\n        let mut rep = self.rep.borrow_mut();\n        rep.unref_entry(e);\n    }\n}\n\nimpl CacheInsert for Cache {\n\n    fn insert(\n        &mut self,\n        key_:      &Slice,\n        value:     *mut c_void,\n        charge:    usize,\n        deleter:   CacheDeleterFn\n    ) -> *mut CacheHandle\n    {\n        let mut rep = self.rep.borrow_mut();\n        rep.insert_entry(key_, value, charge, deleter)\n    }\n}\n\nimpl CacheLookup for Cache {\n\n    fn lookup(&mut self, key_: &Slice) -> *mut CacheHandle {\n        let mut rep = self.rep.borrow_mut();\n        rep.lookup_entry(key_)\n    }\n}\n\nimpl CacheRelease for Cache {\n\n    fn release(&mut self, handle: *mut CacheHandle) {\n        trace!(\"Cache::release: releasing handle {:?}\", handle);\n        let mut rep = self.rep.borrow_mut();\n        rep.unref_entry(handle);\n    }\n}\n\nimpl CacheValue for Cache {\n\n    fn value(&mut self, handle: *mut CacheHandle) -> *mut c_void {\n        trace!(\"Cache::value: reading value for handle {:?}\", handle);\n        unsafe {\n            if handle.is_null() {\n                error!(\"Cache::value: called with null handle\");\n                std::ptr::null_mut()\n            } else {\n                let h = &*handle;\n                *h.value()\n            }\n        }\n    }\n}\n\nimpl CacheErase for Cache {\n\n    fn erase(&mut self, key_: &Slice) {\n        let mut rep = self.rep.borrow_mut();\n        rep.erase_entry(key_);\n    }\n}\n\nimpl CacheNewId for Cache {\n\n    fn new_id(&mut self) -> u64 {\n        let mut rep = self.rep.borrow_mut();\n        let current = *rep.next_id();\n        let next = current.wrapping_add(1);\n        rep.set_next_id(next);\n        debug!(\"Cache::new_id: generated id={}\", next);\n        next\n    }\n}\n\nimpl CachePrune for Cache {\n\n    fn prune(&mut self) {\n        debug!(\"Cache::prune: pruning unused entries\");\n        let mut rep = self.rep.borrow_mut();\n        rep.prune_unused();\n        let usage_after = *rep.usage();\n        debug!(\"Cache::prune: done, usage={}\", usage_after);\n    }\n}\n\nimpl CacheTotalCharge for Cache {\n\n    fn total_charge(&self) -> usize {\n        let rep = self.rep.borrow();\n        *rep.usage()\n    }\n}\n\nimpl<T> CacheInterface for T where\n    T: CacheInsert\n        + CacheLookup\n        + CacheRelease\n        + CacheValue\n        + CacheErase\n        + CacheNewId\n        + CachePrune\n        + CacheTotalCharge {}\n\nimpl Default for CacheTest {\n\n    fn default() -> Self {\n        CacheTest::new(CACHE_TEST_CACHE_SIZE)\n    }\n}\n\nimpl Drop for CacheTest {\n\n    fn drop(&mut self) {\n        unsafe {\n            if !self.cache.is_null() {\n                debug!(\"CacheTest::drop: dropping cache {:?}\", self.cache);\n                let boxed = Box::from_raw(self.cache);\n                drop(boxed);\n                self.cache = std::ptr::null_mut();\n            }\n        }\n    }\n}\n\nimpl CacheTest {\n\n    pub fn new(capacity: usize) -> Self {\n        info!(\"CacheTest::new: creating fixture with cache size={}\", capacity);\n        let cache_ptr = new_lru_cache(capacity);\n        CacheTest {\n            deleted_keys:   Vec::new(),\n            deleted_values: Vec::new(),\n            cache:          cache_ptr,\n        }\n    }\n\n    pub fn reset_cache(&mut self, capacity: usize) {\n        unsafe {\n            if !self.cache.is_null() {\n                debug!(\n                    \"CacheTest::reset_cache: dropping existing cache {:?}\",\n                    self.cache\n                );\n                let boxed = Box::from_raw(self.cache);\n                drop(boxed);\n            }\n        }\n        self.cache = new_lru_cache(capacity);\n        debug!(\n            \"CacheTest::reset_cache: new cache {:?} with capacity={}\",\n            self.cache,\n            capacity\n        );\n    }\n\n    /// Deleter used for all test cache entries.\n    ///\n    /// The `value` pointer is a `Box<CacheTestValue>` that encodes\n    /// both the owning fixture and the logical `i32` value.\n    pub fn deleter(key_: &Slice, v: *mut c_void) {\n        trace!(\"CacheTest::deleter: called\");\n        unsafe {\n            if v.is_null() {\n                debug!(\"CacheTest::deleter: value pointer is null, skipping\");\n                return;\n            }\n    \n            // Take ownership so the payload is freed exactly once.\n            let boxed_value: Box<CacheTestValue> =\n                Box::from_raw(v as *mut CacheTestValue);\n    \n            let fixture_ptr = *boxed_value.fixture();\n            if fixture_ptr.is_null() {\n                debug!(\n                    \"CacheTest::deleter: fixture pointer is null, not recording deletion\"\n                );\n                return;\n            }\n    \n            let key_int   = decode_key(key_);\n            let value_int = *boxed_value.value();\n    \n            let fixture: &mut CacheTest = &mut *fixture_ptr;\n    \n            trace!(\n                \"CacheTest::deleter: recording deleted key={} value={}\",\n                key_int,\n                value_int\n            );\n    \n            fixture.deleted_keys.push(key_int);\n            fixture.deleted_values.push(value_int);\n        }\n    }\n\n    pub fn lookup(&mut self, key_: i32) -> i32 {\n        let encoded = encode_key(key_);\n        let key_slice = Self::make_slice_for_key(&encoded);\n        unsafe {\n            let cache_ptr = self.cache;\n            let cache = &mut *cache_ptr;\n            let handle = cache.lookup(&key_slice);\n            if handle.is_null() {\n                trace!(\"CacheTest::lookup: miss for key={}\", key_);\n                return -1;\n            }\n            let value_ptr = cache.value(handle);\n            let r = decode_value(value_ptr);\n            cache.release(handle);\n            trace!(\"CacheTest::lookup: hit for key={} value={}\", key_, r);\n            r\n        }\n    }\n\n    pub fn insert(\n        &mut self,\n        key_:      i32,\n        value:     i32,\n        charge:    Option<i32>\n    )\n    {\n        let charge = charge.unwrap_or(1);\n        let encoded = encode_key(key_);\n        let key_slice = Self::make_slice_for_key(&encoded);\n    \n        let fixture_ptr: *mut CacheTest = self as *mut CacheTest;\n        let value_struct = CacheTestValueBuilder::default()\n            .fixture(fixture_ptr)\n            .value(value)\n            .build()\n            .expect(\"CacheTestValueBuilder should be fully initialized\");\n    \n        let value_ptr: *mut c_void =\n            Box::into_raw(Box::new(value_struct)) as *mut c_void;\n    \n        unsafe {\n            let cache_ptr = self.cache;\n            let cache = &mut *cache_ptr;\n            let handle = cache.insert(\n                &key_slice,\n                value_ptr,\n                charge as usize,\n                CacheTest::deleter,\n            );\n            cache.release(handle);\n        }\n    \n        trace!(\n            \"CacheTest::insert: key={} value={} charge={}\",\n            key_,\n            value,\n            charge\n        );\n    }\n\n    pub fn insert_and_return_handle(\n        &mut self,\n        key_:      i32,\n        value:     i32,\n        charge:    Option<i32>\n    ) -> *mut CacheHandle\n    {\n        let charge = charge.unwrap_or(1);\n        let encoded = encode_key(key_);\n        let key_slice = Self::make_slice_for_key(&encoded);\n    \n        let fixture_ptr: *mut CacheTest = self as *mut CacheTest;\n        let value_struct = CacheTestValueBuilder::default()\n            .fixture(fixture_ptr)\n            .value(value)\n            .build()\n            .expect(\"CacheTestValueBuilder should be fully initialized\");\n    \n        let value_ptr: *mut c_void =\n            Box::into_raw(Box::new(value_struct)) as *mut c_void;\n    \n        unsafe {\n            let cache_ptr = self.cache;\n            let cache = &mut *cache_ptr;\n            let handle = cache.insert(\n                &key_slice,\n                value_ptr,\n                charge as usize,\n                CacheTest::deleter,\n            );\n            trace!(\n                \"CacheTest::insert_and_return_handle: key={} value={} charge={} handle={:?}\",\n                key_,\n                value,\n                charge,\n                handle\n            );\n            handle\n        }\n    }\n\n    pub fn erase(&mut self, key_: i32) {\n        let encoded = encode_key(key_);\n        let key_slice = Self::make_slice_for_key(&encoded);\n        unsafe {\n            let cache_ptr = self.cache;\n            let cache = &mut *cache_ptr;\n            cache.erase(&key_slice);\n        }\n        trace!(\"CacheTest::erase: key={}\", key_);\n    }\n}\n\nimpl CacheHandle {\n\n    pub(crate) fn as_key_slice(&self) -> Slice {\n        let key = self.key();\n        if key.is_empty() {\n            Slice::from_ptr_len(std::ptr::null(), 0)\n        } else {\n            Slice::from_ptr_len(key.as_ptr(), key.len())\n        }\n    }\n}\n\nimpl CacheRep {\n\n    pub(crate) fn with_capacity(capacity: usize) -> Self {\n        debug!(\n            \"CacheRep::with_capacity: initializing with capacity={}\",\n            capacity\n        );\n        CacheRep {\n            capacity,\n            usage:   0,\n            entries: HashMap::new(),\n            next_id: 0,\n            clock:   0,\n        }\n    }\n\n    pub(crate) fn slice_to_string(key_: &Slice) -> String {\n        unsafe {\n            let size_ref = key_.size();\n            let data_ref = key_.data();\n    \n            let size = *size_ref as usize;\n            let data = *data_ref;\n    \n            if data.is_null() {\n                warn!(\"CacheRep::slice_to_string called with null data pointer\");\n                return String::new();\n            }\n    \n            let bytes = std::slice::from_raw_parts(data as *const u8, size);\n            let s = String::from_utf8_lossy(bytes).into_owned();\n            trace!(\n                \"CacheRep::slice_to_string: size={} -> \\\"{}\\\" (len={})\",\n                size,\n                s,\n                s.len()\n            );\n            s\n        }\n    }\n\n    pub(crate) fn slice_to_vec(key_: &Slice) -> Vec<u8> {\n        unsafe {\n            let size_ref = key_.size();\n            let data_ref = key_.data();\n    \n            let size = *size_ref as usize;\n            let data = *data_ref;\n    \n            if data.is_null() {\n                warn!(\"CacheRep::slice_to_vec: called with null data pointer\");\n                return Vec::new();\n            }\n    \n            let bytes = std::slice::from_raw_parts(data as *const u8, size);\n            bytes.to_vec()\n        }\n    }\n\n    pub(crate) fn ref_entry(&mut self, handle: *mut CacheHandle) {\n        unsafe {\n            let h = &mut *handle;\n            let current_refs = *h.refs();\n            let new_refs = current_refs\n                .checked_add(1)\n                .unwrap_or_else(|| {\n                    error!(\"CacheRep::ref_entry: reference count overflow\");\n                    current_refs\n                });\n            h.set_refs(new_refs);\n            h.set_last_use(self.clock);\n        }\n        self.clock = self.clock.wrapping_add(1);\n        trace!(\n            \"CacheRep::ref_entry: refs incremented, clock={}\",\n            self.clock\n        );\n    }\n\n    pub(crate) fn unref_entry(&mut self, handle: *mut CacheHandle) {\n        unsafe {\n            let h = &mut *handle;\n            let refs_before = *h.refs();\n            if refs_before == 0 {\n                error!(\"CacheRep::unref_entry: called with zero refcount\");\n                return;\n            }\n    \n            let refs_after = refs_before - 1;\n            h.set_refs(refs_after);\n    \n            trace!(\n                \"CacheRep::unref_entry: refs decremented to {}, in_cache={}\",\n                refs_after,\n                *h.in_cache()\n            );\n    \n            if refs_after == 0 {\n                debug!(\n                    \"CacheRep::unref_entry: dropping entry with charge={} and key_len={}\",\n                    *h.charge(),\n                    h.key().len()\n                );\n    \n                if *h.in_cache() {\n                    error!(\n                        \"CacheRep::unref_entry: freeing entry that is still marked in_cache\"\n                    );\n                }\n    \n                let key_slice = h.as_key_slice();\n                let deleter_fn = *h.deleter();\n                let value_ptr = *h.value();\n                (deleter_fn)(&key_slice, value_ptr);\n    \n                drop(Box::from_raw(handle));\n            }\n        }\n    }\n\n    pub(crate) fn evict_if_needed(&mut self) {\n        if self.capacity == 0 {\n            trace!(\"CacheRep::evict_if_needed: capacity is zero, nothing cached\");\n            return;\n        }\n    \n        while self.usage > self.capacity {\n            let mut candidate_key: Option<Vec<u8>> = None;\n            let mut oldest_clock = u64::MAX;\n    \n            for (k, &handle) in self.entries.iter() {\n                unsafe {\n                    let h = &*handle;\n                    if *h.in_cache() && *h.refs() == 1 && *h.last_use() < oldest_clock {\n                        oldest_clock = *h.last_use();\n                        candidate_key = Some(k.clone());\n                    }\n                }\n            }\n    \n            let key = match candidate_key {\n                Some(k) => k,\n                None => {\n                    debug!(\n                        \"CacheRep::evict_if_needed: usage={} capacity={} but all entries pinned; stopping eviction\",\n                        self.usage,\n                        self.capacity\n                    );\n                    break;\n                }\n            };\n    \n            if let Some(handle) = self.entries.remove(&key) {\n                unsafe {\n                    let h = &mut *handle;\n                    if *h.in_cache() {\n                        debug!(\n                            \"CacheRep::evict_if_needed: evicting key(len={}) charge={}\",\n                            h.key().len(),\n                            *h.charge()\n                        );\n                        h.set_in_cache(false);\n                        self.usage = self.usage.saturating_sub(*h.charge());\n                    } else {\n                        warn!(\n                            \"CacheRep::evict_if_needed: entry not marked in_cache during eviction\"\n                        );\n                    }\n                }\n                self.unref_entry(handle);\n            } else {\n                warn!(\n                    \"CacheRep::evict_if_needed: candidate key missing from entries; stopping\"\n                );\n                break;\n            }\n        }\n    }\n\n    pub(crate) fn prune_unused(&mut self) {\n        let keys: Vec<Vec<u8>> = self\n            .entries\n            .iter()\n            .filter_map(|(k, &handle)| unsafe {\n                let h = &*handle;\n                if *h.in_cache() && *h.refs() == 1 {\n                    Some(k.clone())\n                } else {\n                    None\n                }\n            })\n            .collect();\n    \n        for key in keys {\n            if let Some(handle) = self.entries.remove(&key) {\n                unsafe {\n                    let h = &mut *handle;\n                    if *h.in_cache() {\n                        h.set_in_cache(false);\n                        self.usage = self.usage.saturating_sub(*h.charge());\n                    }\n                }\n                self.unref_entry(handle);\n            }\n        }\n    }\n\n    pub(crate) fn clear_all(&mut self) {\n        debug!(\n            \"CacheRep::clear_all: destroying {} cached entries\",\n            self.entries.len()\n        );\n        let handles: Vec<*mut CacheHandle> = self.entries.values().copied().collect();\n        self.entries.clear();\n    \n        for handle in handles {\n            unsafe {\n                let h = &mut *handle;\n                if *h.in_cache() {\n                    self.usage = self.usage.saturating_sub(*h.charge());\n                    h.set_in_cache(false);\n                }\n            }\n            self.unref_entry(handle);\n        }\n    \n        self.usage = 0;\n    }\n\n    pub(crate) fn insert_entry(\n        &mut self,\n        key_:      &Slice,\n        value:     *mut c_void,\n        charge:    usize,\n        deleter:   CacheDeleterFn\n    ) -> *mut CacheHandle\n    {\n        let key_bytes = Self::slice_to_vec(key_);\n        let key_len = key_bytes.len();\n    \n        trace!(\n            \"CacheRep::insert_entry: key_len={} charge={} capacity={} usage_before={}\",\n            key_len,\n            charge,\n            self.capacity,\n            self.usage\n        );\n    \n        let handle_struct = CacheHandleBuilder::default()\n            .key(key_bytes.clone())\n            .value(value)\n            .deleter(deleter)\n            .charge(charge)\n            .refs(1)\n            .in_cache(false)\n            .last_use(self.clock)\n            .build()\n            .expect(\"CacheHandleBuilder should be fully initialized\");\n    \n        let handle_ptr: *mut CacheHandle = Box::into_raw(Box::new(handle_struct));\n    \n        if self.capacity > 0 {\n            unsafe {\n                let h = &mut *handle_ptr;\n                let current_refs = *h.refs();\n                let new_refs = current_refs\n                    .checked_add(1)\n                    .unwrap_or_else(|| {\n                        error!(\n                            \"CacheRep::insert_entry: reference count overflow while adding cache ref\"\n                        );\n                        current_refs\n                    });\n                h.set_refs(new_refs);\n                h.set_in_cache(true);\n            }\n    \n            self.usage = self.usage.saturating_add(charge);\n    \n            if let Some(old_ptr) = self.entries.insert(key_bytes, handle_ptr) {\n                debug!(\"CacheRep::insert_entry: replacing existing entry for key\");\n                unsafe {\n                    let old = &mut *old_ptr;\n                    if *old.in_cache() {\n                        self.usage = self.usage.saturating_sub(*old.charge());\n                        old.set_in_cache(false);\n                    }\n                }\n                self.unref_entry(old_ptr);\n            }\n    \n            self.evict_if_needed();\n        } else {\n            trace!(\"CacheRep::insert_entry: capacity is zero, not caching entry\");\n        }\n    \n        self.clock = self.clock.wrapping_add(1);\n    \n        handle_ptr\n    }\n\n    pub(crate) fn lookup_entry(&mut self, key_: &Slice) -> *mut CacheHandle {\n        let key_bytes = Self::slice_to_vec(key_);\n    \n        trace!(\n            \"CacheRep::lookup_entry: key_len={} usage={} capacity={}\",\n            key_bytes.len(),\n            self.usage,\n            self.capacity\n        );\n    \n        if let Some(&handle_ptr) = self.entries.get(&key_bytes) {\n            self.ref_entry(handle_ptr);\n            trace!(\"CacheRep::lookup_entry: hit\");\n            handle_ptr\n        } else {\n            trace!(\"CacheRep::lookup_entry: miss\");\n            std::ptr::null_mut()\n        }\n    }\n\n    pub(crate) fn erase_entry(&mut self, key_: &Slice) {\n        let key_bytes = Self::slice_to_vec(key_);\n    \n        trace!(\n            \"CacheRep::erase_entry: key_len={} usage_before={}\",\n            key_bytes.len(),\n            self.usage\n        );\n    \n        if let Some(handle_ptr) = self.entries.remove(&key_bytes) {\n            unsafe {\n                let h = &mut *handle_ptr;\n                if *h.in_cache() {\n                    h.set_in_cache(false);\n                    self.usage = self.usage.saturating_sub(*h.charge());\n                }\n            }\n            self.unref_entry(handle_ptr);\n        } else {\n            trace!(\"CacheRep::erase_entry: key not present\");\n        }\n    }\n}\n\n\nThis crate has the following authors:\n[\n    \"klebs <none>\",\n]\nThis crate has the following rust edition:\n2021\nThis crate has the following license:\nMIT\nThis crate is held in the following repository:\nhttps://github.com/klebs6/bitcoin-rs\n","role":"user"}],"model":"gpt-5.1"}}
