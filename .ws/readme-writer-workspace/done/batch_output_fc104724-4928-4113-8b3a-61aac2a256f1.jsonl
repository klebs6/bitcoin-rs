{"id": "batch_req_692ce5914454819098494639ba929b16", "custom_id": "bitcoinleveldb-bloom-ai-readme-request", "response": {"status_code": 200, "request_id": "42649d70bb88d061d9d72a58c8f1eb56", "body": {"id": "chatcmpl-ChmM092qkX82bTeaLKIarmtiDBwtg", "object": "chat.completion", "created": 1764550012, "model": "gpt-5.1-2025-11-13", "choices": [{"index": 0, "message": {"role": "assistant", "content": "```json\n{\n  \"fields\": {\n    \"crate_name\": \"bitcoinleveldb-bloom\",\n    \"full_readme_markdown\": \"# bitcoinleveldb-bloom\\n\\nLevelDB-compatible Bloom filter implementation and test harness used by the `bitcoin-rs` LevelDB port. This crate focuses on byte-level compatibility with the original C++ LevelDB `BuiltinBloomFilter2` policy while providing a safe Rust fa\u00e7ade.\\n\\n> NOTE: This README was generated by an AI model. It may not be perfectly accurate, but it should be a close and useful description of the crate.\\n\\n---\\n\\n## Overview\\n\\nThis crate implements a Bloom filter policy and supporting utilities mirroring LevelDB's built-in Bloom filter (`leveldb.BuiltinBloomFilter2`). It is intended to be plugged into a LevelDB-compatible storage engine within the `bitcoin-rs` project, but it can also be used as a standalone Bloom filter implementation over arbitrary byte slices.\\n\\nKey properties:\\n\\n- **LevelDB-compatible format**: Filters produced here are intended to be interoperable with LevelDB implementations using `BuiltinBloomFilter2` (same hashing scheme, layout, and trailing `k` marker).\\n- **Kirsch\u2013Mitzenmacher double hashing**: Efficient computation of multiple hash probes from a single 32-bit hash, as in the original LevelDB design.\\n- **Configurable bits-per-key**: Construct policies tuned for a target false positive rate / memory footprint trade-off.\\n- **Low-level slice interop**: Can construct filters from raw `Slice` pointers (for FFI / LevelDB core) or from standard `&[u8]` slices.\\n- **Instrumented** with `tracing` for detailed diagnostics in performance and correctness testing.\\n\\nThe crate exposes two main abstractions:\\n\\n- `BloomFilterPolicy`: a `FilterPolicy` / `CreateFilter` / `KeyMayMatch` implementation compatible with the LevelDB APIs provided elsewhere in `bitcoin-rs`.\\n- `BloomTest`: a stateful helper to accumulate keys, build a filter, and empirically measure false positive rates.\\n\\n---\\n\\n## Crate Integration\\n\\nThis crate lives inside the `bitcoin-rs` monorepo:\\n\\n- Repository: <https://github.com/klebs6/bitcoin-rs>\\n\\nIt assumes the existence of several traits and types from the surrounding LevelDB port, particularly:\\n\\n- `Slice`: a lightweight view over `*const u8` + length (mirroring LevelDB's `Slice`).\\n- `FilterPolicy`, `CreateFilter`, `KeyMayMatch`, `Named`: traits defining the filter behavior and metadata.\\n\\nIf you are using this crate outside the monorepo, you will typically consume it indirectly via the LevelDB layer that defines these traits and the `Slice` abstraction.\\n\\n---\\n\\n## Installation\\n\\nIn your `Cargo.toml`:\\n\\n```toml\\n[dependencies]\\nbitcoinleveldb-bloom = \\\"0.1.19\\\"\\n```\\n\\nThis crate uses Rust 2021 edition and is licensed under MIT.\\n\\n---\\n\\n## Core Types\\n\\n### `BloomFilterPolicy`\\n\\n```rust\\n#[derive(Clone, Debug, Getters, Setters, Builder)]\\n#[getset(get = \\\"pub\\\", set = \\\"pub\\\")]\\npub struct BloomFilterPolicy {\\n    bits_per_key: usize,\\n    k: usize,\\n}\\n```\\n\\n`BloomFilterPolicy` encapsulates the Bloom filter configuration:\\n\\n- `bits_per_key`: approximate number of bits in the filter per inserted key.\\n- `k`: number of hash probes per key (automatically derived from `bits_per_key`).\\n\\nConstruction:\\n\\n```rust\\nimpl BloomFilterPolicy {\\n    pub fn new(bits_per_key_: i32) -> Self { /* ... */ }\\n}\\n\\npub fn new_bloom_filter_policy(bits_per_key_: i32) -> Box<dyn FilterPolicy> { /* ... */ }\\n```\\n\\nBehavior:\\n\\n- Negative `bits_per_key_` is clamped to `0`, then coerced to at least `1` bit per key.\\n- `k` is computed as `k = floor(bits_per_key * ln(2)) \u2248 floor(bits_per_key * 0.69)`, which approximates the theoretically optimal number of probes and is then clamped to `1 \u2264 k \u2264 30`.\\n\\nThis matches the LevelDB design: choosing `k = ln(2) * m/n` where `m` is the number of bits and `n` is the number of keys minimizes false positives for a given filter size.\\n\\nInterfaces implemented (from the LevelDB API layer):\\n\\n- `Named` \u2014 returns `\\\"leveldb.BuiltinBloomFilter2\\\"` for wire compatibility.\\n- `FilterPolicy` \u2014 marker trait for LevelDB filter policies.\\n- `CreateFilter` \u2014 builds filters from `*const Slice`.\\n- `KeyMayMatch` \u2014 checks potential membership using a `Slice` key and filter.\\n\\n#### Byte-Slice Interface\\n\\nThe policy exposes a fully byte-based API for independent use:\\n\\n```rust\\nimpl BloomFilterPolicy {\\n    pub fn create_filter_from_bytes(&self, keys: &[&[u8]], dst: &mut Vec<u8>);\\n    pub fn key_may_match_bytes(&self, key: &[u8], bloom_filter: &[u8]) -> bool;\\n}\\n```\\n\\n`create_filter_from_bytes`:\\n\\n- Input: `keys: &[&[u8]]` \u2014 array of byte-slice keys.\\n- Output: appends a filter to `dst`:\\n  - A fresh region of `bytes` zero-initialized bytes for the bitset.\\n  - A single trailing byte encoding `k`.\\n\\nFilter layout:\\n\\n- Let `num_keys = keys.len()`.\\n- Bits per key: `bpk = self.bits_per_key`.\\n- Raw bits: `bits = max(64, num_keys * bpk)` \u2014 small filters are padded to at least 64 bits to avoid pathological false positive rates.\\n- Bytes: `bytes = (bits + 7) / 8` and `bits` is rounded up to a multiple of 8.\\n- `dst` is extended by `bytes` zero bytes, then a trailing byte `k` is pushed.\\n\\nHashing (`Kirsch\u2013Mitzenmacher` double hashing):\\n\\n- Base hash: `h = leveldb_hash(key, seed = 0xbc9f1d34)`.\\n- Delta: `delta = (h >> 17) | (h << 15)` (rotate right by 17 bits).\\n- For each `probe` from `0` to `k-1`:\\n  - `bitpos = (h % bits)`.\\n  - `array[bitpos / 8] |= 1 << (bitpos % 8)`.\\n  - `h = h.wrapping_add(delta)`.\\n\\nThis is exactly the double-hashing construction described by Kirsch and Mitzenmacher, reducing the cost of `k` independent hashes to a single base hash plus linear updates.\\n\\n`key_may_match_bytes`:\\n\\n- Ensures the filter has at least length 2 and decodes:\\n  - `bits = (len(filter) - 1) * 8`.\\n  - `k = filter[len(filter)-1]`.\\n- If `k > 30`, the function treats the filter as a match for compatibility with potential future encodings (matching LevelDB's semantics).\\n- Otherwise performs the same double hashing scheme and returns `false` on the first missing bit, `true` if all `k` bits are present.\\n\\nThis provides a canonical, constant-time-per-probe membership test with standard Bloom filter semantics.\\n\\n### `BloomTest`\\n\\n```rust\\n#[derive(Debug, Getters, Setters, Builder)]\\n#[getset(get = \\\"pub\\\", set = \\\"pub\\\")]\\npub struct BloomTest {\\n    policy: BloomFilterPolicy,\\n    filter: Vec<u8>,\\n    keys: Vec<Vec<u8>>,\\n}\\n```\\n\\n`BloomTest` is a harness around `BloomFilterPolicy` used to:\\n\\n- Accumulate keys.\\n- Build a filter from them.\\n- Probe membership.\\n- Empirically estimate false positive rate.\\n\\nKey methods:\\n\\n```rust\\nimpl BloomTest {\\n    pub fn reset(&mut self);\\n    pub fn add_key_slice(&mut self, key: &[u8]);\\n    pub fn add_key_str(&mut self, key: &str);\\n    pub fn add_key_slice_object(&mut self, s: &Slice);\\n    pub fn add(&mut self, s: &Slice);\\n\\n    pub fn build(&mut self);\\n    pub fn filter_size(&self) -> usize;\\n    pub fn dump_filter(&self);\\n\\n    pub fn matches_slice(&mut self, key: &[u8]) -> bool;\\n    pub fn matches_str(&mut self, key: &str) -> bool;\\n\\n    pub fn false_positive_rate(&mut self) -> f64;\\n}\\n```\\n\\nBehavior:\\n\\n- `Default` builds a policy with `bits_per_key = 10` (roughly ~1% false positive rate in classical Bloom filter analysis).\\n- `add_*` methods stage keys in `self.keys`.\\n- `build` converts all staged keys into a single Bloom filter (using `create_filter_from_bytes`), stores it in `self.filter`, and clears `keys`.\\n- `matches_*` lazily builds the filter if `keys` is not empty before checking membership.\\n- `false_positive_rate` tests 10,000 new keys encoded via `encode_fixed32_into` into a 4-byte buffer, offset by `1_000_000_000` to avoid overlap with typical test data, counts how many yield `true` under `matches_slice`, and returns the observed fraction.\\n\\n`dump_filter` logs a textual visualization of the filter bits, ignoring the trailing `k` byte, with bits rendered as `1` (set) or `.` (unset) and space-separated per byte.\\n\\n---\\n\\n## Low-Level Utilities\\n\\n### Hashing and Encoding\\n\\n```rust\\npub fn bloom_hash(key_: &Slice) -> u32 { /* ... */ }\\n```\\n\\n- Computes the LevelDB Bloom hash for a `Slice` using `leveldb_hash` with seed `0xbc9f1d34`.\\n- Used as the foundation of `BloomFilterPolicy`'s hashing scheme.\\n\\n```rust\\npub fn encode_fixed32_to_bytes(value: u32) -> [u8; 4];\\npub fn encode_fixed32_into(value: u32, buffer: &mut [u8; 4]);\\n```\\n\\n- Encode `u32` values into 4-byte little-endian representation, mirroring LevelDB's fixed-width integer encoding.\\n\\n### Synthetic Keys and Length Progression\\n\\n```rust\\npub fn key(i: i32, buffer: *mut u8) -> Slice { /* ... */ }\\n```\\n\\n- Encodes `i` with `encode_fixed32_to_bytes` into `buffer` and returns a `Slice` over it.\\n- If `buffer` is null, returns an empty `Slice` built from a null pointer and zero length (for defensive usage patterns).\\n\\n```rust\\npub fn next_length(length: i32) -> i32 { /* ... */ }\\n```\\n\\n- Generates a simple sequence for test sizes: increments by 1 below 10, by 10 below 100, by 100 below 1000, then by 1000.\\n- Useful for iterating over key counts in scalability benchmarks.\\n\\n---\\n\\n## Usage Examples\\n\\n### Basic: Build a Bloom Filter from Byte Slices\\n\\n```rust\\nuse bitcoinleveldb_bloom::BloomFilterPolicy;\\n\\nfn main() {\\n    // Aim for ~10 bits per key (typical LevelDB default).\\n    let policy = BloomFilterPolicy::new(10);\\n\\n    // Keys as raw byte slices.\\n    let key1 = b\\\"alpha\\\";\\n    let key2 = b\\\"beta\\\";\\n    let key3 = b\\\"gamma\\\";\\n    let keys: [&[u8]; 3] = [key1.as_ref(), key2.as_ref(), key3.as_ref()];\\n\\n    let mut filter = Vec::new();\\n    policy.create_filter_from_bytes(&keys, &mut filter);\\n\\n    assert!(policy.key_may_match_bytes(b\\\"alpha\\\", &filter));\\n    assert!(policy.key_may_match_bytes(b\\\"beta\\\", &filter));\\n\\n    // Typical Bloom filter behavior: non-members should usually be rejected,\\n    // but could be false positives.\\n    let might_contain = policy.key_may_match_bytes(b\\\"delta\\\", &filter);\\n    println!(\\\"delta may be in the set: {might_contain}\\\");\\n}\\n```\\n\\n### Using `BloomTest` to Empirically Check False Positives\\n\\n```rust\\nuse bitcoinleveldb_bloom::BloomTest;\\n\\nfn main() {\\n    let mut tester = BloomTest::default();\\n\\n    // Add some keys.\\n    tester.add_key_str(\\\"a\\\");\\n    tester.add_key_str(\\\"b\\\");\\n    tester.add_key_str(\\\"c\\\");\\n\\n    // Build the filter explicitly (matches_* will also build lazily).\\n    tester.build();\\n\\n    assert!(tester.matches_str(\\\"a\\\"));\\n    assert!(tester.matches_str(\\\"b\\\"));\\n    assert!(tester.matches_str(\\\"c\\\"));\\n\\n    let fp_rate = tester.false_positive_rate();\\n    println!(\\\"Observed false positive rate: {fp_rate:.4}\\\");\\n}\\n```\\n\\n### Integrating via `FilterPolicy` Trait Objects\\n\\n```rust\\nuse bitcoinleveldb_bloom::new_bloom_filter_policy;\\n// use crate::leveldb::{FilterPolicy, Options, DB}; // from bitcoin-rs LevelDB layer\\n\\nfn configure_leveldb() {\\n    // Create a boxed policy with 10 bits per key.\\n    let bloom_policy = new_bloom_filter_policy(10);\\n\\n    // This example is schematic; actual LevelDB options will be defined by the\\n    // surrounding `bitcoin-rs` LevelDB wrapper.\\n    //\\n    // let mut options = Options::default();\\n    // options.filter_policy = Some(bloom_policy);\\n    // let db = DB::open(options, \\\"/path/to/db\\\").unwrap();\\n}\\n```\\n\\n---\\n\\n## Mathematical and Algorithmic Notes\\n\\nThe Bloom filter implemented here follows the classical analysis:\\n\\n- A Bloom filter is a bit vector of length `m` with `k` hash functions.\\n- After inserting `n` keys, the probability of a false positive is approximately:\\n\\n\\\\[\\n  p \\\\approx \\\\left(1 - e^{-kn/m}\\\\right)^k.\\n\\\\]\\n\\nChoosing `m = bits_per_key * n` and `k \u2248 ln(2) * m/n` minimizes `p` for fixed `m`, and yields:\\n\\n\\\\[\\n  p_{min} \\\\approx (0.5)^{bits\\\\_per\\\\_key \\\\cdot \\\\ln 2} \\\\approx (0.6185)^{bits\\\\_per\\\\_key}.\\n\\\\]\\n\\nThus:\\n\\n- `bits_per_key = 10` gives `p \u2248 0.8%`.\\n- Smaller `bits_per_key` trades memory for increased false positives.\\n\\nThe Kirsch\u2013Mitzenmacher double hashing used in this crate preserves asymptotic false positive characteristics while reducing hash computation to a single base hash plus linear updates.\\n\\nThe filter construction additionally enforces `bits \u2265 64` for small `n`, preventing degenerate configurations where `m` becomes so small that the asymptotic approximation no longer yields reasonable behavior.\\n\\n---\\n\\n## Tracing and Diagnostics\\n\\nAll core operations (construction, hashing, filter building, membership testing) are instrumented with the `tracing` crate, using log levels:\\n\\n- `info!` for high-level events (policy construction, false positive statistics),\\n- `debug!` for structural details (filter sizes, reset actions),\\n- `trace!` for per-key and per-bit actions (probing, bit-setting),\\n- `warn!` and `error!` for anomalous conditions (invalid parameters, null pointers where unexpected).\\n\\nEnable appropriate `tracing` subscribers in your application to inspect filter behavior, verify interoperability, or benchmark performance.\\n\\n---\\n\\n## Safety and FFI Considerations\\n\\nThe crate assumes a `Slice` type akin to LevelDB's, consisting of a raw pointer and length. The unsafe blocks are localized and guarded:\\n\\n- Null pointers from `Slice::data()` with zero length are handled gracefully, treated as empty keys.\\n- `create_filter` converts `*const Slice` + `n` into a slice with `from_raw_parts`, only when `n > 0` and `keys` is non-null.\\n- Byte slices are always reconstructed with lengths derived from the `Slice` metadata.\\n\\nWhen integrating with C or C++:\\n\\n- Ensure `Slice` lifetime guarantees match those expected by the Rust side.\\n- Ensure that any `*mut u8` passed into `key` points to at least 4 bytes of valid writable memory.\\n\\n---\\n\\n## License\\n\\nThis crate is distributed under the MIT License. See the repository for full licensing information.\\n\",\n    \"package_categories\": [\n      \"algorithms\",\n      \"data-structures\",\n      \"cryptography\",\n      \"database\",\n      \"science\"\n    ],\n    \"package_description\": \"LevelDB-compatible Bloom filter policy and test harness for the bitcoin-rs LevelDB port, implementing Kirsch\u2013Mitzenmacher double hashing over byte slices.\",\n    \"package_keywords\": [\n      \"bloom-filter\",\n      \"leveldb\",\n      \"bitcoin\",\n      \"database\",\n      \"probabilistic\"\n    ]\n  },\n  \"struct_docs\": \" This structure is a directive indicating which fields we need you to provide for us in your response to our query.\\n\",\n  \"struct_name\": \"AiReadmeWriterDesiredOutput\",\n  \"type\": \"struct\"\n}\n```", "refusal": null, "annotations": []}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 5684, "completion_tokens": 4030, "total_tokens": 9714, "prompt_tokens_details": {"cached_tokens": 1792, "audio_tokens": 0}, "completion_tokens_details": {"reasoning_tokens": 0, "audio_tokens": 0, "accepted_prediction_tokens": 0, "rejected_prediction_tokens": 0}}, "service_tier": "default", "system_fingerprint": null}}, "error": null}
