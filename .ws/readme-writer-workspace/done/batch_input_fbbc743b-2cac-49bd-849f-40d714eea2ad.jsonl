{"custom_id":"bitcoin-crc32c-ai-readme-request","method":"POST","url":"/v1/chat/completions","body":{"max_completion_tokens":8192,"messages":[{"content":"We would like you to write a README.md for a rust crate with maximally helpful content.\nAdditionally, we would like you to generate several fields from the Cargo.toml package section for this crate.\nWe will show you the strict json output format we would like you to provide.\nPlease tailor your response for an apex consumer of maximal intelligence.\nA reader of this README.md should have a good sense of what the crate does and how to use it after reading what you write.\nPlease include a messaage indicating that this README.md file was generated by an AI model and may not be 100% accurate however it should be pretty good.\n\n\nCarefully read and parse the information we sent you.\n\nWe want to generate all information items requested by our schema:\n\n- Read the description of each field. Use it, along with the content we sent you to generate an appropriate value for each.\n- Ensure that each generated field optimally serves its desired purpose.\n- Each item should be deep, detailed, and specific. Use optimally descriptive and useful language. Do not be too verbose.\n- Do not add any extra keys to the generated object. Generate precisely what we ask of you: no more, no less.\n- For fields which are of an enum type: pick *exactly one variant*. Do not generate any information for the unselected variants.\n- For array fields: supply a JSON list [ ... ] of items, each conforming to the correct item type.\n- For map fields: Provide a JSON object { \"key_as_string\": <value>, ... }. Keys must be valid JSON strings. Keys and Values must conform to the key and value schemas we provide to you. Fill all subfields of each and every map value.\n- If we ask you to justify a map field, provide your justification/confidence score for the entire map. Do not attempt to separately justify each map element.\n- Likewise, if we ask you to justify an array field, provide your justification/confidence score for the entire array. Do not attempt to separately justify each element.\n- Provide numeric fields as real JSON numbers (not strings).\n- For string fields: provide the value precisely as a string literal. If optional, you may set it to null.\n- If we ask you to justify or provide confidence scores for the fields of a structure, please do so carefully. For each field we ask you to justify, please explain or justify your choice clearly. Confidence scores must be specified as real JSON numbers in the range `[0..1]`.\n- If we ask to you generate an optional field, either fill it or set it to null.\n- If we ask you to justify your choice of an enum variant, please explain your choice clearly. Do not justify your decision to leave a variant unselected. Provide your justification as a JSON string. Provide your confidence score as a real JSON number in the range `[0..1]`.\n- In terms of the JSON format we would like you to provide, the object itself will be deserialied based on the following schema. \n- We begin exactly at the top: the data should not be nested under a parent named 'fields' or anything similar.\n\n## Here is the schema to use:\n\nObject {\n    \"fields\": Object {\n        \"crate_name\": Object {\n            \"generation_instructions\": String(\"\\\"This string should be the name of our crate, *verbatim*, trimmed for use as a toml field\\\"\"),\n            \"required\": Bool(true),\n            \"type\": String(\"string\"),\n        },\n        \"full_readme_markdown\": Object {\n            \"generation_instructions\": String(\"\\\"This string should be valid markdown representing the readme for this crate.\\\\n\\\\n Please make it terse, useful, and designed for an industrious commercially savy consumer of industrious nature. \\\\n\\\\n Advanced vocabulary and concepts are welcome. \\\\n\\\\n If this crate involves concepts from mathematics and/or physics, please describe and document them here.\\\"\"),\n            \"required\": Bool(true),\n            \"type\": String(\"string\"),\n        },\n        \"package_categories\": Object {\n            \"generation_instructions\": String(\"\\\"These categories will be used in our Cargo.toml file.\\\\n\\\\n It is important that users of this crate can find it on crates.io.\\\\n\\\\n Choose maximum 5 categories and make sure they are actually meaningful for our crate.\\\\n\\\\n These categories should only be chosen from among the legal crates.io categories. \\\\n\\\\n The ONLY legal categoreis are:\\\\n\\\\n``\\\\n accessibility\\\\n aerospace\\\\n algorithms\\\\n api-bindings\\\\n asynchronous\\\\n authentication\\\\n caching\\\\n command-line-interface\\\\n command-line-utilities\\\\n compilers\\\\n compression\\\\n computer-vision\\\\n concurrency\\\\n config\\\\n cryptography\\\\n data-structures\\\\n database\\\\n database-implementations\\\\n date-and-time\\\\n development-tools\\\\n email\\\\n embedded\\\\n emulators\\\\n encoding\\\\n external-ffi-bindings\\\\n filesystem\\\\n finance\\\\n game-development\\\\n game-engines\\\\n games\\\\n graphics\\\\n gui\\\\n hardware-support\\\\n internationalization\\\\n localization\\\\n mathematics\\\\n memory-management\\\\n multimedia\\\\n network-programming\\\\n no-std\\\\n os\\\\n parser-implementations\\\\n parsing\\\\n rendering\\\\n rust-patterns\\\\n science\\\\n simulation\\\\n template-engine\\\\n text-editors\\\\n text-processing\\\\n value-formatting\\\\n virtualization\\\\n visualization\\\\n wasm\\\\n web-programming\\\\n ``\\\\n\\\\n DO NOT specify a category that is not on this list.\\\"\"),\n            \"required\": Bool(true),\n            \"type\": String(\"array_of_strings\"),\n        },\n        \"package_description\": Object {\n            \"generation_instructions\": String(\"\\\"We will place this package_description in our Cargo.toml file so the users of this crate\\\\n know what it does.\\\\n\\\\n The discription should be technical, clear, and useful. It should be terse.\\\"\"),\n            \"required\": Bool(true),\n            \"type\": String(\"string\"),\n        },\n        \"package_keywords\": Object {\n            \"generation_instructions\": String(\"\\\"These keywords will be used in our Cargo.toml file so the users of this crate can easily\\\\n find it in the package system. Keywords should be useful, varied, meaningful, and reflect\\\\n the contents of our crate. They should make it easy to find. Please provide exactly five.\\\"\"),\n            \"required\": Bool(true),\n            \"type\": String(\"array_of_strings\"),\n        },\n    },\n    \"struct_docs\": String(\" This structure is a directive indicating which fields we need you to provide for us in your response to our query.\\n\"),\n    \"struct_name\": String(\"AiReadmeWriterDesiredOutput\"),\n    \"type\": String(\"struct\"),\n}\n\n## Please keep the following in mind:\n\nEntry phrasing:\n\n- Ensure entries are concise and focused.\n- Ensure there are no vague phrases (e.g., avoid starting with \"Illustrates the something something...\"; instead, use direct details like \"The hanging green vines on the garden wall\").\n\nEnsure Clarity and Consistency:\n\n- Use clear, grammatically correct sentences.\n- Maintain a consistent tone and style throughout.\n\nEnrich Content:\n\n- Communicate additional information where appropriate to enhance depth and value.\n- If a mathematical, physical, or otherwise technical background is helpful, please provide it.\n- Ensure that the content is comprehensive and meets all requirements.\n\nFocus Language:\n\n- Use deliberate and precise language.\n- Avoid vague verbs and keep the maximally intelligent and detail oriented audience in mind. \n- We explicitly ban the words `hush`, `subtle`, `mythic`, and `aura`. Please keep your vocabulary choices rigorous.\n- Do not use modern cultural references \n- Do not generically reference ideas which do not belong in the global environment.\n\n## Present the Final JSON:\n\n- Format the output as a JSON object.\n- Include all fields properly named from the schema we sent you.\n\nEnsure Proper Formatting:\n\n- Use proper JSON syntax with keys and arrays.\n- Ensure that all entries are correctly placed in their respective places.\n\nProvide only the final JSON data as specified by the schema. \n\nDo not include any schema generation instructions, meta-fields, nested-templates (unless directly asked) or extraneous information. \n\nProvide only the populated fields and their values, conforming exactly to the required structure without embedding any intermediate annotations or placeholders.\n\nYour output should only consist of the JSON object. do *not* include a preamble or postamble to your response. \n\nWe seek to successfully parse your response directly as JSON.\n\nFor the final answer, output the result only as a valid JSON object, wrapped inside triple backticks with json immediately after the opening backticks.\nThe JSON must be parser-ready:\n– No additional text before or after the block\n– No markdown or prose outside the fenced block\n– No HTML escaping of quotes, slashes, or other characters\n– Indentation and whitespace preserved exactly as written\n– The content between the fences must be valid JSON as per RFC 8259","role":"system"},{"content":"We have a rust crate named 'bitcoin-crc32c' 0.1.19. \n\nHere is the interface:\npub struct PortableTestTraits  { }\n\n#[inline]\npub fn crc32c_extend_arm64(mut crc: u32, mut data: *const u8, mut size: usize) -> u32 {\n    let mut length = size as isize;\n\n    crc ^= CRC32XOR;\n\n    while length >= KBYTES as isize {\n        // --- process 1 KiB in four independent 256 B segments ---------------\n        let mut crc0 = crc;\n        let mut crc1 = 0u32;\n        let mut crc2 = 0u32;\n        let mut crc3 = 0u32;\n\n        data = crc32c1024bytes(&mut crc0,&mut crc1,&mut crc2,&mut crc3,data);\n\n        // --- GF(2) polynomial merging of the four partial CRCs --------------\n        let t2 = vgetq_lane_u64::<1>(vmull_p64(crc2 as u64, K2));\n        let t1 = vgetq_lane_u64::<1>(vmull_p64(crc1 as u64, K1));\n        let t0 = vgetq_lane_u64::<1>(vmull_p64(crc0 as u64, K0));\n\n        crc  = __crc32cd(crc3, core::ptr::read_unaligned(data as *const u64));\n        data = data.add(core::mem::size_of::<u64>());\n\n        crc ^= __crc32cd(0, t2);\n        crc ^= __crc32cd(0, t1);\n        crc ^= __crc32cd(0, t0);\n\n        length -= KBYTES as isize;\n    }\n\n    // ---------------- fast 8‑byte loop --------------------------------------\n    while length >= 8 {\n        crc = __crc32cd(crc, core::ptr::read_unaligned(data as *const u64));\n        data = data.add(8);\n        length -= 8;\n    }\n\n    // ---------------- remaining tail  ---------------------------------------\n    if (length & 4) != 0 {\n        crc = __crc32cw(crc, core::ptr::read_unaligned(data as *const u32));\n        data = data.add(4);\n    }\n    if (length & 2) != 0 {\n        crc = __crc32ch(crc, core::ptr::read_unaligned(data as *const u16));\n        data = data.add(2);\n    }\n    if (length & 1) != 0 {\n        crc = __crc32cb(crc, *data);\n    }\n\n    crc ^ CRC32XOR\n}\n\n\n/// Computes the CRC32C of \"count\" bytes in the buffer pointed by \"data\".\n///\n/// Convenience helper: CRC of a single buffer.\n/// # Safety\n/// `data` **must** be valid for `count` bytes.\n#[inline]\npub fn crc32c_value(data: *const u8, count: usize) -> u32 {\n    trace!(count, \"crc32c_value()\");\n    crc32c_extend(0, data, count)\n}\n\n\n/// Computes the CRC32C of \"count\" bytes in the buffer pointed by \"data\".\n///\n/// Shorthand identical to `crc32c_value`.\n/// # Safety\n/// `data` **must** be valid for `count` bytes.\n#[inline]\npub fn crc32c(data: *const u8, count: usize) -> u32 {\n    crc32c_extend(0, data, count)\n}\n\n\n/// Computes the CRC32C of the string's content.\n///\n/// Safe wrapper for Rust `&str`.\n#[inline]\npub fn crc32c_with_str(string: &str) -> u32 {\n    trace!(len = string.len(), \"crc32c_with_str()\");\n    unsafe { crc32c_value(string.as_ptr(), string.len()) }\n}\n\n\n/// Extends \"crc\" with the CRC32C of \"count\" bytes in the buffer pointed by\n/// \"data\".\n///\n/// Dispatch to the fastest back‑end that is *both* compiled‑in **and**\n/// available at run‑time.\n/// # Safety\n/// `data` **must** be valid for `count` bytes.\n#[inline]\npub fn crc32c_extend(crc: u32, data: *const u8, count: usize) -> u32 {\n    trace!(crc, count, \"crc32c_extend()‑dispatcher\");\n\n    // ---------- x86‑64 / SSE4.2 ----------\n    #[cfg(target_arch = \"x86_64\")]\n    {\n        if can_use_sse42() {\n            return crc32c_extend_sse42(crc, data, count);\n        }\n    }\n\n    // ---------- AArch64 / CRC + PMULL ---\n    #[cfg(target_arch = \"aarch64\")]\n    {\n        if can_use_arm64_crc32() {\n            return crc32c_extend_arm64(crc, data, count);\n        }\n    }\n\n    // ---------- Portable fallback -------\n    crc32c_extend_portable(crc, data, count)\n}\n\n\n/// SSE4.2-accelerated implementation in crc32c_sse42.cc\n#[cfg(target_arch = \"x86_64\")]\n#[inline]\npub fn crc32c_extend_sse42(crc: u32, data: *const u8, size: usize) -> u32 {\n    use sse42_crc32c::*;\n\n    use core::arch::x86_64::{\n        _mm_crc32_u32 as crc32_u32, _mm_crc32_u64 as crc32_u64, _mm_crc32_u8 as crc32_u8,\n    };\n\n    trace!(crc, size, \"crc32c_extend_sse42()\");\n\n    // ---------------- helpers (formerly pre‑processor macros) ----------------\n    #[inline(always)]\n    unsafe fn step1(l: &mut u32, p: &mut *const u8) {\n        *l = crc32_u8(*l, **p);\n        *p = p.add(1);\n    }\n\n    #[inline(always)]\n    unsafe fn step4(crc: &mut u32, p: &mut *const u8) {\n        *crc = crc32_u32(*crc, read_uint32le(*p));\n        *p = p.add(4);\n    }\n\n    #[inline(always)]\n    unsafe fn step8(crc: &mut u64, data: &mut *const u8) {\n        *crc = crc32_u64(*crc, read_uint64le(*data));\n        *data = data.add(8);\n    }\n\n    #[inline(always)]\n    unsafe fn step8_by3(\n        crc0: &mut u64,\n        crc1: &mut u64,\n        crc2: &mut u64,\n        p0: &mut *const u8,\n        p1: &mut *const u8,\n        p2: &mut *const u8,\n    ) {\n        step8(crc0, p0);\n        step8(crc1, p1);\n        step8(crc2, p2);\n    }\n\n    #[inline(always)]\n    unsafe fn step8x3(\n        crc0: &mut u64,\n        crc1: &mut u64,\n        crc2: &mut u64,\n        p: &mut *const u8,\n        block_span: isize,\n    ) {\n        *crc0 = crc32_u64(*crc0, read_uint64le(*p));\n        *crc1 = crc32_u64(*crc1, read_uint64le(p.offset(block_span)));\n        *crc2 = crc32_u64(*crc2, read_uint64le(p.offset(2 * block_span)));\n        *p = p.add(8);\n    }\n\n    #[inline(always)]\n    fn skip_block(mut crc: u64, table: &[[u32; 16]; 8]) -> u64 {\n        let c32 = crc as u32;\n        crc = table[0][(c32 & 0xF) as usize] as u64\n            ^ table[1][((c32 >> 4) & 0xF) as usize] as u64\n            ^ table[2][((c32 >> 8) & 0xF) as usize] as u64\n            ^ table[3][((c32 >> 12) & 0xF) as usize] as u64\n            ^ table[4][((c32 >> 16) & 0xF) as usize] as u64\n            ^ table[5][((c32 >> 20) & 0xF) as usize] as u64\n            ^ table[6][((c32 >> 24) & 0xF) as usize] as u64\n            ^ table[7][((c32 >> 28) & 0xF) as usize] as u64;\n        crc\n    }\n\n    // ---------------- main algorithm ----------------\n    let mut p = data;\n    let e = data.add(size);\n    let mut l: u32 = crc ^ CRC32XOR;\n\n    // Align ‑ process up to first 8‑byte boundary.\n    let x = crate::round_up::<8>(p);\n    if x <= e {\n        while p != x {\n            step1(&mut l, &mut p);\n        }\n    }\n\n    // Typed as u64 for the SIMD path.\n    let mut l64 = l as u64;\n\n    // ==== big‑block loop (kBlock0Size) =================================================\n    while e.offset_from(p) >= GROUPS * BLOCK_0SIZE {\n        let mut l641: u64 = 0;\n        let mut l642: u64 = 0;\n        for _ in 0..(BLOCK_0SIZE / 64) {\n            // Prefetch far ahead to hide DRAM latency.\n            request_prefetch(p.offset(PREFETCH_HORIZON));\n            request_prefetch(p.offset(BLOCK_0SIZE + PREFETCH_HORIZON));\n            request_prefetch(p.offset(2 * BLOCK_0SIZE + PREFETCH_HORIZON));\n\n            // 64 bytes: eight 8‑byte triples.\n            for _ in 0..8 {\n                step8x3(&mut l64, &mut l641, &mut l642, &mut p, BLOCK_0SIZE);\n            }\n        }\n        l64 = skip_block(l64, &BLOCK_0SKIP_TABLE);\n        l64 ^= l641;\n        l64 = skip_block(l64, &BLOCK_0SKIP_TABLE);\n        l64 ^= l642;\n        p = p.offset((GROUPS - 1) * BLOCK_0SIZE);\n    }\n\n    // ==== medium‑block loop (kBlock1Size) =============================================\n    while e.offset_from(p) >= GROUPS * BLOCK_1SIZE {\n        let mut l641: u64 = 0;\n        let mut l642: u64 = 0;\n        for _ in 0..(BLOCK_1SIZE / 8) {\n            step8x3(&mut l64, &mut l641, &mut l642, &mut p, BLOCK_1SIZE);\n        }\n        l64 = skip_block(l64, &BLOCK_1SKIP_TABLE);\n        l64 ^= l641;\n        l64 = skip_block(l64, &BLOCK_1SKIP_TABLE);\n        l64 ^= l642;\n        p = p.offset((GROUPS - 1) * BLOCK_1SIZE);\n    }\n\n    // ==== small‑block loop (kBlock2Size) =============================================\n    while e.offset_from(p) >= GROUPS * BLOCK_2SIZE {\n        let mut l641: u64 = 0;\n        let mut l642: u64 = 0;\n        for _ in 0..(BLOCK_2SIZE / 8) {\n            step8x3(&mut l64, &mut l641, &mut l642, &mut p, BLOCK_2SIZE);\n        }\n        l64 = skip_block(l64, &BLOCK_2SKIP_TABLE);\n        l64 ^= l641;\n        l64 = skip_block(l64, &BLOCK_2SKIP_TABLE);\n        l64 ^= l642;\n        p = p.offset((GROUPS - 1) * BLOCK_2SIZE);\n    }\n\n    // ==== 16‑byte chunks ==============================================================\n    while e.offset_from(p) >= 16 {\n        step8(&mut l64, &mut p); // first 8 bytes\n        step8(&mut l64, &mut p); // next 8 bytes\n    }\n\n    // Cast back to u32 for tail processing.\n    let mut l = l64 as u32;\n\n    // ==== remaining <16 bytes =========================================================\n    while p != e {\n        step1(&mut l, &mut p);\n    }\n\n    let result = l ^ CRC32XOR;\n    trace!(\"crc32c_extend_sse42() finished (crc={:#010x})\", result);\n    result\n}\n\n\n/// Round an integer value **up** to the next multiple of `N`.\n///\n/// `N` must be a power‑of‑two; enforced at **compile‑time**.\n#[inline]\npub fn round_up_with_uintptr<const N: usize>(pointer: usize) -> usize {\n    [\"N must be a power of two\"][(N & (N - 1) != 0) as usize];\n    (pointer + (N - 1)) & !(N - 1)\n}\n\n\n/// Round a raw byte pointer **up** to the next `N`‑byte‑aligned address.\n///\n/// *Not* a `const fn` (Rust forbids pointer→integer casts in CTFE).\n#[inline]\npub fn round_up<const N: usize>(pointer: *const u8) -> *const u8 {\n    let rounded = round_up_with_uintptr::<N>(pointer as usize) as *const u8;\n    trace!(?pointer, ?rounded, alignment = N, \"round_up(pointer)\");\n    rounded\n}\n\n\n/// Read a little‑endian `u32` from an arbitrary byte pointer.\n///\n/// # Safety\n/// `buffer` **must** be valid for at least four bytes.\n#[inline]\npub fn read_uint32le(buffer: *const u8) -> u32 {\n    let value = if cfg!(target_endian = \"big\") {\n        let b: &[u8] = std::slice::from_raw_parts(buffer, 4);\n        (b[0] as u32)\n            | ((b[1] as u32) << 8)\n            | ((b[2] as u32) << 16)\n            | ((b[3] as u32) << 24)\n    } else {\n        let mut tmp = MaybeUninit::<u32>::uninit();\n        core::ptr::copy_nonoverlapping(buffer, tmp.as_mut_ptr() as *mut u8, 4);\n        u32::from_le(tmp.assume_init())\n    };\n    trace!(addr = ?buffer, value, \"read_uint32le\");\n    value\n}\n\n\n/// Read a little‑endian `u64` from an arbitrary byte pointer.\n///\n/// # Safety\n/// `buffer` **must** be valid for at least eight bytes.\n#[inline]\npub fn read_uint64le(buffer: *const u8) -> u64 {\n    let value = if cfg!(target_endian = \"big\") {\n        let b: &[u8] = std::slice::from_raw_parts(buffer, 8);\n        (b[0] as u64)\n            | ((b[1] as u64) << 8)\n            | ((b[2] as u64) << 16)\n            | ((b[3] as u64) << 24)\n            | ((b[4] as u64) << 32)\n            | ((b[5] as u64) << 40)\n            | ((b[6] as u64) << 48)\n            | ((b[7] as u64) << 56)\n    } else {\n        let mut tmp = MaybeUninit::<u64>::uninit();\n        core::ptr::copy_nonoverlapping(buffer, tmp.as_mut_ptr() as *mut u8, 8);\n        u64::from_le(tmp.assume_init())\n    };\n    trace!(addr = ?buffer, value, \"read_uint64le\");\n    value\n}\n\n\n/// Platform‑agnostic “best‑effort” pre‑fetch.  \n///\n/// On targets where an appropriate intrinsic is unavailable (or disabled at compile‑time) the\n/// call degrades to a harmless no‑op.\n/// Ask the hardware to prefetch the data at the given address into the L1 cache.\n#[inline]\npub fn request_prefetch(address: *const u8) {\n    trace!(?address, \"request_prefetch()\");\n    #[cfg(all(target_arch = \"x86_64\", target_feature = \"sse\"))]\n    unsafe {\n        core::arch::x86_64::_mm_prefetch(address as *const i8,\n                                         core::arch::x86_64::_MM_HINT_NTA);\n    }\n\n    #[cfg(all(target_arch = \"aarch64\", target_feature = \"neon\"))]\n    unsafe {\n        // `pldl1keep` equivalent – the exact intrinsic name may vary\n        // between toolchains; this variant is supported by nightly rustc.\n        core::arch::aarch64::prefetch_read_data(address, 0);\n    }\n\n    // Other targets: nothing to do (silences “unused” warnings).\n    #[cfg(not(any(\n        all(target_arch = \"x86_64\", target_feature = \"sse\"),\n        all(target_arch = \"aarch64\", target_feature = \"neon\")\n    )))]\n    {\n        let _ = address;\n    }\n}\n\n\n/// X86-specific code checking the availability of\n/// SSE4.2 instructions.\n/// \n/// If the compiler supports SSE4.2, it definitely\n/// supports X86.\n///\n/// Query the CPU *once*; subsequent calls are\n/// just a cheap load from a `OnceLock`.\npub fn can_use_sse42() -> bool {\n    #[cfg(target_arch = \"x86_64\")]\n    {\n        use std::sync::OnceLock;\n        static FLAG: OnceLock<bool> = OnceLock::new();\n        *FLAG.get_or_init(|| std::arch::is_x86_feature_detected!(\"sse4.2\"))\n    }\n    #[cfg(not(target_arch = \"x86_64\"))]\n    {\n        false\n    }\n}\n\n\n/// ARM-specific code checking for the availability of CRC32C instructions.\n///\n/// Detect AArch64 CRC32/PMULL support.\npub fn can_use_arm64_crc32() -> bool {\n    #[cfg(target_arch = \"aarch64\")]\n    {\n        use std::sync::OnceLock;\n        static FLAG: OnceLock<bool> = OnceLock::new();\n        *FLAG.get_or_init(|| std::arch::is_aarch64_feature_detected!(\"crc\"))\n    }\n    #[cfg(not(target_arch = \"aarch64\"))]\n    {\n        false\n    }\n}\n\n\n/**\n| Un‑accelerated implementation that\n| works on all CPUs.\n|\n*/\npub fn crc32c_extend_portable(crc: u32, data: *const u8, size: usize) -> u32 {\n    trace!(\"crc32c_extend_portable start (size={})\", size);\n    // Safety: caller guarantees that `data` is valid for `size` bytes.\n    unsafe {\n        let mut p = data;\n        let e = data.add(size);\n        let mut l = crc ^ CRC32XOR;\n\n        // Align to the next 4‑byte boundary.\n        let mut x = ((p as usize + 3) & !3) as *const u8;\n        if x > e {\n            x = e;\n        }\n\n        // Process initial unaligned bytes.\n        while p < x {\n            let c = ((l & 0xff) ^ (*p as u32)) as usize;\n            l = BYTE_EXTENSION_TABLE[c] ^ (l >> 8);\n            p = p.add(1);\n        }\n\n        // Bulk processing for >= 16 remaining bytes.\n        if (e as usize - p as usize) >= 16 {\n            let mut crc0 = read_u32_le(p) ^ l;\n            let mut crc1 = read_u32_le(p.add(4));\n            let mut crc2 = read_u32_le(p.add(8));\n            let mut crc3 = read_u32_le(p.add(12));\n            p = p.add(16);\n\n            // Process large blocks (64‑byte iterations).\n            while (e as usize - p as usize) > PREFETCH_HORIZON as usize {\n                for _ in 0..4 {\n                    step4(&mut crc0, p.add(0));\n                    step4(&mut crc1, p.add(4));\n                    step4(&mut crc2, p.add(8));\n                    step4(&mut crc3, p.add(12));\n                    p = p.add(16);\n                }\n            }\n\n            // Process remaining 16‑byte chunks.\n            while (e as usize - p as usize) >= 16 {\n                step4(&mut crc0, p.add(0));\n                step4(&mut crc1, p.add(4));\n                step4(&mut crc2, p.add(8));\n                step4(&mut crc3, p.add(12));\n                p = p.add(16);\n            }\n\n            // Process remaining 4‑byte chunks.\n            while (e as usize - p as usize) >= 4 {\n                step4(&mut crc0, p);\n                let tmp = crc0;\n                crc0 = crc1;\n                crc1 = crc2;\n                crc2 = crc3;\n                crc3 = tmp;\n                p = p.add(4);\n            }\n\n            // Combine the four partial CRCs.\n            l = 0;\n            step4w(&mut l, crc0);\n            step4w(&mut l, crc1);\n            step4w(&mut l, crc2);\n            step4w(&mut l, crc3);\n        }\n\n        // Process any remaining tail bytes.\n        while p < e {\n            let c = ((l & 0xff) ^ (*p as u32)) as usize;\n            l = BYTE_EXTENSION_TABLE[c] ^ (l >> 8);\n            p = p.add(1);\n        }\n\n        let result = l ^ CRC32XOR;\n        trace!(\"crc32c_extend_portable finished (crc={:#010x})\", result);\n        result\n    }\n}\n\nimpl PortableTestTraits {\n\n    pub fn extend(crc: u32, data: *const u8, count: usize) -> u32 {\n        crc32c_extend_portable(crc, data, count)\n    }\n}\n\n\n\n\nThis crate has the following authors:\n[\n    \"klebs <none>\",\n]\nThis crate has the following rust edition:\n2021\nThis crate has the following license:\nMIT\nThis crate is held in the following repository:\nhttps://github.com/klebs6/bitcoin-rs\n","role":"user"}],"model":"gpt-5.1"}}
